[
  {
    "id": "818eac56a7059cb82a13e4656a2039f698b72ba788c548813933b4876d0ec928",
    "text": "Explain the difference between a list and a tuple in Python.",
    "domain": "technical-python",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must cover the core difference in mutability (lists can be changed, tuples cannot) and should mention the syntax difference ([] vs ()). Bonus points for discussing use cases, like tuples being hashable for dictionary keys.",
    "rubric_id": ""
  },
  {
    "id": "e2597dee62322f6c282ffc8c53fb05f56c4e3f480290bdb105cd48aebe4cf671",
    "text": "What is a decorator in Python and when would you use one?",
    "domain": "technical-python",
    "difficulty": 5,
    "ideal_answer_snippet": "The evaluation should check that the answer defines a decorator as a function that modifies or wraps another function. The answer must provide a clear use case, such as logging, timing, or access control, to demonstrate understanding.",
    "rubric_id": ""
  },
  {
    "id": "9b9eb68558305ca415a313c396e79f22388aca179d032c7eca6f4e54ccc2cd9b",
    "text": "What is overfitting in machine learning?",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as a model learning the training data too well, including noise. It must state the key consequence: poor generalization and low performance on new, unseen data.",
    "rubric_id": ""
  },
  {
    "id": "e14e6c83653fbbb3a201aaec7896d966776b011333fd3458df5825e9ec27eddb",
    "text": "Explain the bias-variance tradeoff.",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both bias (error from overly simple assumptions) and variance (error from sensitivity to small fluctuations in training data). It must explain their inverse relationship and the goal of finding a balance to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "467e32aa6b01342398a947117f8456f2678388b2a4dc62a02a10e38dc5c32834",
    "text": "What are the core values of Agile?",
    "domain": "behavioral-agile",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list the four core values from the Agile Manifesto. Key concepts to look for are: individuals and interactions, working software, customer collaboration, and responding to change.",
    "rubric_id": ""
  },
  {
    "id": "ce6846fb82992fa753ca2bbbfabad8528aa357a025ec776db91d4ac47087d326",
    "text": "Is Java Platform Independent if then how?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state 'yes' and explain that platform independence is achieved through the Java Virtual Machine (JVM), which interprets compiled Java bytecode for any platform.",
    "rubric_id": ""
  },
  {
    "id": "3f955fc64a74498a477a407ba268c7f86eeda4725d80475a8c0fe3e4d8c378f0",
    "text": "What are the top Java Features?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list several key features of Java. Look for mentions of platform independence, its object-oriented nature, robustness (e.g., garbage collection), and security.",
    "rubric_id": ""
  },
  {
    "id": "68ebf5f7158b4384302be47e6bbc22e1e4fdc15cd5524d62377beb4a9cea9606",
    "text": "What is JVM?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define JVM as the Java Virtual Machine. It should explain its core function: to load, verify, and execute Java bytecode, which is the key to Java's platform independence.",
    "rubric_id": ""
  },
  {
    "id": "b3c945fc712e9f54448624d8513dfb9cab8b604c030f5573c21b5f7662bd45fb",
    "text": "What is JIT?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify JIT as the Just-In-Time compiler. It should explain that the JIT improves performance by compiling bytecode into native machine code at runtime.",
    "rubric_id": ""
  },
  {
    "id": "5ff12ccc426c4fdcb45ce1ec954114b185e6a52c6f45fe3180095d4068da2fed",
    "text": "What are Memory storages available with JVM?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list the key memory areas within the JVM. Check for mentions of the Heap (for object allocation), Stack (for method calls and local variables), and Method Area (for class-level data).",
    "rubric_id": ""
  },
  {
    "id": "e99845afddc259b49689119019e1453f5e52a1e44b35b13e0a8d21194d5a32b8",
    "text": "What is a classloader?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the classloader as the part of the JRE responsible for dynamically loading Java classes into the JVM at runtime.",
    "rubric_id": ""
  },
  {
    "id": "26d2ab6c51c10c54a1737e0e31face189e91f12dd10c08d0f89c93c736ff0cd1",
    "text": "Difference between JVM, JRE, and JDK.",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must correctly differentiate the three components. Look for: JDK (for development, includes JRE), JRE (for running applications, includes JVM), and JVM (the virtual machine that executes code).",
    "rubric_id": ""
  },
  {
    "id": "52c42068cbfc1673d81237041050faab9c1b49c3cb5a6a4b56c299c22f578bb2",
    "text": "What are the differences between Java and C++?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must highlight key distinctions. Check for platform independence (Java is, C++ is not), memory management (Java has automatic garbage collection), and pointers (Java does not support direct pointer arithmetic).",
    "rubric_id": ""
  },
  {
    "id": "d281a075c8fbef39e4669c1dc003db2a48873a8a5cc57d1bda65f75c69780998",
    "text": "Explain public static void main(String args[]) in Java.",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must break down each keyword: 'public' (access modifier for global availability), 'static' (method can be run without creating an instance of the class), 'void' (method doesn't return a value), and 'main' (the entry point for execution).",
    "rubric_id": ""
  },
  {
    "id": "45e1ca220067d432e08f59fdf338a9750c3cdcf828e75792b7dd0267bb95428d",
    "text": "What is Java String Pool?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain the String Pool as a special storage area in the heap memory. It should mention that it stores unique string literals to save memory by reusing existing objects.",
    "rubric_id": ""
  },
  {
    "id": "8f334858156a6c86173114f5e6fe96106bea7dbbd89b1a64ac69aa9143075697",
    "text": "What will happen if we don't declare the main as static?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that while the program will compile without error, the JVM will not be able to find and execute the main method, as it looks for a static main method as the application's entry point.",
    "rubric_id": ""
  },
  {
    "id": "a714b72e8307de81ff4a41948b256f496c57951dcc802d3595f9bef6e76187dc",
    "text": "What are Packages in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should define packages as a way to group related classes and interfaces. It must mention the primary benefits: preventing naming conflicts and controlling access.",
    "rubric_id": ""
  },
  {
    "id": "d5e5c16551b8e70cfe32e905d68b65dcab87dd9ba62d787fcef9d2a5c12e221b",
    "text": "Why Packages are used?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must clearly state the reasons for using packages. Key points to look for are preventing naming conflicts, providing controlled access to classes, and organizing a large codebase.",
    "rubric_id": ""
  },
  {
    "id": "f377e9feecd84ddfaa2155d2cc5aac1f771832cfa864c8a4d7d470e06af6a448",
    "text": "What are the advantages of Packages in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should list the main benefits of using packages. Check for concepts like avoiding name collisions, easier access control, and better organization of related classes and interfaces.",
    "rubric_id": ""
  },
  {
    "id": "ac6ab2f3870358b86b0618df0d0690e27049709c76b14e88e88f082eb30b6b82",
    "text": "How many types of packages are there in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify the two main types of packages: built-in packages (from the Java API, e.g., java.util) and user-defined packages (created by the programmer).",
    "rubric_id": ""
  },
  {
    "id": "a0b8c803a962ca82cb49aa8e317662d80f36a29bccfe5a4b51102ecd119df0cc",
    "text": "Explain different data types in Java.",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must distinguish between primitive data types (e.g., int, char, boolean) and non-primitive/reference data types (e.g., String, Array, Class). It should provide examples for each category.",
    "rubric_id": ""
  },
  {
    "id": "deaeae593a593db2b2761381b15eceb2053cb7566ba003779eec62cb56d3401b",
    "text": "When a byte datatype is used?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should specify that the 'byte' data type is used to save memory in large arrays when the variable's value is known to be within the 8-bit signed integer range (-128 to 127).",
    "rubric_id": ""
  },
  {
    "id": "0ddff66f0690f30cd7b79481eb123d50b8eb3eac2c1829a722ccf6bf571c3c57",
    "text": "Can we declare Pointer in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must be a clear 'no'. It should explain that Java does not support pointers to avoid direct memory manipulation, which enhances security and robustness.",
    "rubric_id": ""
  },
  {
    "id": "45b5c69657669e3da3c72f4394b092f4ec58ebb5abcf51f1a6ae876d764dde04",
    "text": "What is the default value of byte datatype in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the default value for a byte data type in Java is 0.",
    "rubric_id": ""
  },
  {
    "id": "0a9a4883906bb89ed2662a9d9e5778cbd341da1c6b3ab50bc06d37d76875b576",
    "text": "What is the default value of float and double datatype in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must correctly state the default values: 0.0f for float and 0.0d for double.",
    "rubric_id": ""
  },
  {
    "id": "36635227ae7aa47bd255f1f96764b25ca61acd50db44983bf261531c7fb633ca",
    "text": "What is the Wrapper class in Java?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a wrapper class as a class that encapsulates primitive data types into an object. It should explain that this is necessary for using primitives in contexts that require objects, such as with Java Collections.",
    "rubric_id": ""
  },
  {
    "id": "4d12f0f9b055e8684412afad0e8832bea3af2c91a4024165554f2472171ee9d7",
    "text": "Why do we need wrapper classes?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state the primary need for wrapper classes: to use primitive data types with Java's collection framework (e.g., ArrayList) and to take advantage of utility methods provided by these classes. It should also mention autoboxing and unboxing.",
    "rubric_id": ""
  },
  {
    "id": "f2a6ca84c67388add63d82dadff2f68bd4cbb60bb83e49df76c122381c87d690",
    "text": "Differentiate between instance and local variables.",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate based on scope and lifetime. Look for: instance variables are declared in a class but outside a method and belong to an object instance, while local variables are declared within a method and exist only during that method's execution.",
    "rubric_id": ""
  },
  {
    "id": "07eb5dec04f1f16cea9fcd2d615da1785505b8173d2556e5e332e18681f88f21",
    "text": "What are the default values assigned to variables and instances in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must specify that instance variables get default values if not explicitly initialized. Look for correct defaults: 0 for numeric types, false for boolean, and null for object references. It should also note that local variables do not get default values.",
    "rubric_id": ""
  },
  {
    "id": "a6c490c8ed33b3f0e70d02e62b49ad2a06520f83ae299213a51803ba40b607c0",
    "text": "What is a Class Variable?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a class variable as one declared with the 'static' keyword. It should emphasize the key property: there is only one copy of a static variable, which is shared among all instances of the class.",
    "rubric_id": ""
  },
  {
    "id": "d72678bd60866c5b34ced4e40541ba1978751c30bd8016eebe9eb6a5d4787c3d",
    "text": "What is the default value stored in Local Variables?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that local variables are not assigned any default value by the compiler. They must be explicitly initialized before use.",
    "rubric_id": ""
  },
  {
    "id": "6673549d90b217705d41ae5ac93b08d7eb0f425aedfe5c689c78562f6903a530",
    "text": "Explain the difference between instance variable and a class variable.",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate based on the 'static' keyword and how they are stored. Check for: Instance variables (non-static) belong to a specific object, with each object having its own copy. Class variables (static) are shared among all objects of the class.",
    "rubric_id": ""
  },
  {
    "id": "6b5dee6b3cecc3141aeb985842ede6a7944b9ad49c8a9d2d5951175cf8a239e5",
    "text": "What is a static variable?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define a static variable as one that belongs to the class itself rather than to any specific instance. The key concept to look for is that a single copy of the variable is shared among all objects of that class.",
    "rubric_id": ""
  },
  {
    "id": "1dc25af5c5d2f2f90923176486ae0ca4b282a44f23a0d1b50fd8aca65f9feb7b",
    "text": "What is the difference between System.out, System.err, and System.in?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must correctly identify each stream: System.out for standard output, System.err for standard error output (often for displaying errors), and System.in for standard input (typically keyboard input).",
    "rubric_id": ""
  },
  {
    "id": "c510dcfa267b7e3574ab632773f49034f5a9b144a05d12cca6ab2b7b40fc2dfb",
    "text": "What do you understand by an IO stream?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should define an I/O stream as a sequence of data flowing from a source to a destination. It must differentiate between input streams (for reading data) and output streams (for writing data).",
    "rubric_id": ""
  },
  {
    "id": "86eb9b4ba46ad23359f28f5dd984c7de19ae3478a1b3b07e5b8dcebc9a25e060",
    "text": "What is the difference between the Reader/Writer class hierarchy and the InputStream/OutputStream class hierarchy?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must highlight the fundamental difference: InputStream/OutputStream classes handle byte streams (for binary data like images), while Reader/Writer classes handle character streams (for text data, managing character encoding).",
    "rubric_id": ""
  },
  {
    "id": "06d6b6c6d87c2ab65ec8c7ccbb828a3aa2376ffdca4c2f60784ead6920179888",
    "text": "What are the super most classes for all the streams?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the four abstract base classes for Java I/O streams. Check for: java.io.InputStream, java.io.OutputStream, java.io.Reader, and java.io.Writer.",
    "rubric_id": ""
  },
  {
    "id": "a9ebd4c578e73e889a5f62ecb41370c3bd42c7e5c987169216402ebf4fb58f9f",
    "text": "What are the FileInputStream and FileOutputStream?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define these as concrete stream classes for file I/O. It should specify that FileInputStream is for reading byte data from a file, and FileOutputStream is for writing byte data to a file.",
    "rubric_id": ""
  },
  {
    "id": "06b0139d1432238de790c713000c977699f9684df74a0fa9258cc44683ded16e",
    "text": "What is the purpose of using BufferedInputStream and BufferedOutputStream classes?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that these classes improve I/O performance. The key mechanism to mention is buffering: they read or write large chunks of data from/to an internal buffer, reducing the number of actual system calls.",
    "rubric_id": ""
  },
  {
    "id": "720570f3466280fa06501d848915eb72bef3c426fca6145e411093cb5e04cbd8",
    "text": "What are FilterStreams?",
    "domain": "technical-java",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should define Filter Streams (like FilterInputStream/FilterOutputStream) as wrapper classes that add functionality to other streams. It must provide an example, such as BufferedInputStream adding buffering capabilities to a FileInputStream.",
    "rubric_id": ""
  },
  {
    "id": "9267e8649baed19d59adfded8e2bef76dc948df3934b53f05a914a4632ff0b1d",
    "text": "What is an I/O filter?",
    "domain": "technical-java",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define an I/O filter as an object that processes data as it is being read from one stream and written to another. This concept is the basis for classes like FilterInputStream and FilterOutputStream.",
    "rubric_id": ""
  },
  {
    "id": "63fa71802678bd019cbe8a1145e6d8095b320daf39b918fb3112a2ee36a0e1c2",
    "text": "How many ways you can take input from the console?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should list common methods for console input in Java. Key classes to mention are the Scanner class (most common and easy) and the BufferedReader class (more efficient for large inputs).",
    "rubric_id": ""
  },
  {
    "id": "52e03489f10d3174c8862cdd66639a0c71940e5b2fe407bc44da1ad56eb82cd0",
    "text": "Difference in the use of print, println, and printf.",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must distinguish the three printing methods. Look for: 'print' keeps the cursor on the same line, 'println' moves the cursor to the next line after printing, and 'printf' allows for formatted output using format specifiers.",
    "rubric_id": ""
  },
  {
    "id": "938c8600bebde2fe47611cc4d4e9cb4115f8a55764df784ad1b74320649806d5",
    "text": "What are operators? ",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should define operators as special symbols used to perform operations on variables and values. It should provide examples like arithmetic operators (+, -) or logical operators (&&, ||).",
    "rubric_id": ""
  },
  {
    "id": "795940326aab350db1ca73a0c5cc002a8f19f2f95860149223b9790565b8d482",
    "text": "How many types of operators are available in Java? ",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should list several categories of operators in Java. Check for mentions of Arithmetic, Relational, Logical, Assignment, and Bitwise operators.",
    "rubric_id": ""
  },
  {
    "id": "3f62f311fffacfb3b417885eeed000e6b9f873b17414767ed96d05dd7a3c2942",
    "text": "Explain the difference between >> and >>> operators.",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate between the signed (>>) and unsigned (>>>) right shift operators. Key point: '>>' preserves the sign bit (fills with 1s for negative numbers), while '>>>' always fills with zeros, regardless of the sign.",
    "rubric_id": ""
  },
  {
    "id": "325495965c67a743f36f0a56f89765578aa5d7229e8725a3dd757a3eda18cfa3",
    "text": "Which Java operator is right associative?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the assignment operator (=) and its variations (e.g., +=, -=) as being right-associative. This means expressions like a = b = 5 are evaluated from right to left.",
    "rubric_id": ""
  },
  {
    "id": "e12de88f98f0bc1992d2159327850230a41df9ba5c8624c0e1b2bf57c4843d88",
    "text": "What is dot operator?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain that the dot operator (.) is used to access the members (instance variables and methods) of an object or class.",
    "rubric_id": ""
  },
  {
    "id": "b2c2465a35f9c891b54777d6e1e979966e973406f2d727c3ddf43a6f1d7ab8c6",
    "text": "What is covariant return type?",
    "domain": "technical-java",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define a covariant return type as the ability for an overriding method in a subclass to have a return type that is a subtype of the return type of the overridden method in the superclass. This avoids the need for casting.",
    "rubric_id": ""
  },
  {
    "id": "8e92505a572179f01ab3af2bd8a6d449620a75f11478f6d35bc29c4936a0cf86",
    "text": "What is the transient keyword?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the 'transient' keyword is used to mark a field to be excluded when an object is serialized. This is used for fields that should not be persisted.",
    "rubric_id": ""
  },
  {
    "id": "d4518833795bba874ce83159a9a32feb0c87fd9808f1c6555720d785bb374237",
    "text": "What's the difference between the methods sleep() and wait()?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must highlight the key difference related to locking. Look for: sleep() is a method of the Thread class and does not release the lock it holds, while wait() is a method of the Object class and does release the lock, allowing another thread to enter the synchronized block.",
    "rubric_id": ""
  },
  {
    "id": "397b4689341207ce62e83b637b7524b05b964f9570faf41b5e4c14754af6c06d",
    "text": "What are the differences between String and StringBuffer?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must focus on the core difference of immutability. Check that it states String objects are immutable (cannot be changed), while StringBuffer objects are mutable (can be modified). It should also mention that StringBuffer is thread-safe.",
    "rubric_id": ""
  },
  {
    "id": "6d4fa2e60bc6f83bd610769b07850d5b1dbbe7ba92936758d7b98bfb9f891d58",
    "text": "What are the differences between StringBuffer and StringBuilder?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must focus on thread safety (synchronization). Look for: StringBuffer is synchronized and therefore thread-safe, while StringBuilder is non-synchronized and not thread-safe, but is faster in a single-threaded environment.",
    "rubric_id": ""
  },
  {
    "id": "5437cf32155faf62dc250ca864409ed74a2355f87dc7dbec5510c1f4a0d5dcf0",
    "text": "Which among String Builder or String Buffer should be preferred when there are a lot of updates required to be done in the data?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must make a choice based on the threading context. Check for: use StringBuilder for better performance in a single-threaded environment, and use StringBuffer when thread safety is required in a multi-threaded environment.",
    "rubric_id": ""
  },
  {
    "id": "e32b0f4e5b69a54e6020e510a72861fbece82aacf5d00a6c516d4d839ea0adf5",
    "text": "Why is StringBuffer called mutable?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should explain that StringBuffer is called mutable because its contents and size can be modified after it is created, without creating a new object. This is in direct contrast to the immutable String class.",
    "rubric_id": ""
  },
  {
    "id": "b54bb2a54ec3ce6ec2facc060456fcd7ca83c28518e647a7a76913f366174972",
    "text": "How is the creation of a String using new() different from that of a literal?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on memory allocation. Key point: using a literal (`String s = \"abc\"`) may reuse an existing object from the String pool. Using `new String(\"abc\")` is guaranteed to create a new object in the heap memory.",
    "rubric_id": ""
  },
  {
    "id": "46964f3e3fa014900b8cad581a6b9996c46d81dede4835b5a2bdd02cdad73df7",
    "text": "What is an array in Java?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define an array as a data structure that stores a fixed-size, sequential collection of elements of the same type. It should mention that elements are accessed via a zero-based index.",
    "rubric_id": ""
  },
  {
    "id": "f52f3e17fcb6c24b98e211f5056a55b6b8ac47a060658f853e46efbb17038bb7",
    "text": "On which memory arrays are created in Java?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly state that arrays in Java are objects and are therefore created in the heap memory. The reference variable to the array is stored in the stack.",
    "rubric_id": ""
  },
  {
    "id": "4cf13f0a627b4e45f5850d0b01e7ca53a0df6ca3b09f5c62434517679b7dbfd3",
    "text": "What are the types of an array?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should identify the main types of arrays based on their dimensions. Look for a distinction between single-dimensional arrays and multi-dimensional arrays (like 2D arrays or matrices).",
    "rubric_id": ""
  },
  {
    "id": "75b669ad44e666460a30d44c2a23b1546d540d8719685df0e6d6315811f6b760",
    "text": "Why does the Java array index start with 0?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should explain that the index represents an offset from the base memory address of the array. The first element is at the base address itself, so its offset is 0.",
    "rubric_id": ""
  },
  {
    "id": "300a9765938991d11262311a1f22dac37d92417d19c8abf775615e6970c6d05e",
    "text": "What is the difference between int array[] and int[] array?",
    "domain": "technical-java",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that there is no functional difference; both declare an array of integers. It should identify `int[] array` as the preferred, conventional Java style, as it keeps the type information (`int[]`) together.",
    "rubric_id": ""
  },
  {
    "id": "f12efa2826feda74bbac0af351ef85478f878940146bd6fcb656db003e417fc7",
    "text": "How to copy an array in Java?",
    "domain": "technical-java",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several methods for copying arrays. Check for mentions of `System.arraycopy()`, the `clone()` method, and utility methods from the `java.util.Arrays` class like `Arrays.copyOf()`.",
    "rubric_id": ""
  },
  {
    "id": "87f44c8a17e9e8688d0b73c643c44adcb4bf018eb51b3567dc3dc91938dc16b8",
    "text": "Explain C++ and its advantages.",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define C++ as an object-oriented extension of C. Check for mentions of key advantages like OOP features (classes, inheritance), performance (mid-level language), and memory management capabilities.",
    "rubric_id": ""
  },
  {
    "id": "f26fac65e041b07f60893b6177c148354ded6e88ab373ef51a7b8a231aa34a80",
    "text": "What are the different data types present in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should categorize the data types. Look for a distinction between fundamental (int, float, char), derived (array, pointer), and user-defined (class, struct) types.",
    "rubric_id": ""
  },
  {
    "id": "4962d3dfdcf57be07608f85207984f8d7f63eb3838fb21301c50e2e7c1e81a70",
    "text": "Define 'std' in C++.",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify 'std' as the standard namespace. It should explain that this namespace contains the C++ Standard Library components like `cout`, `cin`, `string`, and `vector`.",
    "rubric_id": ""
  },
  {
    "id": "31d23638874a9a74dab8228ee24d67e9105b42d23a9848db83164c5f0a178dcf",
    "text": "What are references in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define a reference as an alias for an existing variable. It should state two key properties: a reference must be initialized upon declaration and it cannot be changed to refer to another variable.",
    "rubric_id": ""
  },
  {
    "id": "14b59ebb2abc1d6dff22a347086517ad4312a2c558abe30e27fac5a030a658b7",
    "text": "What do you mean by Call by Value and Call by Reference?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must distinguish between the two argument-passing mechanisms. Look for: Call by Value passes a copy of the argument, so the original variable is unaffected. Call by Reference passes the address (or an alias), so the original variable can be modified by the function.",
    "rubric_id": ""
  },
  {
    "id": "4900dc7b14c8f38ed78a5f42f3dc8bf00cbfd0e51c5c5f7ef3f0639d56bd3833",
    "text": "Define token in C++.",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should define a token as the smallest individual unit of a C++ program that is meaningful to the compiler. It must provide examples like keywords, identifiers, operators, and constants.",
    "rubric_id": ""
  },
  {
    "id": "d7dca22d23331edb5164245c73b8783450f331266e9e85cc18f16106bb331dd0",
    "text": "What is the difference between C and C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must highlight that C++ is an extension of C with support for Object-Oriented Programming (OOP). Key differences to look for are C++'s inclusion of classes, objects, inheritance, and polymorphism, which C lacks.",
    "rubric_id": ""
  },
  {
    "id": "f57df5281644065b34c31c246b649d903e303192087b8f433b49a4965c89a467",
    "text": "What is the difference between struct and class in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify the single key difference: the default access specifier. For a struct, members are public by default. For a class, members are private by default.",
    "rubric_id": ""
  },
  {
    "id": "1bb471d0704bdbf47340717f5048ecbe44d016de903204ad8f4f187750deb598",
    "text": "What is the difference between reference and pointer in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast several key aspects. Check for: references must be initialized and cannot be reassigned or be null, whereas pointers can. Also, the syntax for accessing members differs ('.' for references, '->' for pointers).",
    "rubric_id": ""
  },
  {
    "id": "3115b9b5f13a117a0251c3725287e3ed639f034cf86c897a3cad20fe372bd6a6",
    "text": "What is the difference between function overloading and operator overloading in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both concepts. Function overloading involves multiple functions with the same name but different parameters. Operator overloading involves redefining the behavior of an existing operator for a user-defined type (class or struct).",
    "rubric_id": ""
  },
  {
    "id": "3d9d6ad7dac4edb27918642441469b6c1e4f7c3efec9652a643718b9693c7cbc",
    "text": "What is the difference between an array and a list (like `std::list`) in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must compare storage and performance characteristics. Check for: arrays are fixed-size and contiguous in memory, providing fast O(1) random access. `std::list` is a linked list, dynamic in size, non-contiguous, and provides fast O(1) insertion/deletion but slow O(n) access.",
    "rubric_id": ""
  },
  {
    "id": "af3769d296c6026981e143a2fc3e423fafe639b121eb038587fc2ed5cbdfc2b1",
    "text": "What is the difference between a while loop and a do-while loop in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate based on when the condition is checked. Look for: a `while` loop is entry-controlled (checks before executing), while a `do-while` loop is exit-controlled (executes at least once, then checks).",
    "rubric_id": ""
  },
  {
    "id": "def75c4d807a632fcdfbbbd27b9308d3d3b7d26510a4e3676d01c4d988898232",
    "text": "Discuss the difference between prefix and postfix increment/decrement operators in C++.",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain the order of operation. Prefix (`++var`) increments the variable first, then returns the new value. Postfix (`var++`) returns the original value first, then increments the variable.",
    "rubric_id": ""
  },
  {
    "id": "bfd732497220dc7571d6afedaf5698280637056886ba25b0afaf4a21d7f4c0bc",
    "text": "What is the difference between `new` and `malloc()` in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify `new` as a C++ operator and `malloc()` as a C function. Key difference: `new` is type-safe and calls the object's constructor, while `malloc()` just allocates raw memory and returns a void pointer without calling a constructor.",
    "rubric_id": ""
  },
  {
    "id": "e37004f67e1478617a7bb2344d9cdc62aa14ea932ab5354c9de55e6610bfc768",
    "text": "What is the difference between virtual functions and pure virtual functions in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must differentiate based on implementation. A virtual function has an implementation in the base class and can be overridden. A pure virtual function (`= 0`) has no implementation, making the class abstract and forcing derived classes to provide an implementation.",
    "rubric_id": ""
  },
  {
    "id": "909a3928cd1e528f44264be89ca6ba362462ab1db7817c29910f2dcd9d01aeb5",
    "text": "What are classes and objects in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define a class as a blueprint or template for creating objects. An object must be defined as an instance of a class, a concrete entity with its own data members.",
    "rubric_id": ""
  },
  {
    "id": "0f0be126b3c5e28eeaa289a5c64b15ffade362c2add1c04a43be121dcbea2c56",
    "text": "What is Function Overriding in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define function overriding as a derived class providing its own implementation for a virtual function from its base class. It should state that the function signature (name, parameters, return type) must match.",
    "rubric_id": ""
  },
  {
    "id": "afeb03a232d1872819725aae2ec55217783f2ab92b112bc1fd1c6f3226359093",
    "text": "What are the various OOPs concepts in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should list the core concepts of Object-Oriented Programming. Check for mentions of Encapsulation, Abstraction, Inheritance, and Polymorphism.",
    "rubric_id": ""
  },
  {
    "id": "977b4ca45d44c0f4901dd9288fea9a477cd2cbaeba39a87f159a4b3039b89992",
    "text": "Explain inheritance in C++.",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define inheritance as the mechanism where a new class (derived) inherits properties from an existing class (base). The primary purpose to mention is code reusability.",
    "rubric_id": ""
  },
  {
    "id": "abf9f1640ded29c607205f4d8eb432d069bd08c051e01f958e90a4801e48fe5f",
    "text": "When should we use multiple inheritance in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should state that multiple inheritance is used when a class needs to combine behaviors from more than one distinct base class. It must also acknowledge the potential complexity, like the diamond problem.",
    "rubric_id": ""
  },
  {
    "id": "843677c16ed8832ccb2e0a50e647b6740686a17bab1a9d0a283d0c7ea31ebcf4",
    "text": "What is virtual inheritance in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define virtual inheritance as the solution to the diamond problem in multiple inheritance. The key mechanism to check for is that it ensures a derived class gets only one copy of the common base class's members.",
    "rubric_id": ""
  },
  {
    "id": "67a3f5fbf985fbcf0a27de5ffba775293895a4991a0184f6e13d2265fa351004",
    "text": "What is polymorphism in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define polymorphism as 'many forms' and explain it as the ability for objects to be treated through a common interface. It should distinguish between compile-time (overloading) and runtime (virtual functions) polymorphism.",
    "rubric_id": ""
  },
  {
    "id": "9247831b0a01c0be09c0b66f9981a6005ec9832fb1cb2f0fde2d918e7cf553d5",
    "text": "What are the different types of polymorphism in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the two main types of polymorphism. Look for: Compile-time (or static) polymorphism, achieved via function and operator overloading, and Runtime (or dynamic) polymorphism, achieved via virtual functions.",
    "rubric_id": ""
  },
  {
    "id": "7676654a8217ee07e4dda5a2d28872fb0a0d2e38af94fb11c6e7346d8c6f4929",
    "text": "Compare compile-time polymorphism and Runtime polymorphism in C++.",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast the two types. Look for: compile-time is resolved by the compiler (early binding) and is faster, using function/operator overloading. Runtime is resolved at runtime (late binding), is more flexible, and uses virtual functions.",
    "rubric_id": ""
  },
  {
    "id": "13e41238ea68daf9b7101880ee4533b679f8f1613ed946ce9cc8b1964700962b",
    "text": "Explain the constructor in C++.",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define a constructor as a special member function that is automatically called when an object is created. Its primary purpose is to initialize the object's data members. It should also mention that its name is the same as the class name.",
    "rubric_id": ""
  },
  {
    "id": "199b75fa8736ff34696394545c606c995e8e2b6073cb4a9f52e0a883e374ebe7",
    "text": "What are destructors in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define a destructor as a special member function automatically called when an object is destroyed. Its primary purpose is to release resources (like freeing memory) allocated by the object.",
    "rubric_id": ""
  },
  {
    "id": "8821ceb5a33ba84aaa806fcde3a0376ec3c709efd96ab91719e5c33aa2ccfa2a",
    "text": "What is a virtual destructor in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that a virtual destructor is crucial for correct cleanup when deleting a derived class object through a base class pointer. It ensures that the destructors for both the derived and base classes are called, preventing resource leaks.",
    "rubric_id": ""
  },
  {
    "id": "289b911199f23ba88fa3f9cdad2895060b3c1c84d2aee54ff1235e0fc375d366",
    "text": "Is destructor overloading possible in C++? If yes then explain and if no then why?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must be a clear 'no'. The reasoning should be that destructors do not take any arguments, and therefore there is no way to create a different signature for overloading.",
    "rubric_id": ""
  },
  {
    "id": "c3c623d31e9f52a13c6339886e326b05083d05bc7e425c14140d3acdb0c10010",
    "text": "Which operations are permitted on pointers in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list valid pointer operations. Check for: increment/decrement, addition/subtraction of an integer, subtraction of two pointers (of the same type), comparison, and dereferencing (* and ->).",
    "rubric_id": ""
  },
  {
    "id": "a888b7143e105732bec2b121b7a541aa525f867e06b7b83d622848ca881db888",
    "text": "What is the purpose of the \"delete\" operator in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the `delete` operator is used to deallocate memory from the heap that was previously allocated with the `new` operator. It should mention that its purpose is to prevent memory leaks.",
    "rubric_id": ""
  },
  {
    "id": "767b3b5963988acc41439336c88fdc258643be211a9a246e69850cbeed2e608a",
    "text": "How is `delete []` different from `delete` in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clearly distinguish between deallocating a single object versus an array. Look for: `delete` is for a single object allocated with `new`. `delete []` is for an array of objects allocated with `new []`, ensuring the destructor is called for every element in the array.",
    "rubric_id": ""
  },
  {
    "id": "d589fa8634289bbe30593e8f3aa2a3eee519107796bea53abc125c2e0469e1f0",
    "text": "What do you know about friend class and friend function in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the `friend` keyword grants a non-member function or another class special access to the `private` and `protected` members of the class that declares them as a friend.",
    "rubric_id": ""
  },
  {
    "id": "c346a41602b8d50157e2982f90a5be0b1e1f3868fe8f0e4af4731b80b391b0a8",
    "text": "What is an Overflow Error in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define an overflow error as a condition that occurs when the result of an arithmetic operation is too large to fit into the allocated space of the variable's data type, leading to incorrect, often 'wrapped-around' values.",
    "rubric_id": ""
  },
  {
    "id": "19db9d299f38b7c51695dca1f09e8cc5f8bd2c933ec1e5d18e86aecd390347b5",
    "text": "What does the Scope Resolution operator `::` do in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should list the primary uses of the scope resolution operator. Check for: accessing global variables, defining member functions outside a class, accessing static members, and accessing members of a specific namespace.",
    "rubric_id": ""
  },
  {
    "id": "43d281a02f0f4fef309ac39b4ce2b0f25a484a6ebdab34b47311744f98e3adda",
    "text": "What are the C++ access modifiers?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list and define the three access modifiers. Look for: `public` (accessible from anywhere), `protected` (accessible within the class and its derived classes), and `private` (accessible only within the class).",
    "rubric_id": ""
  },
  {
    "id": "568363aeb5e8e6e76b94e5a8773138a2c0b7f42def14b820bc302b4644e25d51",
    "text": "Can you compile a C++ program without the main function?",
    "domain": "technical-c-plus-plus",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should state that you can compile a source file into an object file without a `main` function. However, it must clarify that you cannot link these object files into a runnable executable without a `main` function, as it serves as the program's entry point.",
    "rubric_id": ""
  },
  {
    "id": "67c1ecaae9f093bec7cfab871647bb271469784044f02d560aeabf6a2cb14c04",
    "text": "What is STL in C++?",
    "domain": "technical-c-plus-plus",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify STL as the Standard Template Library. It should explain that the STL provides a collection of template classes and functions for common data structures (like vectors, maps) and algorithms (like sort, find).",
    "rubric_id": ""
  },
  {
    "id": "caacd734f142726d3482dbc0b614a2bfb99a0d1bebfcef51f4b18e2067a8621b",
    "text": "Define inline function in C++. Can we have a recursive inline function?",
    "domain": "technical-c-plus-plus",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an inline function as a request to the compiler to replace the function call with the function's body to avoid call overhead. It should also state that a recursive function generally cannot be inlined because it would lead to infinite expansion.",
    "rubric_id": ""
  },
  {
    "id": "7f955d4a191c643c1e9e38aefa25dd7fbc85173fcc8c96e5edc937fdeb664ee3",
    "text": "What is an abstract class in C++ and when do you use it?",
    "domain": "technical-c-plus-plus",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define an abstract class as a class that cannot be instantiated and contains at least one pure virtual function. It should explain that they are used to define a common interface that all derived classes must implement.",
    "rubric_id": ""
  },
  {
    "id": "c09512bbcda85e8fba0e28e98d0177f2f9c2486a037f337c91e7409a71690cd3",
    "text": "What is the purpose of feature engineering in machine learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the purpose of feature engineering is to create, select, and transform features from raw data to improve the performance and accuracy of machine learning models.",
    "rubric_id": ""
  },
  {
    "id": "8d4adcecc187bafc5ad0dadcc52abff6dbb81b40ff44fb7703532fbf268b55f5",
    "text": "What are some common techniques for feature engineering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common feature engineering techniques. Look for mentions of one-hot encoding for categorical variables, scaling or normalization of numerical features, and creating interaction terms or polynomial features.",
    "rubric_id": ""
  },
  {
    "id": "10319ae497880d19e496403be49fcf3ba2ffc0b3b5d0252af98adac0904f3689",
    "text": "What is the difference between batch processing and real-time processing?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on timing and data volume. Check for: batch processing handles large volumes of data at scheduled intervals, while real-time processing handles data as it arrives, requiring low latency.",
    "rubric_id": ""
  },
  {
    "id": "0ece11082bb833d1fb2015d84c7e43487e3d3a7359fe2c1614e2e01e2c9844a3",
    "text": "What is natural language processing (NLP)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define NLP as a field of AI focused on enabling computers to understand and process human language. It should mention common tasks like sentiment analysis, machine translation, or text classification.",
    "rubric_id": ""
  },
  {
    "id": "971767ead1a62a8b123c4403ca96111359f84e28d4d353a02e3796ad490a43ff",
    "text": "What is sentiment analysis?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should define sentiment analysis as the task of determining the emotional tone (positive, negative, neutral) behind a piece of text. It should also provide a use case, such as analyzing customer reviews or social media comments.",
    "rubric_id": ""
  },
  {
    "id": "1624110d0b8641bc3c32c9c157afcc4ee2ae1ab0c612aa867916de69c81c8034",
    "text": "What is transfer learning in NLP?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain transfer learning as the process of using a pre-trained model (like BERT or GPT) on a new, related task. The key benefit to mention is improved performance with less data and faster training.",
    "rubric_id": ""
  },
  {
    "id": "4be508f777151d514c7601712cc8601404d22793ed7b64ff1fd54fe3c2997e2c",
    "text": "What is named entity recognition (NER)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define NER as the task of identifying and classifying named entities in text into predefined categories, such as person names, organizations, and locations.",
    "rubric_id": ""
  },
  {
    "id": "0fd7a2aa01c248923b7854a9143b9f6b52037fc63cff1faf82f138638a847f8e",
    "text": "What are some challenges in working with unstructured data?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several challenges. Look for mentions of the difficulty in extracting meaningful features, handling noise and inconsistencies, and the sheer volume of data often involved.",
    "rubric_id": ""
  },
  {
    "id": "09e3873dd052cf704f03bc8e77413fc87532555ce3b5d769ef47004a3b08bd37",
    "text": "What is collaborative filtering in recommendation systems?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define collaborative filtering as a technique that makes recommendations based on the preferences of similar users or the similarity of items. It should explain the core idea of 'users who liked X also liked Y'.",
    "rubric_id": ""
  },
  {
    "id": "6aa6fb99dd9bad83b32884ea000e972613a8dd843238b550f85293012ed458b4",
    "text": "What are some evaluation metrics used in recommendation systems?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list metrics relevant to recommendation tasks. Look for mentions of precision, recall, Mean Average Precision (MAP), or Normalized Discounted Cumulative Gain (NDCG) for ranking, and MAE/RMSE for rating prediction.",
    "rubric_id": ""
  },
  {
    "id": "963d639671f56164f210f115f6a2ebeb582b719dea8888e9f98832f5afc66686",
    "text": "What is deep reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define deep reinforcement learning as the combination of reinforcement learning (learning from rewards) with deep neural networks (to approximate value functions or policies), enabling it to handle high-dimensional state spaces.",
    "rubric_id": ""
  },
  {
    "id": "3f8969596639c3959abc03b45d05dde81f7a499ba9c63ae0245f40c6525f4bd9",
    "text": "What is the Markov Decision Process (MDP)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe an MDP as a mathematical framework for modeling decision-making. It must mention the key components: states, actions, transition probabilities, and rewards, and the core Markov property (the future is independent of the past given the present).",
    "rubric_id": ""
  },
  {
    "id": "0f7974b53d16f37ae95e6d395000ba650066b4535012c62a0dcf897dd8a2ae17",
    "text": "What is policy gradient in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define policy gradient methods as a class of algorithms that directly optimize the agent's policy by adjusting its parameters in the direction that increases expected rewards.",
    "rubric_id": ""
  },
  {
    "id": "4d3525cb5d733382824c6832c78a2be927b9c2db06f9fedb34f0572219609c08",
    "text": "What is a convolutional neural network (CNN)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a CNN as a type of deep learning model specialized for processing grid-like data, such as images. It should mention the use of convolutional layers to automatically learn and extract hierarchical features.",
    "rubric_id": ""
  },
  {
    "id": "8e1b2ac9e368185a026d3a88f371b91767b07ef1a566229e9505d831b5cf4a0a",
    "text": "What is data augmentation in deep learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should define data augmentation as a technique to artificially increase the size of a training dataset by creating modified versions of existing data. It must mention the purpose, which is to improve model generalization and reduce overfitting.",
    "rubric_id": ""
  },
  {
    "id": "4c5ed2a44a51d8bae9443489cb8773e9957414f288ce869bddc5fd9d28b758f0",
    "text": "What is sequence-to-sequence learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define sequence-to-sequence (seq2seq) models as a type of model that transforms an input sequence into an output sequence, where the sequences can be of different lengths. It should provide an example task like machine translation or text summarization.",
    "rubric_id": ""
  },
  {
    "id": "9b1ef747c921c85d1949211ec401f049511ce5a8dd4a94bc4aeac0a86af6bd60",
    "text": "What is attention mechanism in deep learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain the attention mechanism as a technique that allows a neural network to focus on specific parts of the input sequence when producing an output. This helps the model handle long sequences more effectively.",
    "rubric_id": ""
  },
  {
    "id": "134fac4b3eb37a6d3d1e8181348ad942f6ee3b16fd48f202a2836b58ffb4e4fa",
    "text": "What are some common optimization algorithms used in deep learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common optimizers. Look for mentions of Stochastic Gradient Descent (SGD), Adam, and RMSprop.",
    "rubric_id": ""
  },
  {
    "id": "de7ce88cbb75e09fea62c10a9928ef1f80b84dd8cddbb908a4891db4d2d8c98d",
    "text": "What is semi-supervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define semi-supervised learning as a machine learning approach that uses a combination of a small amount of labeled data and a large amount of unlabeled data for training.",
    "rubric_id": ""
  },
  {
    "id": "7584ba6abd5a8e6a0a09ac2b2148a54b2e29ad78403365095eaf0c4b7cbbc743",
    "text": "What is self-supervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define self-supervised learning as a type of unsupervised learning where the model generates its own labels from the input data. The goal is to learn representations that can be used for downstream tasks, often through a pretext task like predicting a masked word.",
    "rubric_id": ""
  },
  {
    "id": "74a7a6ce2dc0d82c221291cda38cb9abb8205b002820e367efd0f6bf9b278101",
    "text": "What is reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define reinforcement learning as an area of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a cumulative reward.",
    "rubric_id": ""
  },
  {
    "id": "faf8d4e82e5c55532f9c64519071aeea36bb79126144bcbd0718ea05f8291c6c",
    "text": "What is Q-learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Q-learning as a model-free reinforcement learning algorithm. It should explain that its goal is to learn a policy by learning a Q-function that estimates the value of taking a certain action in a certain state.",
    "rubric_id": ""
  },
  {
    "id": "9f12989d7e37551d56df44fb1564876ce3000dd7b3d58c5ecf95cbbb9de7932e",
    "text": "What is the exploration-exploitation tradeoff in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain the tradeoff as the dilemma between exploring the environment to discover new, potentially better actions (exploration) and sticking with the currently known best action to maximize immediate rewards (exploitation).",
    "rubric_id": ""
  },
  {
    "id": "b1166d48a8184bceede274d739df21707aa9f6845d486679662af9b2b984ad7a",
    "text": "What is the Bellman equation in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the Bellman equation as a fundamental concept that expresses the value of a state in terms of the immediate reward and the discounted value of future states. It forms the basis for many reinforcement learning algorithms.",
    "rubric_id": ""
  },
  {
    "id": "16fff09f7e9e9ef829e6a1ac736508d817a498c44ddc95e827e257aafdbabeac",
    "text": "What is the difference between on-policy and off-policy learning in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between the two learning types. On-policy methods learn from actions taken by the current policy being optimized. Off-policy methods learn from actions taken by a different policy (a behavior policy), allowing for more exploration.",
    "rubric_id": ""
  },
  {
    "id": "6ab7bb85bac33c31ec803f7373d3563e0ebaac9f7c949bf144e87e6280b55c77",
    "text": "What is data science?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define data science as an interdisciplinary field that uses scientific methods and algorithms to extract insights from structured and unstructured data. It should mention the combination of skills from statistics, computer science, and domain expertise.",
    "rubric_id": ""
  },
  {
    "id": "4d6f7af1103f29ca3afa308196f1d66576553cac4929b9ee7dcc73001c1c5b79",
    "text": "What are the main components of the data science process?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should outline the key stages of a typical data science workflow. Look for mentions of data collection, data cleaning/preprocessing, exploratory data analysis, modeling, and evaluation/deployment.",
    "rubric_id": ""
  },
  {
    "id": "95d54d9a3179415ad932fa832414d36c3ee0937699148b5dd4a0274d8c9450a0",
    "text": "What is the difference between supervised and unsupervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the data used. Supervised learning uses labeled data (input-output pairs) to train a model. Unsupervised learning uses unlabeled data to find patterns or structure within the data itself.",
    "rubric_id": ""
  },
  {
    "id": "9b9eb68558305ca415a313c396e79f22388aca179d032c7eca6f4e54ccc2cd9b",
    "text": "What is overfitting in machine learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define overfitting as a model that learns the training data too well, capturing noise and random fluctuations. It must state the main consequence: poor performance and generalization on new, unseen data.",
    "rubric_id": ""
  },
  {
    "id": "a7a4bd99f7ab39adcadc33da2f6d38cff7c61f3b7b7d49f4151f35b46d8f59b1",
    "text": "How do you handle missing data in a dataset?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common strategies for handling missing data. Look for mentions of removing rows/columns with missing values or imputing the missing values using statistical measures like the mean, median, or mode.",
    "rubric_id": ""
  },
  {
    "id": "f2e56bf378155223d17f71670d1e1e0b2b43e80536e953bee63468509f262d33",
    "text": "Explain the curse of dimensionality.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain the curse of dimensionality as the various problems that arise when working with high-dimensional data. Key issues to mention are data sparsity and increased computational complexity, which can degrade model performance.",
    "rubric_id": ""
  },
  {
    "id": "b39722abc5ee0ae0f9ed1ee04e6dff8c4436523033ef621a636f8233305bf74d",
    "text": "What is regularization in machine learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique used to prevent overfitting by adding a penalty term to the model's loss function. This penalty discourages the model from learning overly complex patterns.",
    "rubric_id": ""
  },
  {
    "id": "2eb1ed50981fc2bb5de8f135827a31bb486d03619a2d527f8a463b9be0611fe1",
    "text": "What is the purpose of cross-validation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the purpose of cross-validation is to get a more reliable estimate of a model's performance on unseen data. It should describe the process of splitting the data into multiple folds and training/testing on different combinations.",
    "rubric_id": ""
  },
  {
    "id": "c7593c562c863cebcb186fb47b8fee3f22c837cfe9e8bcd0f279197f5779f6da",
    "text": "What are some common algorithms used in supervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common supervised learning algorithms. Look for mentions of Linear/Logistic Regression, Decision Trees, Random Forests, Support Vector Machines (SVMs), and Neural Networks.",
    "rubric_id": ""
  },
  {
    "id": "cbd8ef7909e78fd89ba5817141b7e440909ed2d349603339061b77e1dfffdd56",
    "text": "What is the difference between classification and regression?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the type of output predicted. Classification predicts a discrete class label (e.g., 'spam' or 'not spam'). Regression predicts a continuous numerical value (e.g., house price).",
    "rubric_id": ""
  },
  {
    "id": "eb2524e589f3181edfe28f44d42993e63548cd25d897df9f83c33728fd6c096a",
    "text": "How does regularization prevent overfitting in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that regularization techniques like L1 and L2 add a penalty to the loss function based on the size of the network's weights. This discourages large weights, leading to a simpler, less overfit model.",
    "rubric_id": ""
  },
  {
    "id": "ff8abe6e3daafaf15653031f116c672890e623437b0f74d29f0e0851b497d927",
    "text": "What is the purpose of activation functions in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the primary purpose of activation functions is to introduce non-linearity into the network. This allows the model to learn complex patterns that a simple linear model cannot.",
    "rubric_id": ""
  },
  {
    "id": "3a7537ed9f6d6a18e3d4f4421e24001639af7bcf8fad9acedfc90522be89afde",
    "text": "What is the ROC curve?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the ROC curve as a plot of the True Positive Rate against the False Positive Rate at various threshold settings. It should state that the curve is used to evaluate the performance of a binary classification model.",
    "rubric_id": ""
  },
  {
    "id": "949b24dacc61559bd8670ea4f47ec2bd9447572f371a25969be4c414d4002b0f",
    "text": "What is the F1 score?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the F1 score as the harmonic mean of precision and recall. It should explain that this metric is useful for evaluating classifiers, especially when dealing with imbalanced classes.",
    "rubric_id": ""
  },
  {
    "id": "c8553a48951656111cbb63fb88fe131b433e0953c39049ee1078fbded2015a1c",
    "text": "What is the purpose of dimensionality reduction techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the purpose is to reduce the number of features in a dataset while retaining as much important information as possible. Key benefits to mention are reducing computational cost and mitigating the curse of dimensionality.",
    "rubric_id": ""
  },
  {
    "id": "432599f5a557a1ee5f85651d298c5b52f47b9645250965d1f28cbce491cfff44",
    "text": "Explain the difference between PCA and t-SNE.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate between the two techniques. Look for: PCA is a linear technique that maximizes variance, useful for general dimensionality reduction. t-SNE is a non-linear technique that preserves local similarities, primarily used for data visualization.",
    "rubric_id": ""
  },
  {
    "id": "81fa77c41e26963df01b5d99c0f2b79d880d1e768c27ea8c98191cdd25847f9a",
    "text": "What is K-means clustering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define K-means as an unsupervised clustering algorithm. It should explain the process: partitioning data into K clusters by iteratively assigning each data point to the nearest cluster centroid and then updating the centroid's position.",
    "rubric_id": ""
  },
  {
    "id": "f7924c5ef192eb710e2512dc49d2da5774b28c93b9fbd7695ad7dd26e76ad6cd",
    "text": "What is the elbow method used for in K-means clustering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the elbow method is a heuristic used to find the optimal number of clusters (K). It should describe the process of plotting the within-cluster sum of squares against K and identifying the 'elbow' point where the rate of decrease slows.",
    "rubric_id": ""
  },
  {
    "id": "fb314d5e23fc420b2c804065da04fc62a65aa3ad75f19b96a0c9ef32a4ed8d5c",
    "text": "What is outlier detection?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define outlier detection as the process of identifying data points that deviate significantly from the rest of the dataset. It should mention that these outliers can indicate anomalies or errors.",
    "rubric_id": ""
  },
  {
    "id": "eb2524e589f3181edfe28f44d42993e63548cd25d897df9f83c33728fd6c096a",
    "text": "How does regularization prevent overfitting in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that regularization techniques, such as L1 and L2, add a penalty based on the magnitude of the network weights to the loss function. This discourages overly complex models by constraining the weights, which helps prevent overfitting.",
    "rubric_id": ""
  },
  {
    "id": "ff8abe6e3daafaf15653031f116c672890e623437b0f74d29f0e0851b497d927",
    "text": "What is the purpose of activation functions in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that activation functions introduce non-linearity into a neural network. This is crucial for allowing the network to learn complex patterns and relationships in the data beyond what a simple linear model can capture.",
    "rubric_id": ""
  },
  {
    "id": "539d84d6308cf113096f85f1f95780ee9465e9e8a1527d2db5a29febe46df885",
    "text": "What are the advantages of deep learning over traditional machine learning algorithms?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should highlight key advantages of deep learning. Look for mentions of automatic feature extraction from raw data (like images or text) and its ability to achieve state-of-the-art performance on large, complex datasets.",
    "rubric_id": ""
  },
  {
    "id": "5bc7303e05f27e98db30d514fbd151230ab56655fe02deeee3f747b3e7fc27df",
    "text": "What is backpropagation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define backpropagation as the algorithm used to train neural networks. It should explain the process of calculating the gradient of the loss function with respect to the network's weights and then using this gradient to update the weights to minimize the error.",
    "rubric_id": ""
  },
  {
    "id": "d2d787742ae1b1c45a5936a3d9b185f9f80b68f5e31e949ce88212e58c66e187",
    "text": "What is transfer learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define transfer learning as the technique of reusing a model that was pre-trained on a large dataset for a new, related task. It should state the main benefits: faster training and better performance, especially with limited data for the new task.",
    "rubric_id": ""
  },
  {
    "id": "920451bc41aea641ac7537d01df77f4ee49b9ee4eded9ff5be3db6ac4d150ac6",
    "text": "How do you evaluate the performance of a regression model?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common evaluation metrics for regression tasks. Check for mentions of Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared.",
    "rubric_id": ""
  },
  {
    "id": "4acf1a66c95af82550e1c82c3e1d24814a8a96b06816513b15f18c020e9d65d9",
    "text": "What is the purpose of the A/B test in data science?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define A/B testing as a statistical method for comparing two versions (A and B) of something to determine which one performs better on a given metric. It should provide a use case, such as testing different versions of a webpage to see which one has a higher conversion rate.",
    "rubric_id": ""
  },
  {
    "id": "52a2705e762bd68d1d055d56e207ed426bdd40f357fda8f4f1c8cce2e67f406a",
    "text": "What is the Central Limit Theorem?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state the core idea of the Central Limit Theorem: that the distribution of sample means will approximate a normal distribution as the sample size gets larger, regardless of the population's original distribution.",
    "rubric_id": ""
  },
  {
    "id": "fb06f819fb2cf529b18f519fc8765de5fd7fcb5c0dcedf8fd7f2d58b9ba9e61e",
    "text": "What is the difference between correlation and causation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clearly distinguish the two concepts. Correlation indicates a relationship between two variables, but it does not imply that one causes the other. Causation means that a change in one variable is directly responsible for a change in another. The key phrase to look for is 'correlation does not imply causation.'",
    "rubric_id": ""
  },
  {
    "id": "520bd20dc6125527e637e63308666fea6d6e39cb0465a51cfc597a0e44bdb36f",
    "text": "What is Bayesian inference?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should define Bayesian inference as a statistical method that uses Bayes' theorem to update the probability of a hypothesis based on new evidence. It must mention the use of prior knowledge in the analysis.",
    "rubric_id": ""
  },
  {
    "id": "a3dcdccc804ba2c9186eff706dfd0bed2c1a660aa03b6024cf49a867f95821b3",
    "text": "What is the purpose of hypothesis testing?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that hypothesis testing is a statistical method used to make decisions about a population based on sample data. It should mention the process of testing a null hypothesis against an alternative hypothesis.",
    "rubric_id": ""
  },
  {
    "id": "eb40c3ec7cef05c745313080fc7ff2851aee99f9bd9fb37f6aaba9e3b2bca4af",
    "text": "What is regularization in linear regression?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting by adding a penalty term to the loss function. It should name the common types: Ridge (L2 regularization) and Lasso (L1 regularization).",
    "rubric_id": ""
  },
  {
    "id": "5dab342b8dc6721149630989c13cf3005264c1cc6efaa4dc4c60cf15d64bdcd6",
    "text": "What are the assumptions of linear regression?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list the key assumptions of linear regression. Look for mentions of linearity, independence of errors, homoscedasticity (constant variance of errors), and normality of errors.",
    "rubric_id": ""
  },
  {
    "id": "fc1be89fc9ae3d60a5c0af0f2250a274ecdc1f60064a0d1ccc8ba08d1344f85a",
    "text": "What is the difference between Type I and Type II errors?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly define both types of errors in hypothesis testing. A Type I error is a false positive (rejecting a true null hypothesis). A Type II error is a false negative (failing to reject a false null hypothesis).",
    "rubric_id": ""
  },
  {
    "id": "7945abb7db00f714d4f9998cfe523cd5da917799deac078b9c7e8d6796969aed",
    "text": "What is the p-value in hypothesis testing?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the p-value as the probability of observing results as extreme as the current results, assuming the null hypothesis is true. It should also state that a small p-value (typically < 0.05) is evidence against the null hypothesis.",
    "rubric_id": ""
  },
  {
    "id": "ecc7c2fa1eee94055b405da910e8966f88ea587502d1ccce445831f7387ece99",
    "text": "What is the bias-variance tradeoff?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both bias (error from overly simple assumptions) and variance (error from sensitivity to small fluctuations in training data). It must explain their inverse relationship and the goal of finding a balance to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "67555e3843220416dec5e1871d154043314ddafabb019ba62c0bdbe6131be529",
    "text": "What is the difference between bagging and boosting?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the two ensemble methods. Bagging involves training multiple models in parallel on different subsets of the data and averaging their predictions. Boosting involves training models sequentially, where each new model focuses on correcting the errors of the previous ones.",
    "rubric_id": ""
  },
  {
    "id": "f105331f54ac47f2304b8d212bee14852965deabcb2ab5d2d2334ec908ef61cc",
    "text": "What is the purpose of cross-validation in model evaluation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the purpose of cross-validation is to obtain a more reliable estimate of a model's performance on unseen data. It should describe the process of splitting the data into multiple folds and using different folds for training and validation to reduce variance in the performance estimate.",
    "rubric_id": ""
  },
  {
    "id": "61f36232d8ea52aa537dd8d2da07966bdc238fd45f3540ade0f01bfe77bfdb3e",
    "text": "What is the difference between stratified sampling and random sampling?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on how subgroups are handled. Random sampling selects individuals randomly from the entire population. Stratified sampling divides the population into subgroups (strata) and then takes a random sample from each stratum, ensuring representation of all groups.",
    "rubric_id": ""
  },
  {
    "id": "e1b7f0b31734aa63ebfecc04b99a0347d60a5a40cae3c32328d30d3b5db3f139",
    "text": "What is ensemble learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define ensemble learning as a technique that combines the predictions of multiple machine learning models to improve overall performance and robustness compared to a single model.",
    "rubric_id": ""
  },
  {
    "id": "bc3d54e53db1645e91af2ad1f84fa4cec6f5b9ec2047cf08a830edf42fb8ce7e",
    "text": "What is the difference between variance and standard deviation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both terms as measures of data dispersion. The key distinction is that the standard deviation is the square root of the variance and is expressed in the same units as the original data, making it more interpretable.",
    "rubric_id": ""
  },
  {
    "id": "8486c20424d1a3c27b4ee287c6a7eee625e80ebe71f95dbae7dc7bef19506a23",
    "text": "What is the difference between a decision tree and a random forest?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify a random forest as an ensemble of multiple decision trees. It should explain that this ensemble approach helps to reduce overfitting and generally results in better performance than a single decision tree.",
    "rubric_id": ""
  },
  {
    "id": "120880fd3c67150d1356e244b2b3c100769fe60ed268c1b6387330096ba074d9",
    "text": "What is the difference between batch gradient descent and stochastic gradient descent?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the amount of data used for each update. Batch gradient descent uses the entire training dataset for each weight update, which is slow but accurate. Stochastic gradient descent (SGD) updates weights after each single training example, which is faster but more noisy.",
    "rubric_id": ""
  },
  {
    "id": "00e575522f85140b44ff15d08d294e759027e7fdd8d3fe90b20768b6f0a1e192",
    "text": "What is the role of activation functions in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the primary role of activation functions is to introduce non-linearity into the network. This allows the model to learn and represent more complex patterns and relationships in the data.",
    "rubric_id": ""
  },
  {
    "id": "704cb6db5a926898508cb90bccb3950884fc9689416b37f8d76444cc3008f57a",
    "text": "What is dropout regularization in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define dropout as a regularization technique to prevent overfitting. It should explain the process of randomly setting a fraction of neuron activations to zero during training, which forces the network to learn more robust features.",
    "rubric_id": ""
  },
  {
    "id": "15988670d8123726d59b943dd95fb751b2af788a561896ce8cddd50939a8b23f",
    "text": "What is batch normalization in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define batch normalization as a technique to normalize the inputs of each layer to have a mean of zero and a variance of one. It should state that this helps to speed up training and stabilize the learning process.",
    "rubric_id": ""
  },
  {
    "id": "d884853e51caea43abe6e37585d3a92f1803fff9cf4ba0bd6be13dfffc76c1d0",
    "text": "What is the difference between L1 and L2 regularization?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the penalty term. L1 regularization (Lasso) adds a penalty equal to the absolute value of the weights, which can lead to sparse models by driving some weights to zero. L2 regularization (Ridge) adds a penalty equal to the square of the weights, which encourages smaller weights.",
    "rubric_id": ""
  },
  {
    "id": "caf11303576a8b8a441e5a6b3d24fcd8f4be04128a167087be3d57cee1d731a0",
    "text": "What is the purpose of a confusion matrix in classification?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that a confusion matrix is used to evaluate the performance of a classification model. It should describe the matrix as a table showing the counts of true positives, true negatives, false positives, and false negatives.",
    "rubric_id": ""
  },
  {
    "id": "8f3e93363e19c4490b2f2cdf6551680cd78d17c472b9e79029cfa2a2c1621ceb",
    "text": "What is the softmax function?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the softmax function as an activation function typically used in the output layer of a multi-class classification network. It should explain that it converts a vector of raw scores (logits) into a probability distribution where the sum of the probabilities is 1.",
    "rubric_id": ""
  },
  {
    "id": "b3b9cc80b9f9e217a960276fcffbb51cc9779d4bb0f81de4a110ada92a5af4fa",
    "text": "What is the Kullback-Leibler (KL) divergence?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define KL divergence as a measure of how one probability distribution differs from a second, reference probability distribution. It should note that it is not a true distance metric as it is not symmetric.",
    "rubric_id": ""
  },
  {
    "id": "11966d60e3f2099d4602d605fb38d6af052ed02cd232d13d217fad2e639df96f",
    "text": "What is the difference between batch normalization and layer normalization in neural networks?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the dimension of normalization. Batch normalization normalizes across the batch dimension for each feature. Layer normalization normalizes across the feature dimension for each data point in the batch, making it more suitable for RNNs.",
    "rubric_id": ""
  },
  {
    "id": "30fd6033be5c73c7d3c468121aa9393cc8f0776550b29d2aea4d8152e4c09a72",
    "text": "What is unsupervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define unsupervised learning as a type of machine learning that uses unlabeled data. The goal is to find hidden patterns, structures, or relationships within the data itself, without explicit guidance on the correct output.",
    "rubric_id": ""
  },
  {
    "id": "d58d0bb9cadd9b479dbcecc157739181f6871bb2e6c01ae5fdf08c67342e2a5d",
    "text": "What are the main types of unsupervised learning techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list the primary categories of unsupervised learning. Look for mentions of clustering, dimensionality reduction, and association rule learning.",
    "rubric_id": ""
  },
  {
    "id": "8ff53a070723d4b448d1dc7b15600db897733bae167a4b11e14ec299c54fd892",
    "text": "What is clustering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define clustering as an unsupervised learning task of grouping a set of data points such that points in the same group (cluster) are more similar to each other than to those in other groups.",
    "rubric_id": ""
  },
  {
    "id": "527681c07e3109c0449849c40b95639d7145d45ac209d5b819cd692aaac9269d",
    "text": "What are the common clustering algorithms?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common clustering algorithms. Check for mentions of K-means, Hierarchical clustering, and DBSCAN.",
    "rubric_id": ""
  },
  {
    "id": "81fa77c41e26963df01b5d99c0f2b79d880d1e768c27ea8c98191cdd25847f9a",
    "text": "What is K-means clustering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define K-means as an iterative clustering algorithm that partitions data into K clusters. It should explain the process of assigning data points to the nearest cluster centroid and then re-calculating the centroids.",
    "rubric_id": ""
  },
  {
    "id": "781e8180f7169cc7de61715d9bfe7dfb0ac1d16455ac28ad0b9e9dd2bccdfe7e",
    "text": "What is hierarchical clustering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define hierarchical clustering as an algorithm that builds a hierarchy of clusters. It should differentiate between agglomerative (bottom-up) and divisive (top-down) approaches.",
    "rubric_id": ""
  },
  {
    "id": "feb746f4db80342a7378158218ac3cb6000d126ee64f6e826b476c3edfeacd83",
    "text": "What is DBSCAN clustering?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define DBSCAN as a density-based clustering algorithm. It should explain that it groups together points that are closely packed, marking outliers as noise, and can find arbitrarily shaped clusters.",
    "rubric_id": ""
  },
  {
    "id": "d0ed62cbc97a4ef3d118e096832e29e2ba08823c2857cc6829b0e02b04d20484",
    "text": "What is dimensionality reduction?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define dimensionality reduction as the process of reducing the number of features in a dataset. It should mention the goals: to simplify the model, reduce computational cost, and avoid the curse of dimensionality.",
    "rubric_id": ""
  },
  {
    "id": "539bdf6a7f82e6210b125488886017c5fd624ed7e3f6196c76669a3ec225b70e",
    "text": "What are the common dimensionality reduction techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common techniques for dimensionality reduction. Check for mentions of Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE).",
    "rubric_id": ""
  },
  {
    "id": "a6c26dd89cf8d746b189827507981189e50e648138085ce03908cd11f9f3fab7",
    "text": "What is PCA (Principal Component Analysis)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a linear dimensionality reduction technique. It should explain that PCA transforms the data into a new coordinate system of principal components, which are orthogonal and capture the maximum variance in the data.",
    "rubric_id": ""
  },
  {
    "id": "992422734643c38d5669f56083e6bcb7db321ba81f14c0b62e8b51b7af1d5118",
    "text": "What is t-SNE (t-Distributed Stochastic Neighbor Embedding)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define t-SNE as a non-linear technique for dimensionality reduction. It should emphasize that its primary use is for visualizing high-dimensional data by preserving the local structure and similarities between data points in a low-dimensional space.",
    "rubric_id": ""
  },
  {
    "id": "542734f50bb2c721d8a6e0b6986119595da9ffa5bce22a65a3d091883a3d1a2d",
    "text": "What is Singular Value Decomposition (SVD)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define SVD as a matrix factorization technique. It should explain that SVD decomposes a matrix into three other matrices and is a fundamental technique used in applications like PCA and recommendation systems.",
    "rubric_id": ""
  },
  {
    "id": "b42318b2fedb724c810930e6e3d80fcfafd4e6c51447794938e0200c653ff36b",
    "text": "What is association rule learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define association rule learning as an unsupervised method for discovering interesting relationships between variables in large datasets. It should provide the classic example of market basket analysis (e.g., 'if a customer buys bread, they are likely to also buy milk').",
    "rubric_id": ""
  },
  {
    "id": "bb4441e7f18405c4fd33b3029b016f2fb7879bdf8cc41783eb7794a44b1c0c5c",
    "text": "What are the common association rule learning algorithms?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list the most common algorithms for association rule mining. Check for mentions of the Apriori and FP-Growth algorithms.",
    "rubric_id": ""
  },
  {
    "id": "b6bb376c411307d0aa08d37571736139281ebadaffd4ebc0a2e477645f7cae09",
    "text": "What is the Apriori algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the Apriori algorithm as a classic method for mining frequent itemsets. It should explain the core 'Apriori property': if an itemset is frequent, then all of its subsets must also be frequent.",
    "rubric_id": ""
  },
  {
    "id": "69250d100b10886ba098db8799a77a2d64880077934172a8f442a70cc621cd21",
    "text": "What is FP-Growth?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define FP-Growth as an efficient algorithm for mining frequent itemsets. It should explain that, unlike Apriori, it avoids the costly candidate generation step by using a compact data structure called an FP-tree.",
    "rubric_id": ""
  },
  {
    "id": "25acd3b055fad59530e432c34ff8d7205f74a005d998f571b25873a508545522",
    "text": "What is anomaly detection?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define anomaly detection (or outlier detection) as the process of identifying data points or events that do not conform to the expected pattern of a dataset. It should mention use cases like fraud detection or network intrusion detection.",
    "rubric_id": ""
  },
  {
    "id": "24089d4cf3e0707748b69b0fffe7eda71de2597fcb603cde1f831fae40b9b6f1",
    "text": "What are the common anomaly detection techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common techniques for anomaly detection. Look for mentions of statistical methods (like z-score), density-based methods (like DBSCAN), and algorithms like Isolation Forest or One-Class SVM.",
    "rubric_id": ""
  },
  {
    "id": "b5caebee84a146cdc61e6a741f6cbb142313a28d131ed28e1a7b4df8c86d9494",
    "text": "What is Isolation Forest?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Isolation Forest as an unsupervised algorithm for anomaly detection. It should explain the core idea: anomalies are 'few and different' and are therefore easier to isolate by random partitioning of the data.",
    "rubric_id": ""
  },
  {
    "id": "7c007a92487d8a9cc3a1b8727022edf4bbd6212429ad7f9672712309e9d9d542",
    "text": "What is One-Class SVM?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define One-Class SVM as a variation of Support Vector Machines used for anomaly detection. It should explain that the algorithm learns a boundary around the 'normal' data points, and any points outside this boundary are considered anomalies.",
    "rubric_id": ""
  },
  {
    "id": "c0270da1e77ae447f7ab3f40dc3d9b5c9faa7bc072f64a0cd57c15942a045e34",
    "text": "What is the purpose of density estimation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the purpose of density estimation is to estimate the underlying probability density function of a dataset. This is useful for tasks like anomaly detection and generative modeling.",
    "rubric_id": ""
  },
  {
    "id": "43446d4d247a3fd70c9afe6365e9b722696453d4a8cfbeeafdef15fe00d1684d",
    "text": "What are the common density estimation techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common density estimation techniques. Check for mentions of histograms, Kernel Density Estimation (KDE), and Gaussian Mixture Models (GMM).",
    "rubric_id": ""
  },
  {
    "id": "922cd9d496dfdec1b85f0fd768f3d27c3d8ad2c3d9b87a334e4926c1edb62aac",
    "text": "What is the Gaussian Mixture Model (GMM)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a GMM as a probabilistic model that assumes the data is generated from a mixture of a finite number of Gaussian distributions. It should mention that GMMs are often used for clustering and density estimation.",
    "rubric_id": ""
  },
  {
    "id": "234ffc0ffe278c020613fed0f852df7f1a6828c6b8e866e6fb88eea6eb8c831f",
    "text": "What is the Expectation-Maximization (EM) algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the EM algorithm as an iterative method for finding maximum likelihood estimates of parameters in statistical models with latent (hidden) variables. It should mention that it's commonly used to train Gaussian Mixture Models.",
    "rubric_id": ""
  },
  {
    "id": "df185a46257e0216b14370a4ee1f51d61a6ef769aacb46794199b38680ef9f79",
    "text": "What is the difference between generative and discriminative models?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on what each model learns. Generative models learn the joint probability distribution of the data and can generate new data samples. Discriminative models learn the conditional probability or the decision boundary between classes.",
    "rubric_id": ""
  },
  {
    "id": "26eb9daf0d3779f2ca4be4b902b1e3cebb96f0e135ba251e36231a3969ca922e",
    "text": "What is the purpose of generative modeling?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the purpose of generative modeling is to learn the underlying distribution of a dataset in order to generate new, synthetic data samples that resemble the original data. It should mention applications like image or text generation.",
    "rubric_id": ""
  },
  {
    "id": "dad004d353263323d1711ac87d68cb236505dfaeebfbcd05fa3de7ab4c5d85d0",
    "text": "What are the common generative modeling techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common generative models. Check for mentions of Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs).",
    "rubric_id": ""
  },
  {
    "id": "80444afc3cc799c3bdf596f1493776a0e3561987b3032aa8936584aa57bdda36",
    "text": "What is a Variational Autoencoder (VAE)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a VAE as a type of generative model. It should explain that it uses an encoder-decoder architecture to learn a compressed, probabilistic latent representation of the data, which can then be sampled to generate new data.",
    "rubric_id": ""
  },
  {
    "id": "0db20edc71d027982bf44af89503bb91d32a476952ecf7d8e05e34030f3010a3",
    "text": "What is a Generative Adversarial Network (GAN)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a GAN as a generative model consisting of two competing neural networks: a generator that creates synthetic data and a discriminator that tries to distinguish between real and synthetic data. The two are trained together in an adversarial process.",
    "rubric_id": ""
  },
  {
    "id": "c583798b85d8ff87f2bad299ef118419dccde8aa0ba778118fb6f32a7dbf0d94",
    "text": "What is a Restricted Boltzmann Machine (RBM)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an RBM as a generative stochastic neural network. It should explain its structure of visible and hidden layers and mention its use in tasks like feature learning and collaborative filtering.",
    "rubric_id": ""
  },
  {
    "id": "8336b2924b6e348febe2b1552d8804906fa712c0ad96210b6362c1aad21a12f0",
    "text": "What is the purpose of self-organizing maps (SOMs)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that Self-Organizing Maps are a type of unsupervised neural network used for dimensionality reduction and visualization. The key concept to mention is that they map high-dimensional data onto a low-dimensional grid while preserving the topological structure of the data.",
    "rubric_id": ""
  },
  {
    "id": "95c5c82f9e8e19319c01944654ea0d02234e7ba7c2341c0da9a148dd1f20003c",
    "text": "What is the difference between generative and discriminative clustering algorithms?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should differentiate based on the underlying approach. Generative clustering algorithms, like GMMs, model the probability distribution of each cluster. Discriminative algorithms, like K-means, directly try to find the boundaries between clusters.",
    "rubric_id": ""
  },
  {
    "id": "5e7144e510a392418320cd89b56b4eda8f7ccab1f47b31cfe874b760d90fb346",
    "text": "What is the purpose of data preprocessing in unsupervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that data preprocessing is crucial for preparing raw data for unsupervised algorithms. It should mention key steps like feature scaling and handling missing values, which are often necessary because these algorithms are sensitive to the scale and quality of the input data.",
    "rubric_id": ""
  },
  {
    "id": "c8bd25a49882c0a0fc79d5b3f86ffc1bb2ed14a93e5beb4f5141d325764af7ad",
    "text": "What are the common data preprocessing techniques in unsupervised learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common preprocessing techniques. Check for mentions of feature scaling (normalization or standardization), handling missing values, encoding categorical features, and potentially dimensionality reduction.",
    "rubric_id": ""
  },
  {
    "id": "1991a40bbda8fbca7644d1efad2f609309091f435feed6c4923e6d12c2075016",
    "text": "What is feature scaling?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define feature scaling as the process of transforming the range of features to a similar scale. It should explain that this is important for distance-based algorithms like K-means, where features with larger ranges can dominate the distance calculation.",
    "rubric_id": ""
  },
  {
    "id": "d7bed308b958bece20fefcab2864541d175d7a659e5cda6adaf2bb3fdab1a34a",
    "text": "What is feature encoding?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define feature encoding as the process of converting categorical features into a numerical format that can be used by machine learning algorithms. It should provide examples like one-hot encoding or label encoding.",
    "rubric_id": ""
  },
  {
    "id": "25acd3b055fad59530e432c34ff8d7205f74a005d998f571b25873a508545522",
    "text": "What is anomaly detection?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define anomaly detection as the task of identifying data points that are rare and significantly different from the majority of the data. It should provide a use case like fraud detection or identifying defective products.",
    "rubric_id": ""
  },
  {
    "id": "24089d4cf3e0707748b69b0fffe7eda71de2597fcb603cde1f831fae40b9b6f1",
    "text": "What are the common anomaly detection techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common techniques. Check for mentions of statistical methods, density-based approaches (like DBSCAN), and algorithms specifically designed for this task, such as Isolation Forest and One-Class SVM.",
    "rubric_id": ""
  },
  {
    "id": "b5caebee84a146cdc61e6a741f6cbb142313a28d131ed28e1a7b4df8c86d9494",
    "text": "What is Isolation Forest?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Isolation Forest as an unsupervised algorithm for anomaly detection. It should explain the core principle: anomalies are 'few and different,' making them easier to isolate through random partitioning of the data.",
    "rubric_id": ""
  },
  {
    "id": "7c007a92487d8a9cc3a1b8727022edf4bbd6212429ad7f9672712309e9d9d542",
    "text": "What is One-Class SVM?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define One-Class SVM as a version of Support Vector Machine used for anomaly detection. It should explain that the algorithm learns a boundary that encloses the 'normal' data points, and any point falling outside this boundary is flagged as an anomaly.",
    "rubric_id": ""
  },
  {
    "id": "c0270da1e77ae447f7ab3f40dc3d9b5c9faa7bc072f64a0cd57c15942a045e34",
    "text": "What is the purpose of density estimation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that density estimation is the process of constructing an estimate of an unobservable underlying probability density function based on observed data. It's useful for tasks like anomaly detection and generative modeling.",
    "rubric_id": ""
  },
  {
    "id": "43446d4d247a3fd70c9afe6365e9b722696453d4a8cfbeeafdef15fe00d1684d",
    "text": "What are the common density estimation techniques?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common techniques for density estimation. Look for mentions of histograms, Kernel Density Estimation (KDE), and Gaussian Mixture Models (GMM).",
    "rubric_id": ""
  },
  {
    "id": "922cd9d496dfdec1b85f0fd768f3d27c3d8ad2c3d9b87a334e4926c1edb62aac",
    "text": "What is the Gaussian Mixture Model (GMM)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a GMM as a probabilistic model that assumes the data is generated from a mixture of several Gaussian distributions. It should mention its use for both density estimation and clustering.",
    "rubric_id": ""
  },
  {
    "id": "234ffc0ffe278c020613fed0f852df7f1a6828c6b8e866e6fb88eea6eb8c831f",
    "text": "What is the Expectation-Maximization (EM) algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the EM algorithm as an iterative method for finding maximum likelihood estimates of parameters in models with latent (hidden) variables. It should specify that it is commonly used for training Gaussian Mixture Models.",
    "rubric_id": ""
  },
  {
    "id": "74a7a6ce2dc0d82c221291cda38cb9abb8205b002820e367efd0f6bf9b278101",
    "text": "What is reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define reinforcement learning as an area of machine learning where an agent learns to make optimal decisions by interacting with an environment and receiving feedback in the form of rewards or punishments.",
    "rubric_id": ""
  },
  {
    "id": "d37d2b15ccad2dff44cdd27abb5a77167dcfd16cd57df645ded71dfb86ee8a56",
    "text": "What are the main components of reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list the key components of an RL system. Check for mentions of the agent, the environment, states, actions, and rewards.",
    "rubric_id": ""
  },
  {
    "id": "a0de17ae2d040d062158bdc0390b65a3c7b3ff2dac09c1f691dea047d90567bf",
    "text": "What is an agent in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the agent as the learner or decision-maker in a reinforcement learning setup. It is the entity that takes actions in the environment.",
    "rubric_id": ""
  },
  {
    "id": "418a076e00a7fe86cf4a5f58c2d77fc9e2cc462bf5977eed7a9e6128c48b270f",
    "text": "What is an environment in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the environment as the external system that the agent interacts with. It receives the agent's actions and returns the next state and a reward.",
    "rubric_id": ""
  },
  {
    "id": "3bb5d55e75c423ae73a805f13eee50af8e0fbbe4cab2871eb1e947bb3682ee4f",
    "text": "What is a state in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a state as a representation of the current situation of the environment. It provides the information the agent uses to decide its next action.",
    "rubric_id": ""
  },
  {
    "id": "6c1539b18703b0c599ebf67aba59a02f9aeada043a0c073a49d5f114f34831ec",
    "text": "What is an action in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an action as a choice or decision made by the agent, which influences the state of the environment.",
    "rubric_id": ""
  },
  {
    "id": "93f45540e0d7bf3e6676c0dfd283a3aaba17f993595512a6512f0a06a1e53144",
    "text": "What is a reward in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a reward as the feedback signal from the environment that indicates how good the agent's action was. The agent's goal is to maximize the cumulative reward.",
    "rubric_id": ""
  },
  {
    "id": "2394051327abdece1661e70390c74248cd255e23e06304c01aba6f16488be49e",
    "text": "What is the policy in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the policy as the agent's strategy. It maps states to actions and dictates what action the agent will take in a given state.",
    "rubric_id": ""
  },
  {
    "id": "c805c8c04af01430883b0a515a3ec06b471cb27db0d33e94cd0ba8e9dcc3a69a",
    "text": "What is exploration in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define exploration as the act of trying out new actions to discover more about the environment and find potentially better rewards.",
    "rubric_id": ""
  },
  {
    "id": "2394051327abdece1661e70390c74248cd255e23e06304c01aba6f16488be49e",
    "text": "What is the policy in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the policy as the strategy the agent uses to decide which action to take in a given state. It is essentially the 'brain' of the agent.",
    "rubric_id": ""
  },
  {
    "id": "c805c8c04af01430883b0a515a3ec06b471cb27db0d33e94cd0ba8e9dcc3a69a",
    "text": "What is exploration in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define exploration as the process of an agent trying new or random actions to learn more about the environment and discover potentially better strategies, rather than always choosing the known best action.",
    "rubric_id": ""
  },
  {
    "id": "9a6cde89948655d98564f57d5d74851431e320aeaa8393ba10c322e708e7015f",
    "text": "What is exploitation in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define exploitation as the agent choosing the action that it currently believes will yield the highest reward, based on its past experience.",
    "rubric_id": ""
  },
  {
    "id": "eb27935fe0b47f08f57bb047d2a80fbbaf13a48ec67d7be85f7c32e8316dd4cc",
    "text": "What is the exploration-exploitation trade-off in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain the trade-off as the fundamental dilemma in reinforcement learning: choosing between exploring the environment to find new information (exploration) and using the currently known best strategy to maximize immediate rewards (exploitation).",
    "rubric_id": ""
  },
  {
    "id": "714c6590ae33cae77db3696a09f79ab9f5ea42506de60b1019c4677c4af3d8e2",
    "text": "What are the common algorithms used in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common reinforcement learning algorithms. Check for mentions of Q-learning, SARSA, and Deep Q-Networks (DQN).",
    "rubric_id": ""
  },
  {
    "id": "faf8d4e82e5c55532f9c64519071aeea36bb79126144bcbd0718ea05f8291c6c",
    "text": "What is Q-learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Q-learning as a model-free, off-policy reinforcement learning algorithm. It should explain that the goal is to learn a Q-function, which estimates the value of taking a certain action in a certain state, to find the optimal policy.",
    "rubric_id": ""
  },
  {
    "id": "d1d092c11daf267f17c8144e85745d9516e10a1e244a37a5dee1c887074f81a7",
    "text": "What is SARSA?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define SARSA as a model-free, on-policy reinforcement learning algorithm. It should be contrasted with Q-learning by explaining that SARSA updates its Q-values based on the action actually taken by the current policy.",
    "rubric_id": ""
  },
  {
    "id": "35bc8d635237a50fab0d1fb5fd067014a831733aa13e1b95ba44e3ea15a4f1a2",
    "text": "What are Deep Q-Networks (DQN)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define DQN as a reinforcement learning algorithm that uses a deep neural network to approximate the Q-function. This allows Q-learning to be applied to problems with high-dimensional state spaces, like video games.",
    "rubric_id": ""
  },
  {
    "id": "75fb9878fa0b50a1f48cfc447322b81d5b7cf48c8e9f239683c941bfa3bda6b4",
    "text": "What are Policy Gradient methods?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define policy gradient methods as a class of reinforcement learning algorithms that directly learn and optimize a parameterized policy, without needing to learn a value function first.",
    "rubric_id": ""
  },
  {
    "id": "aff01364496a0e2ad2b112600ce5d8ece682335161cdd3f1dc7976a024d9a1dd",
    "text": "What are Actor-Critic methods?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Actor-Critic methods as a class of reinforcement learning algorithms that combine both policy-based (Actor) and value-based (Critic) methods. The Actor learns the policy, and the Critic evaluates the actions taken by the Actor.",
    "rubric_id": ""
  },
  {
    "id": "e096d3939b0d5370aee5b95ca68393355a5ff861599d01c0e7c8b1b8d86d211f",
    "text": "What is the Bellman equation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the Bellman equation as a fundamental concept in reinforcement learning. It should explain that the equation decomposes the value of a state into the immediate reward plus the discounted value of future states, forming the basis for many RL algorithms.",
    "rubric_id": ""
  },
  {
    "id": "3f8969596639c3959abc03b45d05dde81f7a499ba9c63ae0245f40c6525f4bd9",
    "text": "What is the Markov Decision Process (MDP)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an MDP as the mathematical framework for modeling reinforcement learning problems. It must list the key components (states, actions, transition probabilities, rewards) and mention the crucial Markov property, where the future depends only on the present state and action.",
    "rubric_id": ""
  },
  {
    "id": "cd80753fba0627f1418b9d78587c02ac28c29251b5baf1d8bea011ae659f6711",
    "text": "What is the Markov property?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the Markov property means the future is independent of the past, given the present. In RL terms, the next state and reward depend only on the current state and the action taken, not on the entire history of states and actions.",
    "rubric_id": ""
  },
  {
    "id": "8f88312f51a36eb886f726e56eaafd8b1ef4e71fb5b89743170f0a39f8dc83b7",
    "text": "What is the value function in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the value function as an estimate of the expected cumulative future reward from a given state. It guides the agent's decisions by indicating how good it is to be in a particular state.",
    "rubric_id": ""
  },
  {
    "id": "e624c44d0b241ca8baed02b739f62b8fed7567b3dccc10e26046a513ab68927b",
    "text": "What is the policy iteration algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe policy iteration as an algorithm for finding an optimal policy. It should explain the two alternating steps: policy evaluation (calculating the value function for the current policy) and policy improvement (updating the policy to be greedy with respect to the value function).",
    "rubric_id": ""
  },
  {
    "id": "b14f113342a77f4cdf2a5a9fe15af1122b55b16676d816bbdc31f746e65bded1",
    "text": "What is the value iteration algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define value iteration as an algorithm for finding the optimal value function. It should explain that it works by iteratively applying the Bellman update to the value estimates until they converge to the optimal values.",
    "rubric_id": ""
  },
  {
    "id": "9144abb66eaaf6f437ffc32ab8800ddd145b6414e442107f17afcd505447d2ba",
    "text": "What is temporal difference (TD) learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define TD learning as a model-free reinforcement learning method. It should explain the core idea of updating value estimates based on the difference between the current estimate and a new estimate derived from the immediate reward and the value of the next state (bootstrapping).",
    "rubric_id": ""
  },
  {
    "id": "1f77df010b65f5f6c2e6b0f5fe4d6141d5271e6b0478815fbc7f34b9b9655ff9",
    "text": "What is Monte Carlo reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Monte Carlo methods as a way to learn value functions by averaging the returns from complete episodes of interaction. It should be contrasted with TD learning by noting that MC methods wait until the end of an episode to make updates.",
    "rubric_id": ""
  },
  {
    "id": "24bb8c1f86a31e89f96a4914e23041dc1387519bb79c4e9919b0ebb1dab47f9d",
    "text": "What is the eligibility trace?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an eligibility trace as a mechanism in reinforcement learning that combines aspects of TD and Monte Carlo methods. It should explain that it assigns credit for a reward to all preceding states and actions, with credit decaying over time.",
    "rubric_id": ""
  },
  {
    "id": "03278ce0e0329f796a7dad343f9f1b7791919bc7d333596e5d39139929d6e686",
    "text": "What is function approximation in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that function approximation is the use of models, like neural networks, to represent value functions or policies instead of using a tabular representation. This is essential for problems with large or continuous state and action spaces.",
    "rubric_id": ""
  },
  {
    "id": "956a4b62be820dc8a604f7cd5200c82480f7d2568e035502a8ec5605048f38e4",
    "text": "What is off-policy learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define off-policy learning as a method where the agent learns a target policy while following a different behavior policy. This allows for more exploration while still learning the optimal policy. Q-learning should be cited as an example.",
    "rubric_id": ""
  },
  {
    "id": "ea361451461f8b782f6c625662094d4feee3fed272bdc2e1c2c59a3143cd9881",
    "text": "What is on-policy learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define on-policy learning as a method where the agent learns and updates the same policy it is currently using to take actions. SARSA should be cited as a classic example.",
    "rubric_id": ""
  },
  {
    "id": "47842e366e9d1fce840eb2b733807d5607ea75f73a8622288e5821dc7f923499",
    "text": "What is the advantage function in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the advantage function as a measure of how much better taking a specific action is compared to the average action in a given state. It should mention its use in actor-critic methods to reduce variance in policy gradient updates.",
    "rubric_id": ""
  },
  {
    "id": "b3a5e91d79d8e39d2cdcb087409ca012dd8e90e6c432017ee083c97d9d1bf55f",
    "text": "What is the exploration-exploitation dilemma in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain the dilemma as the core challenge of balancing the need to try new actions to discover better strategies (exploration) with the need to use the currently known best strategy to get high rewards (exploitation).",
    "rubric_id": ""
  },
  {
    "id": "1910fd6ed7bc459b9f313bc1fd22d73c443c982571c68c570309fbcc2fc6f9b4",
    "text": "What is the discount factor in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the discount factor (gamma) as a parameter that determines the importance of future rewards. A value close to 0 prioritizes immediate rewards, while a value close to 1 prioritizes long-term rewards.",
    "rubric_id": ""
  },
  {
    "id": "035d4539cd8a9f946fdbee23e687089ffff7b10e62d816afaf7fcf38294ffd9c",
    "text": "What is the role of rewards in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that rewards are numerical feedback signals from the environment that guide the agent's learning. The agent's objective is to learn a policy that maximizes the total cumulative reward.",
    "rubric_id": ""
  },
  {
    "id": "c95845e86cb7bba430f36e17a3fcb1550a3a8c71b9a742eea99733d8850bec16",
    "text": "What is the policy gradient in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the policy gradient as the gradient of the expected reward with respect to the policy's parameters. It should explain that policy gradient methods update the policy by moving its parameters in the direction of this gradient.",
    "rubric_id": ""
  },
  {
    "id": "4c810cc13955c3d39461d11fd530a1c87daf10ee3eb2bd3e85e9314e75e9e27e",
    "text": "What is the advantage of deep reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the main advantage is the ability to handle high-dimensional state and action spaces by using deep neural networks as function approximators. This allows RL to be applied to complex problems like playing video games from raw pixel data.",
    "rubric_id": ""
  },
  {
    "id": "f1f0223901c95082ef305ae8a8dadd3537f23e9ec72f67f12509757a0b3ddca3",
    "text": "What are some applications of reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several real-world applications of reinforcement learning. Look for mentions of robotics, game playing (e.g., AlphaGo), autonomous vehicles, and recommendation systems.",
    "rubric_id": ""
  },
  {
    "id": "347f6ccdece447cc4a0e087bf8d12b2189562364b986d4532fd8fee22fad2b23",
    "text": "What is policy search in reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define policy search as a category of reinforcement learning methods that directly search for an optimal policy in the policy space, rather than learning a value function first. Policy gradient methods are a key example.",
    "rubric_id": ""
  },
  {
    "id": "ef6af4c5ee94f0f7ebea8a9d5f19b84f2c5a1fc858ee27b769edfb19a6bec524",
    "text": "What could be some issues if the distribution of the test data is significantly different than the distribution of the training data?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the core issue as poor model generalization, leading to low test accuracy despite high training accuracy. It should mention the term 'dataset shift' or 'covariate shift' and explain that the model has learned patterns that are not present in the test data.",
    "rubric_id": ""
  },
  {
    "id": "8b8e2e68de2a4e78288101bfb76c221012a399c58a845713c328a99a26c2b2f4",
    "text": "What are some ways I can make my model more robust to outliers?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should provide several strategies. Look for suggestions related to the data (e.g., removing or transforming outliers), the model choice (e.g., using tree-based models which are less sensitive), and the error metric (e.g., using Mean Absolute Error instead of Mean Squared Error).",
    "rubric_id": ""
  },
  {
    "id": "081853333205d5f2f28148201cad02fdb3a8d147ddaca97d19e658bd1155e2f8",
    "text": "What are some differences you would expect in a model that minimizes squared error, versus a model that minimizes absolute error? In which cases would each error metric be appropriate?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that minimizing squared error (like MSE) penalizes large errors more heavily and is sensitive to outliers. Minimizing absolute error (like MAE) is more robust to outliers. Therefore, MAE is appropriate when outliers are present and should not be overly influential.",
    "rubric_id": ""
  },
  {
    "id": "ba07e4b53ba44ad0e1487e22b25d231a8253cd492c06a58bd5491740e7e6b50a",
    "text": "What error metric would you use to evaluate how good a binary classifier is? What if the classes are imbalanced? What if there are more than 2 groups?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must address all three parts. For a balanced binary classifier, accuracy is acceptable. For imbalanced classes, it must suggest metrics like Precision, Recall, F1-score, or AUC-ROC. For multi-class problems, it should mention metrics like macro/micro F1-score or log-loss.",
    "rubric_id": ""
  },
  {
    "id": "ac670fdf1ec591494db3317e704cc2de3bd4fc2c7902c386dbbc92f5dddbcc8b",
    "text": "What are various ways to predict a binary response variable? Can you compare two of them and tell me when one would be more appropriate? What's the difference between these? (SVM, Logistic Regression, Naive Bayes, Decision Tree, etc.)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should compare at least two binary classification algorithms. For example, comparing Logistic Regression and SVM, it should mention that Logistic Regression provides probabilities and works well for linearly separable data, while SVM with a kernel can handle non-linear data but is computationally more expensive.",
    "rubric_id": ""
  },
  {
    "id": "0db07d84b4d3684db5168e7f4701a706572656c9c697c559ea59b5e10641af82",
    "text": "What is regularization and where might it be helpful? What is an example of using regularization in a model?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting by penalizing model complexity. It should state that it is helpful when a model has high variance. An example must be provided, such as using L1 (Lasso) or L2 (Ridge) regularization in linear regression.",
    "rubric_id": ""
  },
  {
    "id": "4ba009ea808e27cd61fb79a133a62abd87952af23444b216973bdb9b5b4fb9d3",
    "text": "Why might it be preferable to include fewer predictors over many?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several reasons for using fewer predictors. Key points to check for are: reducing the risk of overfitting, improving model interpretability, and decreasing computational cost and complexity.",
    "rubric_id": ""
  },
  {
    "id": "613c5e2c19fef7719506f402076969e0d98a6467939a6130661125f787623097",
    "text": "Given training data on tweets and their retweets, how would you predict the number of retweets of a given tweet after 7 days after only observing 2 days worth of data?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should propose a modeling approach. A good approach would be to frame this as a regression problem, using features from the first two days (e.g., initial retweet count, user features, content features) to predict the 7-day total. Mentioning time-series modeling is also a valid approach.",
    "rubric_id": ""
  },
  {
    "id": "766dbb0e7b2dc3246472b695c4c074c7c7a8f1819441d862c5ca55f8eeac2f4c",
    "text": "How could you collect and analyze data to use social media to predict the weather?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should outline a clear process. This includes data collection (using APIs from platforms like Twitter to get posts mentioning weather), feature engineering (extracting text features, location, time), and modeling (using a time-series or regression model to predict a weather outcome like temperature).",
    "rubric_id": ""
  },
  {
    "id": "cdf9cfff0e8b68223e4790a99a75f29ee7062e198e73867c6975c9dc843334bc",
    "text": "How would you construct a feed to show relevant content for a site that involves user interactions with items?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe building a recommendation engine. It should mention the two main approaches: content-based filtering (recommending items similar to what a user has liked) and collaborative filtering (recommending items that similar users have liked).",
    "rubric_id": ""
  },
  {
    "id": "323b207dca0c5d58c056d29fd56cfc5d7df12d2d47a4265e3b6be525bf2ca8c6",
    "text": "How would you design the people you may know feature on LinkedIn or Facebook?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should frame this as a link prediction problem in a social graph. Key features to mention include mutual friends (triadic closure), common interests, shared groups, and overlapping network attributes like location or workplace.",
    "rubric_id": ""
  },
  {
    "id": "17bf3707d2991205392db44a5768d24a39c1d44a14bee089c4f00d6f30ed6785",
    "text": "How would you predict who someone may want to send a Snapchat or Gmail to?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should propose a ranking or classification model. The model should be based on features engineered from past interactions, such as frequency of communication, recency of the last interaction, and whether the user is responding to an incoming message.",
    "rubric_id": ""
  },
  {
    "id": "9e7d871513e41cd1b795af528aaf542b37b906abb7b68f3fb6c7faf09ec2f7f0",
    "text": "How would you suggest to a franchise where to open a new store?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline a data-driven approach. This involves creating a dataset with features for potential locations (e.g., demographic data, traffic, proximity to competitors) and building a regression model to predict the potential success (e.g., revenue) of a new store at each location.",
    "rubric_id": ""
  },
  {
    "id": "a9649b9bcdfea61675efe32ed95becb927e7172b1e32b17807f5922475f0b82c",
    "text": "In a search engine, given partial data on what the user has typed, how would you predict the user's eventual search query?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a query auto-completion system. It must mention using language models, like n-grams, trained on historical search data to predict the most probable next words or complete queries based on the partial input.",
    "rubric_id": ""
  },
  {
    "id": "f0d1911aa736909f9b7cb60cd0e2bd1a2f5d14f04d441ed177d0e19105fda0f5",
    "text": "Given a database of all previous alumni donations to your university, how would you predict which recent alumni are most likely to donate?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should frame this as a binary classification problem (donate vs. not donate). Key features to build the model would include past donation history (frequency, amount), graduation year, major, and engagement with the university.",
    "rubric_id": ""
  },
  {
    "id": "54b6583d2e23f8b2ada883b105c1108f5888197fae753e7ce51f70b0714b3f6d",
    "text": "Suppose you are Uber and you want to design a heatmap to recommend to drivers where to wait for a passenger. How would you approach this?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose a predictive model based on historical data. The model should predict passenger demand density based on features like time of day, day of the week, location, and special events. The output would be a heatmap of predicted demand.",
    "rubric_id": ""
  },
  {
    "id": "511d09cca3cb8c0ad7912e67192eca90ac79ddc39b8428cbb23af054adab80f0",
    "text": "How would you build a model to predict a March Madness bracket?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a binary classification model to predict the winner of a single game. Features would include team statistics (e.g., win-loss record, points per game), rankings, and possibly historical tournament performance. This model would then be applied iteratively for each round of the tournament.",
    "rubric_id": ""
  },
  {
    "id": "304996b069140b31741795dfe271bb4ea851b3b3f1e11741cf6f73970d0a9950",
    "text": "You want to run a regression to predict the probability of a flight delay, but there are flights with delays of up to 12 hours that are really messing up your model. How can you address this?",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should suggest methods for handling outliers in the target variable. Key strategies to look for are transforming the target variable (e.g., log transform), capping the values (winsorizing), or framing the problem differently, perhaps as a classification problem (delayed vs. not delayed) first.",
    "rubric_id": ""
  },
  {
    "id": "c6c42836a7e58325d05273efcad89328d52a130e0522bc0b384906fd22c61cc4",
    "text": "What is R2? What are some other metrics that could be better than R2 and why?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define R-squared as the proportion of the variance in the dependent variable that is predictable from the independent variables. It should also mention its limitations (e.g., it always increases with more variables) and suggest alternatives like Adjusted R-squared or RMSE for evaluating regression models.",
    "rubric_id": ""
  },
  {
    "id": "eab65c86c2f522959291e16bf8ab18a49b2bccc2ed6c019289af76c1db45dbbe",
    "text": "What is the curse of dimensionality?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain the curse of dimensionality as the various problems that arise when working with high-dimensional data. Key issues to mention are data sparsity (data points become far apart) and the increased computational complexity, which can degrade model performance.",
    "rubric_id": ""
  },
  {
    "id": "cd403cdd8a21ec4f236ebbcc7c8bfd74368c25daafdf41cb7f1335f7d9710538",
    "text": "Is more data always better?.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should be nuanced, stating that while more data is generally beneficial, it is not always better. It must mention that the quality and relevance of the data are more important. Adding noisy or irrelevant data can degrade model performance.",
    "rubric_id": ""
  },
  {
    "id": "fac076f24dd072d7d28bf74e0e337c1de80d5eb5b7cc7f146153cbd980588d0e",
    "text": "What are advantages of plotting your data before per- forming analysis?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should emphasize the importance of Exploratory Data Analysis (EDA). Key advantages to mention are identifying patterns, detecting outliers, understanding relationships between variables, and informing feature engineering and model selection.",
    "rubric_id": ""
  },
  {
    "id": "e2be5bee6be6a680f6c3cf9c9d609e451824ce11388544f48d28e687843972c2",
    "text": "What is the role of trial and error in data analysis? What is the role of making a hypothesis before diving in?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that hypothesis-driven analysis provides structure and focus, preventing random exploration. However, it should also acknowledge that trial and error (experimentation with different models and features) is a necessary part of the iterative process of finding the best solution.",
    "rubric_id": ""
  },
  {
    "id": "877bbe0b8f9586eecda8b72ec2ec3e2a8661e28b8db8c22ec8ad483e4773fb6d",
    "text": "How can you determine which features are the most important in your model?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several methods for assessing feature importance. Look for mentions of model-specific methods (like coefficients in linear models or feature importance in tree-based models), permutation importance, and techniques like SHAP.",
    "rubric_id": ""
  },
  {
    "id": "087126f007873696c124fa74e8d04711f9940202743332255ad2ac84c3ada0bb",
    "text": "How do you deal with some of your predictors being missing?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list common strategies for handling missing data. Key techniques to mention are deleting rows/columns with missing values, or imputing the missing values using mean, median, mode, or more sophisticated models.",
    "rubric_id": ""
  },
  {
    "id": "f3e3d7a283b44cb2dc5185eb4948afc6de2caeef6f1372a29f7987e3d9b5fc6e",
    "text": "You have several variables that are positively correlated with your response, and you think combining all of the variables could give you a good prediction of your response. However, you see that in the multiple linear regression, one of the weights on the predictors is negative. What could be the issue?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify multicollinearity as the likely issue. It should explain that when predictor variables are highly correlated with each other, the model's coefficient estimates can become unstable and have counterintuitive signs.",
    "rubric_id": ""
  },
  {
    "id": "f4dc790536ac5dd0c0e0500441a5baa975a3d8e5fa991c9f8152e21615715f66",
    "text": "Let's say you're given an unfeasible number of predictors in a predictive modeling task. What are some ways to make the prediction more feasible?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must suggest dimensionality reduction techniques. Look for mentions of feature selection methods (like using L1 regularization) and feature extraction methods (like Principal Component Analysis - PCA).",
    "rubric_id": ""
  },
  {
    "id": "6f6ecb61bb4e3e134c0c784c9a6bf6beba27db9151ae51a51d6e787608740858",
    "text": "Now you have a feasible number of predictors, but you are sure that you don't need all of them. How would you perform feature selection on the dataset?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common feature selection strategies. Check for mentions of filter methods (e.g., using correlation), wrapper methods (e.g., recursive feature elimination), and embedded methods (e.g., Lasso regression).",
    "rubric_id": ""
  },
  {
    "id": "3395857a7fe6e3b549c3efcadfcc7ac642c9f9f246447106e07d334f2491e35e",
    "text": "Your linear regression didn't run and communicates that there are an infinite number of best estimates for the regression coefficients. What could be wrong?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify perfect multicollinearity as the cause. This happens when one predictor variable is a perfect linear combination of one or more other predictors, making it impossible to find a unique solution for the coefficients.",
    "rubric_id": ""
  },
  {
    "id": "7b875f0f3c95aa7f740b7303ae6cc536a393b71052698b7a9455532f7c9f40bf",
    "text": "You run your regression on different subsets of your data, and find that in each subset, the beta value for a certain variable varies wildly. What could be the issue here?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should suggest that the model has high variance and is likely overfitting. The instability of the coefficient across different subsets of data is a classic symptom of this issue, possibly exacerbated by multicollinearity.",
    "rubric_id": ""
  },
  {
    "id": "6f3a88edc5b6b67ee1ab7e6063fecd645aec7e4d4536aa7421fb0b59d6978666",
    "text": "What is the main idea behind ensemble learning? If I had many different models that predicted the same response variable, what might I want to do to incorporate all the models? Would you expect this to perform better than an individual model or worse?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the main idea of ensemble learning is to combine multiple models to achieve better predictive performance than any single model. It should suggest combining their predictions (e.g., by averaging or voting) and state that this usually performs better due to reduced variance.",
    "rubric_id": ""
  },
  {
    "id": "5e779296c4d2c41150ec2d0d5a5d8e478b2223c08d79b3062181dd5ab7322bb5",
    "text": "How could you use GPS data from a car to determine the quality of a driver?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must involve feature engineering from raw GPS data. Key features to derive include speed, acceleration, braking events, cornering severity, and adherence to speed limits. These features can then be used to create a driver score.",
    "rubric_id": ""
  },
  {
    "id": "871bb6c0cdfed77b9ae2259f0f86f4bd134a52c2d2fcee966fa226f31a31e7cf",
    "text": "Given accelerometer, altitude, and fuel usage data from a car, how would you determine the optimum acceleration pattern to drive over hills?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should frame this as an optimization problem. The goal is to find an acceleration pattern (a function of altitude change) that minimizes fuel usage. A model could be built to predict fuel usage based on acceleration and altitude data, which could then be used for optimization.",
    "rubric_id": ""
  },
  {
    "id": "4598e321d1971a2977b1f962e40adab039670bd37ae72cef809c38d20a18b8f2",
    "text": "Given position data of NBA players in a season's games, how would you evaluate a basketball player's defensive ability?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should involve creating metrics from positional data. Look for ideas like opponent field goal percentage when the player is the nearest defender, ability to contest shots (distance to shooter), and defensive positioning relative to the ball and opponent.",
    "rubric_id": ""
  },
  {
    "id": "8ac67926cfab3bc3aac9cbfb81f7df8bde2d8ca0720c6724b222b72d2fa83803",
    "text": "How would you quantify the influence of a Twitter user?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should go beyond simple metrics like follower count. It must suggest more sophisticated metrics such as engagement rate (likes/retweets per follower), the reach of their retweets, and their position and centrality in the social network graph.",
    "rubric_id": ""
  },
  {
    "id": "4a106be64880a10e0b386da94c546db7e5583ded705be926c81ae306e15f2d9e",
    "text": "Given location data of golf balls in games, how would construct a model that can advise golfers where to aim?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a model that predicts the likely final position of a shot given an aim point and other factors (e.g., club choice, weather). This could be a probabilistic model that shows a distribution of outcomes, allowing the golfer to choose an aim point that minimizes risk.",
    "rubric_id": ""
  },
  {
    "id": "287d621578c820b96a3b4afe8af905259b3ad27698ba4186f6931061962aad21",
    "text": "You have 100 mathletes and 100 math problems. Each mathlete gets to choose 10 problems to solve. Given data on who got what problem correct, how would you rank the problems in terms of difficulty?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should suggest a method more sophisticated than just calculating the percentage of correct answers. A good approach would be to use an Item Response Theory (IRT) model, which can estimate both the ability of each mathlete and the difficulty of each problem simultaneously.",
    "rubric_id": ""
  },
  {
    "id": "06c0cd083f6d7e4bbe4035a9c310581d674d0166cc758636a2ded0e888d07185",
    "text": "You have 5000 people that rank 10 kinds of sushi in terms of saltiness. How would you aggregate this data to estimate the true saltiness rank in each kind?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should propose a method for aggregating rankings. Simple approaches include averaging the ranks. More advanced methods to mention could include models like the Bradley-Terry model to derive a latent 'saltiness score' for each type of sushi from the pairwise comparisons implied by the rankings.",
    "rubric_id": ""
  },
  {
    "id": "a54d5e95ea51518a8934ab8f60433e41c2f558066153ae04d845bb6bd7fc357e",
    "text": "Given data on congressional bills and which congressional representatives co-sponsored the bills, how would you determine which other representatives are most similar to yours in voting behavior? How would you evaluate who is the most liberal? Most republican? Most bipartisan?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose using the co-sponsorship data to measure similarity. This could involve creating a vector for each representative and using a similarity metric like cosine similarity. To measure political leaning, dimensionality reduction techniques like PCA could be used to find the main axis of political division.",
    "rubric_id": ""
  },
  {
    "id": "80dc448b86ff4f974b6d32663aec8b9b1db0e8c550daafae502242ebbf6745ca",
    "text": "How would you come up with an algorithm to detect plagiarism in online content?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a text similarity algorithm. Key steps to mention are text preprocessing (normalization), feature extraction (e.g., using TF-IDF or document embeddings), and then comparing the features of a new document against a database of existing documents using a similarity metric.",
    "rubric_id": ""
  },
  {
    "id": "b900821f7ea23a7e1e51aa691c5eb27aa69f10e2f40be12c87bcbe733eb10550",
    "text": "You have data on all purchases of customers at a grocery store. Describe to me how you would program an algorithm that would cluster the customers into groups. How would you determine the appropriate number of clusters to include?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe a customer segmentation process. It should involve feature engineering (e.g., creating RFM - Recency, Frequency, Monetary - features), applying a clustering algorithm like K-means, and using the Elbow Method to determine the optimal number of clusters.",
    "rubric_id": ""
  },
  {
    "id": "e57c1e211d42dc2136bd001a0db642d9a29ede9938fe7809fc5402c0272f1f5d",
    "text": "Let's say you're building the recommended music engine at Spotify to recommend people music based on past listening history. How would you approach this problem?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe building a recommendation system. It should mention using collaborative filtering (based on what similar users listen to) and content-based filtering (based on the acoustic features of the music). A hybrid approach combining both is the ideal answer.",
    "rubric_id": ""
  },
  {
    "id": "ac7da56b2f44965765fd91c9b04fb6beec409cad431265fbd0a4b33cf659fcf2",
    "text": "What would be good metrics of success for an advertising-driven consumer product? (Buzzfeed, YouTube, Google Search, etc.) A service-driven consumer product? (Uber, Flickr, Venmo, etc.).",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate between the two business models. For ad-driven products, it should focus on engagement metrics like daily active users, time spent, and ad revenue metrics like CPM or CTR. For service-driven products, it should focus on transaction metrics like number of transactions, transaction value, and user retention.",
    "rubric_id": ""
  },
  {
    "id": "4aa35b1c09790848182fc6e572d93c25dc87d619a8dda077303babb1ccf68473",
    "text": "What would be good metrics of success for a productivity tool? (Evernote, Asana, Google Docs, etc.) A MOOC? (edX, Coursera, Udacity, etc.)",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify appropriate metrics for each product type. For productivity tools, look for engagement and task completion rates. For a MOOC, key metrics would include enrollment numbers, course completion rates, and student satisfaction.",
    "rubric_id": ""
  },
  {
    "id": "e2fcb51ac8bee60a45c1977bac13797a5bd5144a435bc6ac6e007b0b5dfcb35d",
    "text": "What would be good metrics of success for an e-commerce product? (Etsy, Groupon, Birchbox, etc.) A subscription product? (Netflix, Birchbox, Hulu, etc.) Premium subscriptions? (OKCupid, LinkedIn, Spotify, etc.)",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between e-commerce and subscription models. For e-commerce, it should mention metrics like conversion rate, average order value, and customer lifetime value. For subscription products, it must focus on monthly recurring revenue (MRR) and churn rate.",
    "rubric_id": ""
  },
  {
    "id": "a17a97a29d3bb3c9d38c4464651e7bc3b91d74145d545d38a66062ecd65cf411",
    "text": "What would be good metrics of success for a consumer product that relies heavily on engagement and interaction? (Snapchat, Pinterest, Facebook, etc.) A messaging product? (GroupMe, Hangouts, Snapchat, etc.)",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must focus on user engagement metrics. Look for mentions of Daily Active Users (DAU), Monthly Active Users (MAU), session duration, and the number of key actions taken per user (e.g., messages sent, pins created).",
    "rubric_id": ""
  },
  {
    "id": "b7a774705e8f29e11997f5df5650ada44ba5dd66fc9022127668ad1deb552dc6",
    "text": "What would be good metrics of success for a product that o ered in-app purchases? (Zynga, Angry Birds, other gaming apps)",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should focus on monetization metrics. Key metrics to mention include Average Revenue Per User (ARPU), conversion rate to paying users, and customer lifetime value (LTV).",
    "rubric_id": ""
  },
  {
    "id": "5ee4c8200cb8193a54d139a3cb6c90996d622e2f08d10e6171b7a26a128130e2",
    "text": "A certain metric is violating your expectations by going down or up more than you expect. How would you try to identify the cause of the change?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a systematic root cause analysis process. This involves first checking for internal factors (e.g., data pipeline errors, recent product changes) and then investigating external factors (e.g., seasonality, competitor actions, market trends). It should also mention segmenting the metric to isolate the source of the change.",
    "rubric_id": ""
  },
  {
    "id": "a7b6c3fdb899c3a64f95f2b885c33012976cd859a822b8d28799a2a41c551581",
    "text": "Growth for total number of tweets sent has been slow this month. What data would you look at to determine the cause of the problem?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose a structured investigation. This should involve breaking down the metric by user segments (new vs. existing users, geographic location, device type) and looking at related metrics like user growth, user engagement, and potential technical issues.",
    "rubric_id": ""
  },
  {
    "id": "c988e0af6708e5d5db6f752bbed111fdb11b20e3e597d8087795a8838c027c00",
    "text": "You're a restaurant and are approached by Groupon to run a deal. What data would you ask from them in order to determine whether or not to do the deal?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should focus on data needed to forecast profitability. Key data points to ask for include the demographics of Groupon users in the area, redemption rates for similar restaurant deals, and the rate at which Groupon customers become repeat, full-price customers.",
    "rubric_id": ""
  },
  {
    "id": "f6cb25012e609842a72e9c80c07b1802ff9fb304427bf6d18593554e79d740b2",
    "text": "You are tasked with improving the e ciency of a subway system. Where would you start?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should start with defining 'efficiency' through key metrics. Good metrics to mention are on-time performance, passenger wait times, and passenger throughput. The next step should be to identify bottlenecks by analyzing data related to these metrics.",
    "rubric_id": ""
  },
  {
    "id": "7857353d44cf8ff07c5d72b52b0f8689c6010fedc56314c3c6ea96496166f218",
    "text": "Say you are working on Facebook News Feed. What would be some metrics that you think are important? How would you make the news each person gets more relevant?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list key engagement metrics for the News Feed, such as time spent scrolling, likes, comments, and shares. To improve relevance, it should describe using a machine learning model that predicts which stories a user is most likely to interact with based on their past behavior and preferences.",
    "rubric_id": ""
  },
  {
    "id": "b27fee1a08742fac6be7f0f2a8c7f092d01af3270ff90a5be2b0c4c55f1b212f",
    "text": "How would you measure the impact that sponsored stories on Facebook News Feed have on user engagement? How would you determine the optimum balance between sponsored stories and organic content on a user's News Feed?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose using an A/B test. One group would see a certain number of sponsored stories, and a control group would see none or a different number. The impact would be measured by comparing user engagement metrics (likes, shares, time spent) and negative signals (hiding stories, leaving the platform) between the groups to find the optimal balance.",
    "rubric_id": ""
  },
  {
    "id": "70ce208650def5ab0c8c8d186cf60f478b69c659ef4408097ab320cecfeae34a",
    "text": "You are on the data science team at Uber, and you are asked to start thinking about surge pricing. What would be the objectives of such a product and how would you start looking into this?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the dual objectives of surge pricing: to balance supply (drivers) and demand (riders) and to maximize ride completions. The approach should involve analyzing historical data to build a model that predicts supply and demand imbalances based on location, time, and events.",
    "rubric_id": ""
  },
  {
    "id": "0b0de4a4186d16293788325bdf9bbedf421696a2f809286f6f91a9cf4d65add0",
    "text": "Say that you are Netflix. How would you determine what original series you should invest in and create?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a data-driven approach. This involves analyzing user viewing data to identify underserved genres or themes, finding actors or directors who are popular with specific audience segments, and building a predictive model to forecast the potential viewership and value of a proposed project.",
    "rubric_id": ""
  },
  {
    "id": "603334f3b8b6ec79294c93cb5b07d0067b1fc6409fb679ab37386cc21beb9112",
    "text": "Let's say that you are scheduling content for a content provider on television. How would you determine the best times to schedule content?",
    "domain": "behavioral-behavioral",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must involve analyzing historical viewership data. The goal is to identify time slots when the target audience for a specific show is most likely to be watching. It should also consider competitor programming in different time slots.",
    "rubric_id": ""
  },
  {
    "id": "2bef3f400d0fb4e83659e3475edfc287450006adb16807d38d64f5016996c6ce",
    "text": "Write a function to calculate all possible assignment vectors of 2n users, where n users are assigned to group 0 (control), and n users are assigned to group 1 (treatment).",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should identify this as a combinations problem. The solution should involve generating all combinations of choosing 'n' users out of '2n' total users for one of the groups. The remaining users would then form the other group.",
    "rubric_id": ""
  },
  {
    "id": "076952c2894a346040a76b4e09d679c51563be811bcfbc47be7df9bb06c0e069",
    "text": "Given a list of tweets, determine the top 10 most used hashtags.",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should outline a clear algorithm. This involves iterating through each tweet, extracting all hashtags (e.g., using regular expressions), counting the frequency of each hashtag using a hash map or dictionary, and then sorting the hashtags by frequency to find the top 10.",
    "rubric_id": ""
  },
  {
    "id": "0ef48c6b112f1dd72d9bbf5903c129a808137397e3b79e0b70d8928b28e39b9e",
    "text": "Program an algorithm to find the best approximate solution to the knapsack problem1 in a given time.",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must recognize this as a classic optimization problem. Since an exact solution might be too slow, it should suggest a greedy algorithm. A good greedy approach is to iteratively pick items with the highest value-to-weight ratio until the knapsack is full.",
    "rubric_id": ""
  },
  {
    "id": "5b5853d6b4ff5ac6ab26017319503dfc74bcb55e0da5896e8e131b57fd29d338",
    "text": "Program an algorithm to find the best approximate solution to the travelling salesman problem2 in a given time.",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify this as an NP-hard problem where an exact solution is infeasible for large inputs. It should propose a heuristic or approximation algorithm, such as a greedy approach (e.g., nearest neighbor) or a local search method (e.g., 2-opt).",
    "rubric_id": ""
  },
  {
    "id": "49d1000a097dcafb8e366794d6c6fea3d4f240929f09c1b1811bc8505cd0552c",
    "text": "You have a stream of data coming in of size n, but you don't know what n is ahead of time. Write an algorithm that will take a random sample of k elements. Can you write one that takes O(k) space?",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the Reservoir Sampling algorithm. The key steps to look for are: fill a reservoir of size k with the first k elements. Then, for each subsequent element, generate a random number and if it falls within a certain probability, replace a random element in the reservoir with the new element.",
    "rubric_id": ""
  },
  {
    "id": "b07fabd7965d0bf8dcd6fffd1e79cc9095935e03a1074dda8ec7db928804e3df",
    "text": "Write an algorithm that can calculate the square root of a number.",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should propose an iterative numerical method. The most common and efficient method to mention is Newton's method or the Babylonian method. Another valid approach is using binary search.",
    "rubric_id": ""
  },
  {
    "id": "38951c853e39eb0911d5c72509eecdc3c55fc1778c98930fe176feefa48f0ce9",
    "text": "Given a list of numbers, can you return the outliers?",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must first define what constitutes an outlier. A common statistical definition is any point that falls outside of 1.5 times the Interquartile Range (IQR) above the third quartile or below the first quartile. The algorithm should calculate these bounds and return the numbers that fall outside them.",
    "rubric_id": ""
  },
  {
    "id": "0a47464d6554c7de6bcae82a314071c5df055f9b069a40901e43e218c466d703",
    "text": "When can parallelism make your algorithms run faster?",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that parallelism is effective for tasks that can be broken down into independent sub-problems that can be solved simultaneously. It should mention that not all problems are parallelizable and that communication overhead can sometimes outweigh the benefits.",
    "rubric_id": ""
  },
  {
    "id": "e753fec486055db220dfce3f0b48e24257ea3d3945029f8b4377aa881aedc0ae",
    "text": "What are the different types of joins? What are the differences between them?",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list and differentiate the main SQL join types. Look for: INNER JOIN (returns matching records from both tables), LEFT JOIN (returns all records from the left table and matched records from the right), RIGHT JOIN (opposite of LEFT), and FULL OUTER JOIN (returns all records when there is a match in either table).",
    "rubric_id": ""
  },
  {
    "id": "757ae0866e9a21cf4415749531d058ee5af38bf0d354e2a0d83f615260788cf8",
    "text": "Why might a join on a subquery be slow? How might you speed it up?",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should explain that a join on a subquery can be slow because the database might not be able to optimize it effectively, potentially creating a large temporary table. To speed it up, the subquery should be rewritten as a direct join or using a Common Table Expression (CTE).",
    "rubric_id": ""
  },
  {
    "id": "9d33bcf7f94fbea3e9632103f2753ffaf046df27f52accff8ab7a47a994fe182",
    "text": "Describe the difference between primary keys and foreign keys in a SQL database.",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both key types. A primary key uniquely identifies each record in a table and cannot contain null values. A foreign key is a key in one table that refers to the primary key in another table, creating a link between them.",
    "rubric_id": ""
  },
  {
    "id": "da345045042b74fb39e31a666819a772bc7f4b8ec85f8907cc70cfee663f0d99",
    "text": "Given a COURSES table with columns course_id and course_name, a FACULTY table with columns faculty_id and faculty_name, and a COURSE_FACULTY table with columns faculty_id and course_id, how would you return a list of faculties who teach a course given the name of a course?",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide a correct SQL query that joins the three tables. It should join FACULTY to COURSE_FACULTY on faculty_id, and join that result to COURSES on course_id, then filter by the given course_name.",
    "rubric_id": ""
  },
  {
    "id": "16866d3eea82bfd9e33c596e1cf671f3811bcd4f6f518cbff5afcfc0dbcea837",
    "text": "Given a IMPRESSIONS table with ad_id, click (an indicator that the ad was clicked), and date, write a SQL query that will tell me the click-through-rate of each ad by month.",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide a SQL query that calculates the Click-Through Rate (CTR). The query should group the data by ad_id and the month of the date. The CTR should be calculated as the sum of clicks divided by the total count of impressions (or average of the click indicator).",
    "rubric_id": ""
  },
  {
    "id": "e8fec8766880a557f65aa415b2fe903b36c52cd86da8aa97851daecab374f612",
    "text": "Write a query that returns the name of each department and a count of the number of employees in each:",
    "domain": "technical-programming",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide a correct SQL query that joins the department and employee tables (likely through a linking table). It must use a COUNT function and a GROUP BY clause on the department name to get the number of employees per department.",
    "rubric_id": ""
  },
  {
    "id": "8fdacb5e022c44456daf52dab2c0ab1a435653c6db35784f6bec343fb2ae0c0d",
    "text": "In an A/B test, how can you check if assignment to the various buckets was truly random?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should suggest performing a sanity check or an A/A test before the main experiment. This involves checking that key metrics and user distributions (e.g., by country, device) are statistically similar across the groups before the change is introduced.",
    "rubric_id": ""
  },
  {
    "id": "d3e0727e81f707520e5cac0ecc8373b0ca90d889f7150c6ccfe87df0e714a211",
    "text": "What might be the benefits of running an A/A test, where you have two buckets who are exposed to the exact same product?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that an A/A test is used to validate the testing framework itself. Its benefits include checking for sample ratio mismatch, ensuring the randomization is working correctly, and establishing a baseline for metric variability.",
    "rubric_id": ""
  },
  {
    "id": "5ed42160ee0baa2fe707e032a9e70be8471aab0bf3f0fbd0fbb67ce6afc0d812",
    "text": "What would be the hazards of letting users sneak a peek at the other bucket in an A/B test?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the core issue as contamination of the experiment, which violates the independence assumption. This can invalidate the results, as users' behavior might be influenced by seeing the other version, leading to incorrect conclusions.",
    "rubric_id": ""
  },
  {
    "id": "844cd3e452a813d5b4651af4964eb9be746b2a95a8e5ed87431f21d29d2ae418",
    "text": "What would be some issues if blogs decide to cover one of your experimental groups?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify this as a source of external validity threat. The media coverage could attract a different type of user to that specific group or change user behavior, making the results for that group not generalizable to the overall user population.",
    "rubric_id": ""
  },
  {
    "id": "1f79a9afd2478becc9ada08340946454bf6ce4b2074173aec8c0e67f86c102f4",
    "text": "How would you conduct an A/B test on an opt-in feature?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must address the selection bias inherent in opt-in features. A correct approach would be to randomize all eligible users into two groups: one group is shown the option to opt-in (the treatment), and the other is not (the control). The analysis then compares the behavior of all users in the treatment group to all users in the control group.",
    "rubric_id": ""
  },
  {
    "id": "e64db9a873379ada591601bba8b0716db8374533870114a201201bff754be4fd",
    "text": "How would you run an A/B test for many variants, say 20 or more?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should address the multiple comparisons problem. It must state that running multiple t-tests would inflate the Type I error rate. It should suggest using a statistical method that corrects for this, such as ANOVA followed by a post-hoc test (like Tukey's HSD) or using a Bonferroni correction.",
    "rubric_id": ""
  },
  {
    "id": "cdb6b24107693d4d78148a87d936892d089933244e111907d0f4593c1da6c676",
    "text": "How would you run an A/B test if the observations are extremely right skewed?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose methods to handle skewed data, as standard t-tests assume normality. Good suggestions include transforming the data (e.g., log transform), using a non-parametric test (like the Mann-Whitney U test), or increasing the sample size, as the Central Limit Theorem suggests the distribution of sample means will be normal.",
    "rubric_id": ""
  },
  {
    "id": "9d376b250b170fa48b16e1d7a1634811ed33e4d5fb66a3e14331d55332db2f7b",
    "text": "I have two different experiments that both change the sign-up button to my website. I want to test them at the same time. What kinds of things should I keep in mind?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the potential for interaction effects. It should suggest running a multivariate test (or factorial experiment) with multiple cells (e.g., control, change A only, change B only, both changes A and B) to measure not only the main effect of each change but also how they interact with each other.",
    "rubric_id": ""
  },
  {
    "id": "9106040def89b1031ddebf37991cd008f5a4bc91fcd06df1a9524020480addcf",
    "text": "What is a p-value? What is the difference between type-1 and type-2 error?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the p-value as the probability of observing the current results, or more extreme, if the null hypothesis were true. It must also correctly define a Type I error as a false positive (rejecting a true null) and a Type II error as a false negative (failing to reject a false null).",
    "rubric_id": ""
  },
  {
    "id": "c517b0c1707802521ab44454e2fcf44b01f00cdd6eacee29ac5480cca9f7c7af",
    "text": "Suppose you are AirBnB and you want to test the hypothesis that a greater number of photographs increases the chances that a buyer selects the listing. How would you test this hypothesis?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose an A/B test. The experiment would involve randomly selecting a group of new listings and encouraging their hosts to add more photos (treatment group), and comparing their booking rate against a control group of similar listings with no such encouragement.",
    "rubric_id": ""
  },
  {
    "id": "4100434a790e0bc3c39c357d9ae7fa26fc60ee65bf2a54117f5e5142f133c136",
    "text": "How would you design an experiment to determine the impact of latency on user engagement?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe a controlled experiment. A good design would involve randomly assigning users to different groups and artificially introducing a small amount of extra latency for the treatment groups. The impact would then be measured by comparing engagement metrics (e.g., clicks, session duration) between the control group and the latency-added groups.",
    "rubric_id": ""
  },
  {
    "id": "3093a3ffab56665475d159980422d7b5f98bbe2c639efd7a633b3cdafb6eedc3",
    "text": "What is maximum likelihood estimation? Could there be any case where it doesn't exist?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define Maximum Likelihood Estimation (MLE) as a method for estimating the parameters of a statistical model by finding the parameter values that maximize the likelihood of observing the given data. It should note that MLE may not exist if the likelihood function is unbounded, which can happen with certain model types like Gaussian mixtures.",
    "rubric_id": ""
  },
  {
    "id": "70a5628b4edc17de61f4b512b5f51fefd663a90b49af4c6dbdbe9250938bb125",
    "text": "What's the difference between a MAP, MOM, MLE estima- tor? In which cases would you want to use each?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the estimators. MLE maximizes the likelihood. MAP (Maximum a Posteriori) maximizes the posterior probability, incorporating a prior belief about the parameters. MOM (Method of Moments) equates sample moments to theoretical moments. MAP is useful when you have prior information or as a form of regularization.",
    "rubric_id": ""
  },
  {
    "id": "53ea8eb0d979a8e52318ba8057a9f2e7749f0d3ca8245abb1ac03cd81c8a0154",
    "text": "What is a confidence interval and how do you interpret it?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly define and interpret a confidence interval. A 95% confidence interval is a range of values that you can be 95% confident contains the true population parameter. The correct interpretation is about the process: if we were to repeat the experiment many times, 95% of the calculated confidence intervals would contain the true parameter.",
    "rubric_id": ""
  },
  {
    "id": "b8127051be6a67758896808fbeac5f3799185f195e7024a1bf75d8d0f7a0ac87",
    "text": "What is unbiasedness as a property of an estimator? Is this always a desirable property when performing inference? What about in data analysis or predictive modeling?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an unbiased estimator as one whose expected value is equal to the true value of the parameter being estimated. It should also explain that unbiasedness is not always the most desirable property; sometimes, a biased estimator with lower variance (e.g., from regularization) can have a lower overall error (MSE), which is often preferred for predictive modeling.",
    "rubric_id": ""
  },
  {
    "id": "ffd12551aa14ad12a5f34ebf578bacd04b76b28c7c6d8629b9acee4c13b54483",
    "text": "What is Selection Bias?",
    "domain": "behavioral-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define selection bias as a systematic error that occurs when the sample used for analysis is not representative of the target population. This leads to distorted and incorrect conclusions. It should provide an example, such as a survey conducted only online, which would exclude people without internet access.",
    "rubric_id": ""
  },
  {
    "id": "95940667c94df5a9ad6573df06aec408e3ebcc34ada7c50dae03de463babf929",
    "text": "How would you explain an A/B test to an engineer with no statistics background? A linear regression?",
    "domain": "behavioral-communication",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use an analogy. For an A/B test, it could be explained as showing two different versions of a webpage to two groups of users to see which one performs better, like a scientific experiment. For linear regression, it could be described as finding the best-fitting straight line through a set of data points to predict a value.",
    "rubric_id": ""
  },
  {
    "id": "889c410b60080c075b52f475aeeec38fb5ea6042809f5e4cd9d571130770c109",
    "text": "How would you explain a confidence interval to an engineer with no statistics background? What does 95% confidence mean?",
    "domain": "behavioral-communication",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must avoid technical jargon. It should explain a confidence interval as a range of plausible values for a metric. The 95% confidence part should be explained in terms of reliability: it's not the probability that the true value is in the interval, but rather our confidence in the method that produced the interval.",
    "rubric_id": ""
  },
  {
    "id": "af29e54963dfdad5782b13f6a65257370767fc0efcde44733c6b87531dbcc3b6",
    "text": "How would you explain to a group of senior executives why data is important?",
    "domain": "behavioral-communication",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must focus on business outcomes. It should explain that data allows the company to move from making decisions based on intuition to making decisions based on evidence. It must provide concrete examples of how data can increase revenue, reduce costs, or improve customer satisfaction.",
    "rubric_id": ""
  },
  {
    "id": "1fe5c45e86eddbfb94b0d7feb3d18d3cc3fa5efbba9f86b534fd644c0b658b4e",
    "text": "[Facebook - Easy] There is a fair coin (one side heads, one side tails) and an unfair coin (both sides tails). You pick one at random, flip it 5 times, and observe that it comes up as tails all five times. What is the chance that you are flipping the unfair coin?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must use Bayes' theorem to solve this conditional probability problem. It should calculate the probability of observing 5 tails given the fair coin and given the unfair coin, and then use these to find the posterior probability that the chosen coin was the unfair one.",
    "rubric_id": ""
  },
  {
    "id": "24e3cce05e6d638de91d9cb81e39d8842a1e92fd4efb67176b24e69367adb294",
    "text": "[Lyft - Easy] You and your friend are playing a game. The two of you will continue to toss a coin until the sequence HH or TH shows up. If HH shows up first, you win. If TH shows up first, your friend wins. What is the probability of you winning?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should analyze the game's states. It must recognize that if the first toss is a Tail, the game essentially resets but your friend is guaranteed to win on the next Head. If the first toss is a Head, you have a 1/2 chance of winning immediately (HH) and a 1/2 chance of your friend winning (HT, which contains TH). The final probability of you winning is 1/4.",
    "rubric_id": ""
  },
  {
    "id": "5f5f068b37226d6479eb8967684d2e7eace8d2d2e91f09fc90fa31e4b0d77f28",
    "text": "[Google - Easy] What is the probability that a seven-game series goes to 7 games?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must correctly set up the problem. For the series to go to 7 games, one team must win exactly 3 of the first 6 games. The solution should use the binomial probability formula to calculate the probability of this outcome.",
    "rubric_id": ""
  },
  {
    "id": "e54f497857639bf70ed005290499ff937daf0d8417de9822447e34b8c5e28f38",
    "text": "[Facebook - Easy] Facebook has a content team that labels pieces of content on the platform as spam or not spam. 90% of them are diligent raters and will label 20% of the content as spam and 80% as non-spam. The remaining 10% are non-diligent raters and will label 0% of the content as spam and 100% as non-spam. Assume the pieces of content are labeled independently from one another, for every rater. Given that a rater has labeled 4 pieces of content as good, what is the probability that they are a diligent rater?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must use Bayes' theorem. It needs to calculate the probability of labeling 4 pieces as 'good' given the rater is diligent, and the probability of the same outcome given the rater is non-diligent. These likelihoods are then used to update the prior probability of being a diligent rater.",
    "rubric_id": ""
  },
  {
    "id": "dff06d12adb7bea7bc852647663f15c65fbdc72f671a0211cb0bd6500f65f2b4",
    "text": "[Bloomberg - Easy] Say you draw a circle and choose two chords at random. What is the probability that those chords will intersect?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must recognize that two chords intersect if and only if their four endpoints alternate around the circle. By choosing four random points on the circle to define the chords, there are 3 ways to pair them up, only one of which results in intersecting chords. The probability is 1/3.",
    "rubric_id": ""
  },
  {
    "id": "2bf4cfa890632132464e7cae94e3e5efd136669dca6f821e25d2d04b9f4c6855",
    "text": "[Amazon - Easy] 1/1000 people have a particular disease, and there is a test that is 98% correct if you have the disease. If you don't have the disease, there is a 1% error rate. If someone tests positive, what are the odds they have the disease?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must apply Bayes' theorem to calculate the posterior probability of having the disease given a positive test. It needs to correctly use the base rate (prevalence), the true positive rate (sensitivity), and the false positive rate.",
    "rubric_id": ""
  },
  {
    "id": "8ce55937df17f49684a9c7c965b82812b840de58eb8be5366f4ba318496e2c03",
    "text": "[Facebook - Easy] There are 50 cards of 5 different colors. Each color has cards numbered between 1 to 10. You pick 2 cards at random. What is the probability that they are not of same color and also not of same number?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should use combinatorics. It should calculate the total number of ways to pick 2 cards. Then, for the second card, it must count the number of available cards that have a different color and a different number from the first card picked. The probability is the ratio of these two counts.",
    "rubric_id": ""
  },
  {
    "id": "b3c18418fa1d090e3d956e9335f857d73d287f658dc6ce69f3adbac4fc081a30",
    "text": "[Tesla - Easy] A fair six-sided die is rolled twice. What is the probability of getting 1 on the first roll and not getting 6 on the second roll?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must recognize that the two rolls are independent events. It should calculate the probability of getting a 1 on the first roll (1/6) and the probability of not getting a 6 on the second roll (5/6), and then multiply these probabilities together.",
    "rubric_id": ""
  },
  {
    "id": "e4b799b50f930f797852cfb80ace546ec160e5996d805ccd9cdc1a5e1b56f8ea",
    "text": "[Facebook - Easy] What is the expected number of rolls needed to see all 6 sides of a fair die?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify this as the Coupon Collector's Problem. The solution involves summing the expected number of trials to get each new outcome. This results in a harmonic series: E = 6/6 + 6/5 + 6/4 + 6/3 + 6/2 + 6/1.",
    "rubric_id": ""
  },
  {
    "id": "ae74eafd05c08c41850b9df508965e21beaebcc01118917823ebcf8eea210e25",
    "text": "[Microsoft - Easy] Three friends in Seattle each told you it's rainy, and each person has a 1/3 probability of lying. What is the probability that Seattle is rainy? Assume the probability of rain on any given day in Seattle is 0.25.",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must use Bayes' theorem. It should calculate the probability that all three friends say it's raining given that it actually is raining, and the probability they all say it's raining given that it is not. These likelihoods are then used with the prior probability of rain to find the posterior probability.",
    "rubric_id": ""
  },
  {
    "id": "596da6f8fd6a6f95f79df0bcefbd0e855ee4276130aa1a64121a9739dcd82633",
    "text": "[Uber - Easy] Say you roll three dice, one by one. What is the probability that you obtain 3 numbers in a strictly increasing order?",
    "domain": "technical-probability",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should use combinatorics. First, choose 3 distinct numbers from {1, 2, 3, 4, 5, 6}. There is only one way to arrange these 3 chosen numbers in strictly increasing order. The total number of outcomes is 6*6*6. The probability is (6 choose 3) / 6^3.",
    "rubric_id": ""
  },
  {
    "id": "df9c4223f5e99116768810e1306735d83055539b635a7e0bb5c6cd005371a879",
    "text": "[Bloomberg - Medium] Three ants are sitting at the corners of an equilateral triangle. Each ant randomly picks a direction and starts moving along the edge of the triangle. What is the probability that none of the ants collide? Now, what if it is k ants on all k corners of an equilateral polygon?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must recognize that a collision is avoided only if all ants move in the same direction (all clockwise or all counter-clockwise). For k ants, each with 2 choices, there are 2^k total outcomes. Only 2 of these (all clockwise, all counter-clockwise) are collision-free. The probability is 2 / 2^k.",
    "rubric_id": ""
  },
  {
    "id": "2836b60c1279154ee9c94d4fc9b9d316a6437cc0a9ea09e3bf7726c334d13c0f",
    "text": "[Two Sigma - Medium] What is the expected number of coin flips needed to get two consecutive heads?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should be solved using expected value calculations, possibly by setting up a system of linear equations based on the state of the game (e.g., no recent heads, one recent head). The final expected number of flips is 6.",
    "rubric_id": ""
  },
  {
    "id": "00d70e03f44333cf7ddec887c056f7b420c545125ceec35a3aa93530382c1ebf",
    "text": "[Amazon - Medium] How many cards would you expect to draw from a standard deck before seeing the first ace?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer can be found using symmetry and linearity of expectation. Imagine the 48 non-ace cards arranged in a row. The 4 aces divide these cards into 5 groups. By symmetry, each group is expected to have the same size (48/5). The number of cards drawn before the first ace is the size of the first group, so the expected value is 48/5 + 1 (for the ace itself) = 53/5.",
    "rubric_id": ""
  },
  {
    "id": "7d2de0bdd6f128b4be1c6e6451d34fc4cab1958ef181d9e1cc887c4173b47ab4",
    "text": "[Robinhood - Medium] A and B are playing a game where A has n+1 coins, B has n coins, and they each flip all of their coins. What is the probability that A will have more heads than B?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should use a symmetry argument. Consider the first n coins of player A. By symmetry, the probability that A has more heads than B in these n coins is equal to the probability that B has more heads than A. The outcome depends entirely on A's (n+1)th coin. If it's tails, the probabilities are equal. If it's heads, A is guaranteed to not have fewer heads than B. The final probability is 1/2.",
    "rubric_id": ""
  },
  {
    "id": "698fe2c25e42ba469d17c72972357bf1a98e57cc9fa165c284b868643de19029",
    "text": "[Airbnb - Medium] Say you are given an unfair coin, with an unknown bias towards heads or tails. How can you generate fair odds using this coin?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the Von Neumann method. This involves flipping the coin twice. If the outcomes are the same (HH or TT), discard them and repeat. If the outcomes are different (HT or TH), use the first outcome of the pair as the result. Since HT and TH have the same probability, this generates a fair 50/50 outcome.",
    "rubric_id": ""
  },
  {
    "id": "2c23d2c5365381d657823c6da80d3fde916ef2d30c69bc7e589db3583115d6eb",
    "text": "[Quora - Medium] Say you have N i.i.d. draws of a normal distribution with parameters \u03bc and \u03c3. What is the probability that k of those draws are larger than some value Y?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must frame this as a binomial probability problem. First, it should calculate the probability 'p' that a single draw from the normal distribution is greater than Y (by standardizing Y and using the Z-table or CDF). Then, it must use the binomial probability formula to find the probability of getting exactly 'k' successes in 'N' trials.",
    "rubric_id": ""
  },
  {
    "id": "ae175a84f6731037351c117e2214f39817047d5297ad92e28ef892b8cd261e7d",
    "text": "[Spotify - Hard] A fair die is rolled n times. What is the probability that the largest number rolled is r, for each r in 1..6?",
    "domain": "technical-probability",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must use the cumulative distribution function approach. The probability that the max roll is r is equal to P(all rolls <= r) - P(all rolls <= r-1). This can be calculated as (r/6)^n - ((r-1)/6)^n.",
    "rubric_id": ""
  },
  {
    "id": "79a0f836c03c2e933858c561796b887fdb7bbc57c3d797e46aac00eaadef18b8",
    "text": "[Snapchat - Hard] There are two groups of n users, A and B, and each user in A is friends with those in B and vice versa. Each user in A will randomly choose a user in B as their best friend and each user in B will randomly choose a user in A as their best friend. If two people have chosen each other, they are mutual best friends. What is the probability that there will be no mutual best friendships?",
    "domain": "technical-probability",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should approach this using the principle of inclusion-exclusion or by calculating the probability of the complement event. A simpler approach is to see that for a given user in A, the chance that their chosen best friend in B also chooses them is 1/n. The probability of no mutual friendships can be approximated by (1 - 1/n)^n, which approaches 1/e as n becomes large.",
    "rubric_id": ""
  },
  {
    "id": "9f2db9b8f4eea4012af1abfe0e3cb9f816ec18ce16d056d8354a2619925a3a49",
    "text": "[Tesla - Hard] Suppose there is a new vehicle launch upcoming. Initial data suggests that any given day there is either a malfunction with some part of the vehicle or possibility of a crash, with probability p which then requires a replacement. Additionally, each vehicle that has been around for n days must be replaced. What is the long-term frequency of vehicle replacements?",
    "domain": "technical-probability",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should frame this as a renewal process or a Markov chain problem. The long-term frequency of replacement is the reciprocal of the expected lifetime of a vehicle. The expected lifetime is the sum of probabilities of surviving up to day k, which can be calculated using the given probabilities p and the fixed lifetime n.",
    "rubric_id": ""
  },
  {
    "id": "94630465b52c19a1f40879ad755f5aa5a5bbec52df3985c9ddcea17c68682ff9",
    "text": "[Facebook - Easy] How would you explain a confidence interval to a non-technical audience?",
    "domain": "behavioral-statistics",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must use a simple analogy. It should explain a confidence interval as a 'range of plausible values' for a true metric. A good explanation would be: 'We are 95% confident that the true average time users spend on our site is between 10 and 12 minutes.' It should emphasize it's a measure of certainty in our estimate, not a probability about the true value.",
    "rubric_id": ""
  },
  {
    "id": "6b88d39b0984aff07730381474ce94d67279a4947e090c32c2089939be1b0df6",
    "text": "[Two Sigma - Easy] Say you are running a multiple linear regression and believe there are several predictors that are correlated. How will the results of the regression be affected if they are indeed correlated? How would you deal with this problem?",
    "domain": "technical-statistics",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify the problem as multicollinearity. It should state that this will inflate the variance of the coefficient estimates, making them unstable and hard to interpret. To deal with it, one could remove one of the correlated predictors, combine them, or use a regularization technique like Ridge regression.",
    "rubric_id": ""
  },
  {
    "id": "3c26b85b94cbf75eed82d2c59de796522c73d6169bec24c67edb0301c33edc91",
    "text": "[Uber - Easy] Describe p-values in layman's terms.",
    "domain": "behavioral-statistics",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must use a non-technical analogy. It should explain a p-value as a measure of surprise. A small p-value means our observed data would be very surprising if our initial assumption (the null hypothesis) were true, so we might doubt our assumption.",
    "rubric_id": ""
  },
  {
    "id": "fa735a7bb0f9643880774eaf55eb143d8873e4413bafa01fc317d667d1911a2e",
    "text": "[Facebook - Easy] How would you build and test a metric to compare two user's ranked lists of movie/tv show preferences?",
    "domain": "technical-statistics",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should suggest a rank correlation coefficient. Good metrics to mention are Spearman's rank correlation coefficient or Kendall's Tau. These metrics measure the similarity in the ordering of the two lists, independent of the actual rating values.",
    "rubric_id": ""
  },
  {
    "id": "99ca3b46501617dfbb977c13c8e3884fefc1fa4309fe7b27dd786638deeaa4df",
    "text": "[Microsoft - Easy] Explain the statistical background behind power.",
    "domain": "behavioral-statistics",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define statistical power as the probability of correctly rejecting a false null hypothesis (i.e., avoiding a Type II error). It should explain that power depends on the sample size, effect size, and significance level (alpha).",
    "rubric_id": ""
  },
  {
    "id": "f68cdb6e55ffacc97e7abec20606612dcf7757b887ed6a70aba0022091ed9e6b",
    "text": "[Twitter - Easy] Describe A/B testing. What are some common pitfalls?",
    "domain": "behavioral-statistics",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define A/B testing as a controlled experiment to compare two versions (A and B) of a product to see which performs better. It must also list common pitfalls, such as not running the test long enough, peeking at results early, or not accounting for multiple comparisons.",
    "rubric_id": ""
  },
  {
    "id": "808d490a8ce4ca4eeef292efc6192b5b2ce50f6805ca344378d759646d10644c",
    "text": "[Google - Medium] How would you derive a confidence interval from a series of coin tosses?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the process for calculating a confidence interval for a proportion. This involves calculating the sample proportion of heads, the standard error of the proportion, and then using a critical value from the normal distribution (for large samples) to construct the interval: p_hat +/- z * SE.",
    "rubric_id": ""
  },
  {
    "id": "890f0fa2bfd2a5ffe54f7a71e2d38442d4eee3409768904fcab6d921ffb61778",
    "text": "[Stripe - Medium] Say you model the lifetime for a set of customers using an exponential distribution with parameter \u03bb, and you have the lifetime history (in months) of n customers. What is your best guess for \u03bb?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the best guess for the rate parameter \u03bb of an exponential distribution is the reciprocal of the sample mean lifetime. This is the maximum likelihood estimate (MLE) for \u03bb.",
    "rubric_id": ""
  },
  {
    "id": "5b5ce3d6d06716bce9bc858f55cc4265b88941737facd06a708db7e3f9345f6c",
    "text": "[Lyft - Medium] Derive the mean and variance of the uniform distribution U(a, b).",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly derive the mean and variance using integration. The mean is the integral of x*f(x) over the interval [a, b], which results in (a+b)/2. The variance is the integral of (x-mean)^2*f(x), which results in (b-a)^2/12.",
    "rubric_id": ""
  },
  {
    "id": "4bfdf7b21bf2147af70a9c3459604f92ed10f8f2a447c98794db4e3f5230366d",
    "text": "[Google - Medium] Say we have X ~ Uniform(0, 1) and Y ~ Uniform(0, 1). What is the expected value of the minimum of X and Y?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the cumulative distribution function (CDF) method. It should first find the CDF of Z = min(X, Y), which is P(Z <= z) = 1 - P(Z > z) = 1 - P(X > z)P(Y > z). From the CDF, it can find the PDF and then calculate the expected value by integration, which is 1/3.",
    "rubric_id": ""
  },
  {
    "id": "4e58f1d187a3885e75e92bbb4716edccf651d65694bd9d366302ec7e676d9719",
    "text": "[Spotify - Medium] You sample from a uniform distribution [0, d] n times. What is your best estimate of d?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the maximum value of the sample as the best estimate for d. This is the maximum likelihood estimate (MLE). A slightly better, unbiased estimate is ((n+1)/n) * max(sample), but the sample maximum is a sufficient starting point.",
    "rubric_id": ""
  },
  {
    "id": "19a09fe8829115feb5bfc1b6f34ba6171f2a760793aec14e47f1a715a2eafcdc",
    "text": "[Quora - Medium] You are drawing from a normally distributed random variable X ~ N(0, 1) once a day. What is the approximate expected number of days until you get a value of more than 2?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must frame this as a geometric distribution problem. First, it should estimate the probability 'p' of getting a value > 2 from a standard normal distribution (which is about 2.5% or 0.025). The expected number of trials until the first success in a geometric distribution is 1/p, so the answer is approximately 1/0.025 = 40 days.",
    "rubric_id": ""
  },
  {
    "id": "91e3b9518890256f1dc5d3eb4e846deca390d6eea6105ce794fa63a72cfedcd0",
    "text": "[Facebook - Medium] Derive the expectation for a geometric distributed random variable.",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly set up the summation for the expected value of a geometric distribution, E[X] = sum(k * p * (1-p)^(k-1)) for k=1 to infinity. The derivation should then show how this sum evaluates to 1/p.",
    "rubric_id": ""
  },
  {
    "id": "e2917acc18e645c93c56a88721ae623d6e5c95fa961141e84aed13b538bd81b8",
    "text": "[Google - Medium] A coin was flipped 1000 times, and 550 times it showed up heads. Do you think the coin is biased? Why or why not?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use a hypothesis test for a proportion. It should state the null hypothesis (the coin is fair, p=0.5) and the alternative (p != 0.5). It should then calculate a z-statistic for the observed proportion (0.55) and find the corresponding p-value. Since the p-value is small, it would conclude that the coin is likely biased.",
    "rubric_id": ""
  },
  {
    "id": "0615e767a9f460f64b121279a4c146a9a7c4013aa906dfa8221299859253e5b2",
    "text": "[Robinhood - Medium] Say you have n integers 1...n and take a random permutation. For any integers i, j let a swap be defined as when the integer i is in the jth position, and vice versa. What is the expected value of the total number of swaps?",
    "domain": "technical-statistics",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should use linearity of expectation. For any pair (i, j), define an indicator variable for the event that i is in position j and j is in position i. The probability of this event is 1/(n*(n-1)). Summing the expectation of this indicator over all pairs (n choose 2) gives an expected value of 1/2.",
    "rubric_id": ""
  },
  {
    "id": "f2addd0794a4ddfbe776c9e4915a8f73b07dab1925c78e5e8414e404ed8bad64",
    "text": "[Uber - Hard] What is the difference between MLE and MAP? Describe it mathematically.",
    "domain": "technical-statistics",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must differentiate between Maximum Likelihood Estimation (MLE) and Maximum a Posteriori (MAP) estimation. MLE finds parameters that maximize the likelihood P(Data|Params). MAP finds parameters that maximize the posterior probability P(Params|Data), which, by Bayes' theorem, is proportional to P(Data|Params) * P(Params). MAP incorporates a prior belief about the parameters.",
    "rubric_id": ""
  },
  {
    "id": "15eea047c9ed231d75b82e72cbfabf9f0cb2926eb7f3d058e805e7d6d1c11179",
    "text": "[Google - Hard] Say you have two subsets of a dataset for which you know their means and standard deviations. How do you calculate the blended mean and standard deviation of the total dataset? Can you extend it to K subsets?",
    "domain": "technical-statistics",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide the formulas for combining means and variances. The blended mean is a weighted average of the individual means. The blended variance is more complex and requires a formula that accounts for both the within-group and between-group variance. This can be extended to K subsets.",
    "rubric_id": ""
  },
  {
    "id": "ba2e338e7fd18c4c26575b1ddbda839e41a50defb3c1881b02bc587efc7e0a18",
    "text": "[Lyft - Hard] How do you randomly sample a point uniformly from a circle with radius 1?",
    "domain": "technical-statistics",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must address the non-uniformity of simply picking a random angle and radius. The correct method involves generating a random angle theta from [0, 2pi] and a random value u from [0, 1]. The radius should be the square root of u to ensure uniform spatial distribution. The point is then (sqrt(u)*cos(theta), sqrt(u)*sin(theta)).",
    "rubric_id": ""
  },
  {
    "id": "8fc67e04dc00ffa8836e02391ced73c8b6622e09a41d4e029db65764865cb0dd",
    "text": "[Two Sigma - Hard] Say you continually sample from some i.i.d. uniformly distributed (0, 1) random variables until the sum of the variables exceeds 1. How many times do you expect to sample?",
    "domain": "technical-statistics",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must state the surprising result that the expected number of samples is 'e' (Euler's number). This is a classic probability problem that can be solved with integrals or by recognizing its connection to renewal processes.",
    "rubric_id": ""
  },
  {
    "id": "bfc57f14c0b1f503c80dcd24c8bf1ca2bdbf50ef329fd1d7059cb4cec50ab2ea",
    "text": "[Uber - Hard] Given a random Bernoulli trial generator, how do you return a value sampled from a normal distribution",
    "domain": "technical-statistics",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should suggest that a Bernoulli generator can be used to create a uniform random number generator (by generating a sequence of bits). Then, it must describe a method like the Box-Muller transform to convert two independent uniform random variables into two independent standard normal random variables.",
    "rubric_id": ""
  },
  {
    "id": "e9c43981613c1d5fd95207c313a0a65401ba552e1c8858a6fac401f7320bc023",
    "text": "What do you understand about linear regression?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define linear regression as a supervised learning algorithm that models the linear relationship between a dependent variable and one or more independent variables. It should mention the goal is to find the best-fitting line that minimizes the sum of squared errors.",
    "rubric_id": ""
  },
  {
    "id": "44d56fe099b4ff9cd87a79c83ce5c91fa9402c9bc1651b2cae434a69649f0312",
    "text": "What do you understand by logistic regression?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define logistic regression as a classification algorithm used when the dependent variable is binary. It should explain that it models the probability of a class by passing a linear combination of inputs through a sigmoid function.",
    "rubric_id": ""
  },
  {
    "id": "125668c84901340720283f5dfeceefed876eb053968fc6d571673abaf5d1f660",
    "text": "What is a confusion matrix?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a confusion matrix as a table used to evaluate the performance of a classification model. It must describe the four components: true positives, true negatives, false positives, and false negatives, and how they show where the model is making errors.",
    "rubric_id": ""
  },
  {
    "id": "2387a9e7238359ba91dc26a3ffccf7b6b2f58c409b5ce661153505712c4a0272",
    "text": "What do you understand about the true-positive rate and false-positive rate?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both rates. The True Positive Rate (also called sensitivity or recall) is the proportion of actual positives that are correctly identified. The False Positive Rate is the proportion of actual negatives that are incorrectly identified as positive.",
    "rubric_id": ""
  },
  {
    "id": "161882b31807f057e3d586e50795eba9a069dcfa56c21e437c0635f7440ebee8",
    "text": "How is Data Science different from traditional application programming?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between rule-based and data-driven approaches. Traditional programming involves explicitly writing rules for the computer to follow. Data science involves using algorithms to learn the rules automatically from data.",
    "rubric_id": ""
  },
  {
    "id": "5454c71c35bd07a37474fddd0a0c10c2da2fbb04e4f4e3eb82414e00feccb468",
    "text": "Explain the differences between supervised and unsupervised learning.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the use of labeled data. Supervised learning uses labeled data (input-output pairs) for tasks like classification and regression. Unsupervised learning uses unlabeled data to find inherent patterns, such as in clustering or dimensionality reduction.",
    "rubric_id": ""
  },
  {
    "id": "5805a756f8a02ad10a84321901d0c46a7658b0a4ec110bf70633a7adec37f9a8",
    "text": "What is the difference between the long format data and wide format data?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the two data layouts. Wide format has one row per subject, with observations for different times or conditions in separate columns. Long format has multiple rows per subject, with one row for each time point or condition.",
    "rubric_id": ""
  },
  {
    "id": "54d3c9f78be21b9f6210bd2a6f112a7af87553ef49f3c6e6038035b8fc41be0c",
    "text": "Mention some techniques used for sampling. What is the main advantage of sampling?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the main advantage of sampling is to analyze a subset of a population to make inferences about the whole, which is more efficient. It should list different techniques, such as simple random sampling, stratified sampling, and cluster sampling.",
    "rubric_id": ""
  },
  {
    "id": "dd27cf694e3c3b836b00ce56498332f725ce3bbea4ec67e844d58cbd3ab9298c",
    "text": "What is bias in Data Science?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias as the error introduced by approximating a real-world problem with an overly simple model. High bias leads to underfitting, where the model fails to capture the underlying patterns in the data.",
    "rubric_id": ""
  },
  {
    "id": "d0ed62cbc97a4ef3d118e096832e29e2ba08823c2857cc6829b0e02b04d20484",
    "text": "What is dimensionality reduction?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define dimensionality reduction as the process of reducing the number of input variables (features) in a dataset. It should mention the main goals: reducing computational complexity, mitigating overfitting, and improving interpretability.",
    "rubric_id": ""
  },
  {
    "id": "71aa41622dc238fbfb00e039157f2f25cb6a8976b1eb5452bfb83c142eaa199e",
    "text": "Why is Python used for Data Cleaning in DS?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must highlight the powerful libraries available in Python for data manipulation. It should specifically mention the Pandas library and its DataFrame structure, which makes tasks like handling missing values, filtering data, and transforming columns very efficient.",
    "rubric_id": ""
  },
  {
    "id": "bbcd2b83686dbb3f34a777e7187a64dafaf0bbce2371b7e2944be883e98fc49f",
    "text": "Why is R used in Data Visualization?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must point to R's strong ecosystem for statistical graphics. It should specifically mention the `ggplot2` package and its 'grammar of graphics' philosophy, which allows for the creation of complex and publication-quality visualizations with concise code.",
    "rubric_id": ""
  },
  {
    "id": "d9b8a8ebb84dc6ffa59782c60b70ebfbb939c97449784c0e083b98f7568328e4",
    "text": "What are the popular libraries used in Data Science?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list key libraries from the Python data science stack. Check for mentions of Pandas for data manipulation, NumPy for numerical computation, Matplotlib/Seaborn for visualization, and Scikit-learn for machine learning.",
    "rubric_id": ""
  },
  {
    "id": "fb26a48f7bab1f9432d647364536dfd06f2d5051184d85479bbd5e22db3c3b64",
    "text": "What is variance in Data Science?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define variance as the error from a model's sensitivity to small fluctuations in the training data. High variance means the model is too complex and captures noise, leading to overfitting and poor performance on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "84208d4d1ed9f445b43596f8b3cb44cb88efcd42b5f6213011e9a04ccd735bde",
    "text": "What is pruning in a decision tree algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define pruning as a technique to reduce the size of a decision tree by removing sections of the tree that are non-critical and may lead to overfitting. The goal is to improve the tree's generalization performance on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "01d00c2f79e2f638d8e0803394c21325d78a351ac6d8c6f8dcbd17e7bb8f1928",
    "text": "What is entropy in a decision tree algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define entropy as a measure of impurity or disorder in a set of data. In a decision tree, it is used to decide which feature to split on, with the goal of choosing the split that results in the largest decrease in entropy (i.e., the highest information gain).",
    "rubric_id": ""
  },
  {
    "id": "a8c001519a4434573e8b90a162509c3c60accae9dfa4c5a83c6f33e3919c3029",
    "text": "What information is gained in a decision tree algorithm?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define information gain as the reduction in entropy achieved by splitting the data on a particular feature. The decision tree algorithm selects the feature that provides the highest information gain at each node to create the most effective splits.",
    "rubric_id": ""
  },
  {
    "id": "e15df1d2f68b3b5172f08428d4d30e95e954cfd8f916b69a4032e018c9f5b018",
    "text": "What is k-fold cross-validation?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define k-fold cross-validation as a technique to evaluate a model's performance more robustly. It should describe the process of splitting the data into 'k' folds, then iteratively training the model on k-1 folds and testing on the remaining fold, and finally averaging the results.",
    "rubric_id": ""
  },
  {
    "id": "2e6397b75c276e0df500509a4b55c1625ef4883f60b97bfe04465413564cf695",
    "text": "Explain how a recommender system works.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the main approaches to recommendation systems. It should explain collaborative filtering (recommending based on what similar users like) and content-based filtering (recommending items with similar attributes to what a user has liked in the past).",
    "rubric_id": ""
  },
  {
    "id": "c4fb490fdc3a1749f6283ac97b38be45d43f07a6eea3eda14b47fd5ffa173f87",
    "text": "What is a normal distribution?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the normal distribution as a continuous probability distribution characterized by its symmetric, bell-shaped curve. It should mention that it is defined by its mean and standard deviation.",
    "rubric_id": ""
  },
  {
    "id": "a8df8287eea6566cc627cc0ee2e45b908e5c33ccbc59e2eb9b70023bdf0d80d6",
    "text": "What is Deep Learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define deep learning as a subfield of machine learning based on artificial neural networks with multiple layers (deep architectures). It should emphasize its ability to learn hierarchical representations of data, making it effective for complex tasks like image and speech recognition.",
    "rubric_id": ""
  },
  {
    "id": "d3b60032a9957c5702903c92fac8a37bd29d66d2e232151c9204d5ff610ef6a0",
    "text": "What is an RNN (recurrent neural network)?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define an RNN as a type of neural network designed to handle sequential data. The key feature to mention is its internal loop (recurrent connection), which allows information to persist, giving the network a form of memory.",
    "rubric_id": ""
  },
  {
    "id": "9d0266480e9ef67a705fd7c7c7e70a7753f7fe42dd0ed265218e929160550667",
    "text": "Explain selection bias.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define selection bias as a systematic error that occurs when the sample population is not representative of the target population, leading to distorted results. It should provide an example, such as a poll where participants self-select, which may not reflect the broader population's views.",
    "rubric_id": ""
  },
  {
    "id": "3a7537ed9f6d6a18e3d4f4421e24001639af7bcf8fad9acedfc90522be89afde",
    "text": "What is the ROC curve?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the ROC curve (Receiver Operating Characteristic) as a plot that illustrates the performance of a binary classifier. It should state that it plots the True Positive Rate against the False Positive Rate at various classification thresholds, and that a larger area under the curve (AUC) indicates a better model.",
    "rubric_id": ""
  },
  {
    "id": "1974db752411b89191b5717f18b5b2fcebf44dbc137240fb23a60318d21eeb1f",
    "text": "What do you understand by a decision tree?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a decision tree as a supervised learning model that uses a tree-like structure of decisions. It should explain that each internal node represents a test on a feature, each branch represents the outcome of the test, and each leaf node represents a class label.",
    "rubric_id": ""
  },
  {
    "id": "74ad8b1ff15729bde84a06d9d25904111b05d5e1eea5cbeb5e899fe1b380e020",
    "text": "What do you understand by a random forest model?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a random forest as an ensemble learning method that operates by constructing multiple decision trees at training time. The final prediction is made by taking the majority vote (for classification) or average (for regression) of the individual trees, which helps to reduce overfitting.",
    "rubric_id": ""
  },
  {
    "id": "ee8bfc551aac6a65edcc490276172d7a283e2925487eaea6b5f9d3c6997f1594",
    "text": "Two candidates, Aman and Mohan appear for a Data Science Job interview. The probability of Aman cracking the interview is 1/8 and that of Mohan is 5/12. What is the probability that at least one of them will crack the interview?",
    "domain": "technical-probability",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must solve for P(A or B). The correct approach is to use the formula P(A or B) = P(A) + P(B) - P(A and B). Assuming independence, P(A and B) = P(A) * P(B).",
    "rubric_id": ""
  },
  {
    "id": "aa6c73c2e05c09a7ffe622bd471fe99c8e6ec02028e6231a71b31aa4c1e9b2af",
    "text": "How is Data modeling different from Database design?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the two by abstraction level. Data modeling is a higher-level, conceptual process of defining data elements and their relationships (the 'what'). Database design is the lower-level, physical implementation of that model in a specific database system (the 'how').",
    "rubric_id": ""
  },
  {
    "id": "2f4fc9b74ba4a0d3b4e9f9d468bb5dfe9bcb8cc32eaed6712b88493094beafba",
    "text": "What is precision?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define precision as a classification metric that measures the accuracy of positive predictions. The formula to check for is: Precision = True Positives / (True Positives + False Positives).",
    "rubric_id": ""
  },
  {
    "id": "1ae85dbc156f455ba0de244048521875558917c26787f2415eb2fe8a3e38fce4",
    "text": "What is a recall?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define recall (also known as sensitivity or true positive rate) as a classification metric that measures the model's ability to find all the actual positive samples. The formula to check for is: Recall = True Positives / (True Positives + False Negatives).",
    "rubric_id": ""
  },
  {
    "id": "f5c5f7bbbe018c547cb6cb45bcd699a3ade94f1b00d425c9a342e1ea7f6472f7",
    "text": "What is the F1 score and how to calculate it?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the F1 score as the harmonic mean of precision and recall. It should state that it provides a single score that balances both metrics and is useful for imbalanced datasets. The formula is 2 * (Precision * Recall) / (Precision + Recall).",
    "rubric_id": ""
  },
  {
    "id": "27c52134bf09c4bb8894ea39f9b642728885958158514ef784b874d5cdf09fbb",
    "text": "What is a p-value?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the p-value as the probability of observing results as extreme as, or more extreme than, the current results, assuming the null hypothesis is true. It should also state that a small p-value is used as evidence to reject the null hypothesis.",
    "rubric_id": ""
  },
  {
    "id": "7d87dfab41d9c50226b978dfa6af4dd92b6237de3df0bfa7b4ac5f22254264ca",
    "text": "Why do we use p-value?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the p-value is used in hypothesis testing to help decide whether to reject the null hypothesis. It quantifies the statistical significance of the observed results, providing a threshold for making a decision.",
    "rubric_id": ""
  },
  {
    "id": "6a13a38090c621ee30b422e8d165d37d2ecd977436536baadddc677c010f5f41",
    "text": "What is the difference between an error and a residual error?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between the unobservable true error and the observable residual. The error is the difference between the observed value and the true (unobservable) population value. The residual is the difference between the observed value and the value predicted by the model.",
    "rubric_id": ""
  },
  {
    "id": "ef313f5cbb6d053563cd904dad265f8c99cc9da807e2a3430d63df3b86a8497d",
    "text": "Why do we use the summary function?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should explain that a summary function (like in R or `describe()` in pandas) is used to get a quick statistical overview of a dataset or variable. It must mention the key statistics it provides, such as mean, median, quartiles, min, and max.",
    "rubric_id": ""
  },
  {
    "id": "032ec4c00a0530d0dbb641b32fcd986f97dc7af82bb72051fd65e353b89aa14f",
    "text": "How are Data Science and Machine Learning related to each other?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify Machine Learning as a subfield of Data Science. Data Science is the broad field of extracting insights from data, which includes processes like data collection and cleaning. Machine Learning is the part of Data Science that focuses on building predictive models.",
    "rubric_id": ""
  },
  {
    "id": "f10ee3d7bd683cfb3431f0294ab8d92a81315d00509b851f3bc3165119409ffb",
    "text": "Explain univariate, bivariate, and multivariate analyses.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the analyses based on the number of variables. Univariate analysis involves one variable (e.g., calculating the mean). Bivariate analysis involves two variables (e.g., calculating correlation). Multivariate analysis involves more than two variables (e.g., multiple regression).",
    "rubric_id": ""
  },
  {
    "id": "a60058597ee23a3b1a708d80171ed45c5db23f7f943760bd43ef599b8279bbff",
    "text": "How can we handle missing data?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list several common strategies for handling missing data. Key methods to mention include deleting the rows or columns with missing data, or imputing the missing values using a simple statistic (mean, median, mode) or a predictive model.",
    "rubric_id": ""
  },
  {
    "id": "913a68440d5319a53699abe7c2fd62e80daca893ce57a2c223914ceee2236917",
    "text": "What is the benefit of dimensionality reduction?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list the main benefits of reducing the number of features. Check for mentions of faster model training, reduced risk of overfitting (mitigating the curse of dimensionality), and improved model interpretability and performance.",
    "rubric_id": ""
  },
  {
    "id": "18b60a4f88eb7c3d22e1ad803931a90db0529fc7841776180ecc606dc0fcc295",
    "text": "What is a bias-variance trade-off in Data Science?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both bias (error from overly simple models) and variance (error from overly complex models that are too sensitive to training data). It must explain the trade-off: decreasing one tends to increase the other, and the goal is to find a balance that minimizes total error.",
    "rubric_id": ""
  },
  {
    "id": "8d5d14a21740456d673a91776473e692ebeecf64a32e50d197bc58a979318991",
    "text": "What is RMSE?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define RMSE as Root Mean Square Error, a common metric for evaluating regression models. It should explain that it represents the standard deviation of the residuals (prediction errors), and is in the same units as the target variable.",
    "rubric_id": ""
  },
  {
    "id": "47ba38cb1e7f352b835cee9df088f9cb8612dfa82d1e50d575fbda8c5a2c3fe6",
    "text": "What is a kernel function in SVM?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that a kernel function in a Support Vector Machine (SVM) allows the algorithm to find a non-linear decision boundary. It achieves this by implicitly mapping the data to a higher-dimensional space where it becomes linearly separable, without explicitly computing the coordinates in that space (the 'kernel trick').",
    "rubric_id": ""
  },
  {
    "id": "0a7f9d853a852f6f1d8cdae7f06d6e038e125c472913fd328269311fc0f49a04",
    "text": "How can we select an appropriate value of k in k-means?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe a method for choosing the number of clusters, k. The most common method to mention is the 'elbow method,' which involves plotting the within-cluster sum of squares for different values of k and looking for an 'elbow' point where the rate of decrease slows.",
    "rubric_id": ""
  },
  {
    "id": "119436a4e9d512fe50acd2ecca800de6a2c3ddcb22e304fd8f38e04c98defd00",
    "text": "How can we deal with outliers?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list several strategies for dealing with outliers. These should include removing them if they are errors, transforming the data to reduce their impact, or using models that are inherently robust to outliers, such as tree-based models.",
    "rubric_id": ""
  },
  {
    "id": "7a4a0e6da5ad46ecaaf9608316c9ac6b7e128818fc3b4ef2d4b311f2c8b6eaf5",
    "text": "How to calculate the accuracy of a binary classification algorithm using its confusion matrix?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide the correct formula for accuracy based on the components of a confusion matrix. The formula is: Accuracy = (True Positives + True Negatives) / Total Population.",
    "rubric_id": ""
  },
  {
    "id": "e1b7f0b31734aa63ebfecc04b99a0347d60a5a40cae3c32328d30d3b5db3f139",
    "text": "What is ensemble learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define ensemble learning as the technique of combining multiple machine learning models to produce a single, often more accurate and robust, prediction than any individual model.",
    "rubric_id": ""
  },
  {
    "id": "b519c999548062dc38493062349e39b9c8bb546247fe08baf445e0cad532036e",
    "text": "Explain collaborative filtering in recommender systems.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain collaborative filtering as a technique that makes recommendations based on the behavior of similar users. The core idea to look for is 'users who liked item X also liked item Y'.",
    "rubric_id": ""
  },
  {
    "id": "05cc009bf8129f3d39d17cc5efdbf8238b61d1877094864cc10eb7184688b882",
    "text": "Explain content-based filtering in recommender systems.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain content-based filtering as a technique that makes recommendations based on the attributes of items a user has shown interest in. The core idea is to recommend items that are similar in content to items the user has liked before.",
    "rubric_id": ""
  },
  {
    "id": "d837c1e5a99f0aa65b0d36884f372dcb7e4e02e400ef26c15374cf947402cb68",
    "text": "Explain bagging in Data Science.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bagging (Bootstrap Aggregating) as an ensemble technique. It should describe the process of training multiple models in parallel on different bootstrap samples (random samples with replacement) of the training data and then aggregating their predictions.",
    "rubric_id": ""
  },
  {
    "id": "08c254f9ef3c059a6d42ad8a9bff8cc16801bc9e03fb8ec1d12ebcc46dc5f44e",
    "text": "Explain boosting in Data Science.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define boosting as an ensemble technique that builds models sequentially. It should explain that each new model is trained to correct the errors made by the previous models, thereby focusing on the most difficult data points.",
    "rubric_id": ""
  },
  {
    "id": "c665f47e0bfe62ba9e97c3e17862d786f797ba8a9cac67df089a7995ea98319a",
    "text": "Explain stacking in Data Science.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define stacking (stacked generalization) as an ensemble technique that combines multiple different models. It should explain the process of using the predictions of these base models as input features for a final 'meta-model' that learns to make the ultimate prediction.",
    "rubric_id": ""
  },
  {
    "id": "cfd44482adf2abaeffd66576ed4b109f6d15a4c5a3c3b2c2823ad4a3e5a04420",
    "text": "Explain how Machine Learning is different from Deep Learning.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify Deep Learning as a specific subfield of Machine Learning. The key difference to mention is that deep learning uses neural networks with many layers (deep architectures) and can perform automatic feature extraction, whereas traditional machine learning often requires manual feature engineering.",
    "rubric_id": ""
  },
  {
    "id": "2ca1899a0c2ef9af0c40e961de5bbbdd5ac88747ef9c7d8453aaf58ed5ee396b",
    "text": "What does the word 'Naive' mean in Naive Bayes?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that 'Naive' refers to the algorithm's strong, or 'naive,' assumption that all the features in the dataset are mutually independent of each other, given the class.",
    "rubric_id": ""
  },
  {
    "id": "9ab3efae1d3e6f52fc50d87726de7158f027ea3f5de569de5d93d27ddfac4493",
    "text": "From the below given 'diamonds' dataset, extract only those rows where the 'price' value is greater than 1000 and the 'cut' is ideal.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate the ability to filter a dataset based on multiple conditions. It should involve a clear method, such as using boolean indexing in a pandas DataFrame, to select rows that satisfy both `price > 1000` and `cut == 'Ideal'`.",
    "rubric_id": ""
  },
  {
    "id": "dd3a3460a906c9b76a006f61df7831b4a6efc1d37a1bf1ed4171d0cb9816546a",
    "text": "Make a scatter plot between 'price' and 'carat' using ggplot. 'Price' should be on the y-axis, 'carat' should be on the x-axis, and the 'color' of the points should be determined by 'cut.'",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate knowledge of creating a scatter plot with specific aesthetic mappings. Using a library like ggplot2 or Matplotlib/Seaborn, it should correctly assign 'carat' to the x-axis, 'price' to the y-axis, and map the 'cut' variable to the color aesthetic.",
    "rubric_id": ""
  },
  {
    "id": "9821e05c90d5a633836be8a18ae79f480d180d815495d1619f02bbca0dbb067a",
    "text": "Introduce 25 percent missing values in this \u2018iris' dataset and impute the 'Sepal.Length' column with 'mean' and the 'Petal.Length' column with 'median.'",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe a two-step process. First, it should introduce missing values (NaNs) randomly into the specified columns. Second, it must demonstrate how to fill these missing values, correctly using the mean for 'Sepal.Length' and the median for 'Petal.Length'.",
    "rubric_id": ""
  },
  {
    "id": "ff798a28d99deab115134c6dab7e716876b09fd624044b6441a303b7fe41560f",
    "text": "Implement simple linear regression in R on this 'mtcars' dataset, where the dependent variable is 'mpg' and the independent variable is \u2018disp.'",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must show the correct procedure for building a simple linear regression model. This includes splitting the data into training and testing sets, fitting the model on the training data using the appropriate function (e.g., `lm()` in R), and making predictions on the test set.",
    "rubric_id": ""
  },
  {
    "id": "0f4658e0dab2df925582baa7ba6cc67a98f2dc429887b04f9d7f26b4d916d9a7",
    "text": "Calculate the RMSE values for the model building.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide the correct steps to calculate Root Mean Square Error (RMSE). This involves calculating the difference between actual and predicted values (residuals), squaring these differences, taking the mean of the squares, and finally taking the square root.",
    "rubric_id": ""
  },
  {
    "id": "6ec769bd45156d377245864254d747f2dcd14371eba9ade9927e7bdcf3cc5165",
    "text": "Implement simple linear regression in Python on this 'Boston' dataset where the dependent variable is 'medv' and the independent variable is 'lstat.'",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate the correct workflow for building a linear regression model in Python. This includes loading the data (e.g., with pandas), splitting it into training and testing sets, creating and fitting a model object (e.g., from scikit-learn), and making predictions.",
    "rubric_id": ""
  },
  {
    "id": "064b9c368b408e4952ddb228fe8a2771d37f399881513d8d9f1403ce4e8c80a2",
    "text": "Implement logistic regression on this \u2018heart' dataset in R where the dependent variable is 'target' and the independent variable is 'age.'",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate how to build a logistic regression model. This includes using the correct function (e.g., `glm()` in R with `family='binomial'`), correctly specifying the formula (`target ~ age`), and interpreting the model summary to assess the relationship.",
    "rubric_id": ""
  },
  {
    "id": "23137fedda93c14d97cb7f58a75d755ad64a89189a3c2f455a43a90f03e9aca6",
    "text": "Build an ROC curve for the model built",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the process of generating an ROC curve. This involves getting the predicted probabilities from the logistic regression model, and then using a library function to plot the True Positive Rate vs. the False Positive Rate at all possible thresholds.",
    "rubric_id": ""
  },
  {
    "id": "4bb60127c04a0691d48b85cdd9be46a38eb110461e861281b46d6e067f48adb1",
    "text": "Build a confusion matrix for the model where the threshold value for the probability of predicted values is 0.6, and also find the accuracy of the model.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must show how to convert predicted probabilities into class labels using a specified threshold (0.6). It must then generate a confusion matrix comparing these predicted labels to the true labels and use the matrix values to correctly calculate the model's accuracy.",
    "rubric_id": ""
  },
  {
    "id": "3ddc37596e77cfa277c4ced864851524036c399ca8f14ea34007632186734850",
    "text": "Build a logistic regression model on the 'customer_churn' dataset in Python. The dependent variable is 'Churn' and the independent variable is 'MonthlyCharges.' Find the log_loss of the model.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate the workflow for building and evaluating a logistic regression model. This includes splitting the data, fitting the model, predicting probabilities on the test set, and then using a function (e.g., from scikit-learn) to calculate the log-loss metric.",
    "rubric_id": ""
  },
  {
    "id": "82624f47bf238272c90321c8e5e453766c02130ba0a42b91b512d5eb239c84d6",
    "text": "Build a decision tree model on 'Iris' dataset where the dependent variable is 'Species,' and all other columns are independent variables. Find the accuracy of the model built.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must show the correct procedure for training and evaluating a decision tree classifier. This includes splitting the data, training the model using all other features to predict 'Species', making predictions on the test set, and calculating the accuracy score.",
    "rubric_id": ""
  },
  {
    "id": "3884543370fc3019980ad7c2423a9e2c032cc42db78862d79f1acec70233ef77",
    "text": "Build a random forest model on top of this 'CTG' dataset, where 'NSP' is the dependent variable, and all other columns are independent variables.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate the steps to build a random forest model. This includes ensuring the target variable is in the correct format (factor/categorical), splitting the data into training and testing sets, and then training a random forest classifier using the appropriate library function.",
    "rubric_id": ""
  },
  {
    "id": "d1d061b00581f8f1eec4ea45c5282e11185e05de1acee47313acfa359aee27fd",
    "text": "Write a function to calculate the Euclidean distance between two points.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly implement the Euclidean distance formula. It should take two points as input, calculate the sum of the squared differences of their coordinates, and return the square root of that sum.",
    "rubric_id": ""
  },
  {
    "id": "6c2d0ac9388574ef20490d3b4a825409883157340ec8c5da3ad8f1668c3c574b",
    "text": "Write code to calculate the root mean square error (RMSE) given the lists of values as actual and predicted.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly implement the RMSE formula. The code should iterate through the lists to calculate the errors (actual - predicted), square them, find the mean of the squared errors, and finally take the square root.",
    "rubric_id": ""
  },
  {
    "id": "f20d980c393e4a085183a569623d024cd8b32a0921a8167d8058ce5dc6308d16",
    "text": "Mention the different kernel functions that can be used in SVM.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list the most common kernel functions used in Support Vector Machines. Check for mentions of Linear, Polynomial, Radial Basis Function (RBF), and Sigmoid kernels.",
    "rubric_id": ""
  },
  {
    "id": "15b42c8827079fa161c6c2543ef3782865fac4b7ca1cbb5bd3d8185bcd17617a",
    "text": "How to detect if the time series data is stationary?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define stationarity as having a constant mean and variance over time. It should suggest methods for detection, including visual inspection of plots and using statistical tests like the Augmented Dickey-Fuller (ADF) test.",
    "rubric_id": ""
  },
  {
    "id": "de370dd6703cdf0ed52563a7f86300d47a56416c16dec0e5f8e1437cc2f50ab8",
    "text": "Write code to calculate the accuracy of a binary classification algorithm using its confusion matrix.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide code that correctly implements the accuracy formula using the elements of a confusion matrix. The code should extract the true positives and true negatives, sum them, and divide by the total number of observations.",
    "rubric_id": ""
  },
  {
    "id": "f6a4a9ff36e82b3de68590c6657c884c6fff6fcc8acdb1b4ad21ba662bb0c80c",
    "text": "What does root cause analysis mean?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define root cause analysis as a problem-solving method aimed at identifying the fundamental cause of a problem, rather than just addressing the immediate symptoms. The key idea is that eliminating the root cause will prevent the problem from recurring.",
    "rubric_id": ""
  },
  {
    "id": "170f8eeedb86023262b2ab05cfbd7b985392210842af691bcbfe19c81bffcf6b",
    "text": "What is A/B testing?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define A/B testing as a randomized controlled experiment with two variants, A and B. It should explain that its purpose is to use statistical hypothesis testing to determine which variant is more effective at achieving a specific goal.",
    "rubric_id": ""
  },
  {
    "id": "b483273d9b0c08055041ff99993f871f17136497fc40106ddc07c3becb4e0d22",
    "text": "Out of collaborative filtering and content-based filtering, which one is considered better, and why?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should not give a definitive 'better' but should compare the trade-offs. It should explain that collaborative filtering can suffer from the cold-start problem but can produce more novel recommendations. Content-based filtering does not have a cold-start problem for items but may lead to less diverse recommendations.",
    "rubric_id": ""
  },
  {
    "id": "ab423ffc12888b51537111983df2eedf7451ac8fb79c5bb88edfb1fac4803ea5",
    "text": "In the following confusion matrix, calculate precision and recall.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly apply the formulas for precision and recall to the given confusion matrix data. It needs to identify the True Positives, False Positives, and False Negatives from the matrix and plug them into the respective formulas: Precision = TP / (TP + FP) and Recall = TP / (TP + FN).",
    "rubric_id": ""
  },
  {
    "id": "17ce152e93f7f3470abadc17aa7ab8bf8e6681dcee51a2c14993d188d9929065",
    "text": "Write a function that when called with a confusion matrix for a binary classification model returns a dictionary with its precision and recall.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must provide a function that takes a 2x2 matrix as input. Inside the function, it must correctly extract the TP, FP, and FN values based on their positions in the matrix and use them to calculate precision and recall, returning the results in a dictionary.",
    "rubric_id": ""
  },
  {
    "id": "74a7a6ce2dc0d82c221291cda38cb9abb8205b002820e367efd0f6bf9b278101",
    "text": "What is reinforcement learning?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define reinforcement learning as an area of machine learning where an agent learns to make decisions by taking actions in an environment to maximize a cumulative reward signal.",
    "rubric_id": ""
  },
  {
    "id": "e5db3f2ed35130d7b2de6b32a0875d92f84c688e95219b70e3304bf9c839ddd2",
    "text": "Explain TF/IDF vectorization.",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define TF-IDF as Term Frequency-Inverse Document Frequency, a numerical statistic used to reflect how important a word is to a document in a collection. It should explain both components: TF measures how frequently a term appears in a document, while IDF measures how rare the term is across all documents.",
    "rubric_id": ""
  },
  {
    "id": "6047152fe4f491a61055ee1c68482ba1a1c77e115b95bf222bf88fed69f982e0",
    "text": "What are the assumptions required for linear regression?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list the key assumptions of linear regression. Look for: a linear relationship between variables, independence of observations, homoscedasticity (constant variance of residuals), and normality of residuals.",
    "rubric_id": ""
  },
  {
    "id": "29b3ed56ae0bf3b71497dafc214297394a26a118f15a68d6e70466e105bb67fc",
    "text": "What happens when some of the assumptions required for linear regression are violated?",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that violating the assumptions can make the model's coefficient estimates and p-values unreliable. For example, heteroscedasticity can lead to incorrect standard errors, while non-linearity means the model is not capturing the true relationship.",
    "rubric_id": ""
  },
  {
    "id": "b5a6b535429af8c496160c727c7b729396443e81db4de9e2ac899ea30e03ac10",
    "text": "What kind of a neural network will you use in deep learning regression via Keras-TensorFlow? How will you decide the best neural network model for a given problem?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should suggest starting with a simple model, like a Multi-Layer Perceptron (MLP), for a basic regression task. It must explain that the choice of the best model depends on the data's structure (e.g., CNN for images, RNN for sequences) and involves an iterative process of experimentation.",
    "rubric_id": ""
  },
  {
    "id": "7e95be2616f673ec98685e451638a1cae88e803ad1203e92173f4cbb87914caa",
    "text": "Why do we need autoencoders when there are already powerful dimensionality reduction techniques like Principal Component Analysis?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state the key advantage of autoencoders: their ability to learn non-linear transformations. While PCA is limited to linear projections, autoencoders (as neural networks) can capture more complex patterns and relationships in the data.",
    "rubric_id": ""
  },
  {
    "id": "50572c6fd524241691cfdb95b4fbebd60e55ba117296890bf27988594522ca08",
    "text": "Say you have to build a neural network architecture; how will you decide how many neurons and hidden layers are needed for the network?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that there is no fixed rule, and the process is empirical. It should suggest starting with a simple architecture (e.g., one or two hidden layers) and gradually increasing complexity while monitoring for overfitting. The optimal size often depends on the complexity of the problem and the amount of data available.",
    "rubric_id": ""
  },
  {
    "id": "5c8fb4a4a6581c4a50dc0a9838aa0ef84356935b2ab307a84be6b02d6b44f846",
    "text": "Why CNN is preferred over ANN for Image Classification tasks even though it is possible to solve image classification using ANN?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must highlight two key advantages of CNNs: parameter sharing and translation invariance. It should explain that convolutional layers use shared weights to detect features regardless of their position in the image, making them far more efficient and effective for image data than a fully connected ANN.",
    "rubric_id": ""
  },
  {
    "id": "b662b259fef90a3359b2f4cedb83637faac1a19b222054e09d5f76d4e8936500",
    "text": "Why Sigmoid or Tanh is not preferred to be used as the activation function in the hidden layer of the neural network?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify the vanishing gradient problem as the primary reason. It should explain that for inputs far from zero, the gradients of sigmoid and tanh functions become very small, which can stall the learning process in deep networks. ReLU is often preferred to mitigate this.",
    "rubric_id": ""
  },
  {
    "id": "fd8aafca84f3ef6f80bbd94f40ec15dfd2379a114b57d52b84e845cc9f818741",
    "text": "Why does the exploding gradient problem happen?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that the exploding gradient problem occurs in deep networks when the gradients are repeatedly multiplied by values greater than 1 during backpropagation, leading to exponentially large gradients. This makes the weight updates too large and unstable, preventing the model from learning.",
    "rubric_id": ""
  },
  {
    "id": "c0ffb5838ea0ca492b2ae50fee99653d5b18363af9ab6eed7204cc9c0d0459b6",
    "text": "How to fix the constant validation accuracy in CNN model training?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must suggest that constant validation accuracy is a sign of overfitting or a learning problem. It should propose several potential solutions, such as increasing the size of the training dataset, using data augmentation, adding regularization (like dropout), or adjusting the learning rate.",
    "rubric_id": ""
  },
  {
    "id": "cc7a6a19c3d7159e827801e66c56f291d892dc261537177b5f2ab02ba87c82f6",
    "text": "What do you understand by learning rate in a neural network model? What happens if the learning rate is too high or too low?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define the learning rate as a hyperparameter that controls the step size of weight updates during training. It should explain that if it's too high, the model may overshoot the optimal solution and fail to converge. If it's too low, training will be very slow and may get stuck in a local minimum.",
    "rubric_id": ""
  },
  {
    "id": "fffd99effdd6fcdd11c17c2277db338cf9d884abb7ff2e5e5e952a3f4f37bef2",
    "text": "What kind of a network would you prefer \u2013 a shallow network or a deep network for voice recognition?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state a preference for a deep network for a complex task like voice recognition. It should explain that deep networks are better at learning hierarchical representations of features, which is essential for understanding the complex patterns in speech.",
    "rubric_id": ""
  },
  {
    "id": "f44c8febd659596cea547505878a17ef733145ad6748814f8515a73ce2941ea7",
    "text": "Can you train a neural network model by initializing all biases as 0?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must be 'yes'. It should explain that initializing biases to zero is a common and acceptable practice. Unlike weights, zero initialization for biases does not create a symmetry problem that would prevent the network from learning.",
    "rubric_id": ""
  },
  {
    "id": "b1edab6f1cae3f4b5df0e6914ac0923865333913001e1658883a04e7dc9129a6",
    "text": "Can you train a neural network model by initializing all the weights to 0?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must be a clear 'no'. It must explain that initializing all weights to zero would cause all neurons in a layer to learn the exact same features, as they would have identical gradients during backpropagation. This symmetry prevents the network from learning effectively.",
    "rubric_id": ""
  },
  {
    "id": "201863d9c5537f2803a2806187b7b18bf85ad4d86e98d16820a65c9816407679",
    "text": "Why is it important to introduce non-linearities in a neural network?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that without non-linear activation functions, a deep neural network would just be a linear model, regardless of its depth. Non-linearities are essential for the network to be able to learn and approximate complex, non-linear relationships in the data.",
    "rubric_id": ""
  },
  {
    "id": "9e7260da7331cd382297990c5bb93f0d52a386136344d7dd42d7def968be1656",
    "text": "Why dropout is effective in deep networks?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain dropout as a regularization technique to prevent overfitting. It works by randomly dropping neurons during training, which prevents neurons from co-adapting too much and forces the network to learn more robust and redundant features.",
    "rubric_id": ""
  },
  {
    "id": "9d7f9af5f98f929f574fa0f4d6314f58d6b2ad61732407e9863370539fd9f5b3",
    "text": "A deep learning model finds close to 12 million face vectors. How will you find a new face quickly?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must recognize that a linear scan is too slow. It should suggest using an Approximate Nearest Neighbor (ANN) search algorithm. Key techniques to mention are Locality-Sensitive Hashing (LSH) or tree-based methods to efficiently index the vectors and find the closest matches quickly.",
    "rubric_id": ""
  },
  {
    "id": "076a534e99992d2e1338218364669af06fb6a6327028d45720db1240def6af96",
    "text": "What has fostered the implementation and experimentation of powerful neural network architectures in the industry?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should identify two main drivers. First, the availability of large datasets. Second, the development of powerful and parallel computing hardware, specifically GPUs, which have made it feasible to train deep and complex networks.",
    "rubric_id": ""
  },
  {
    "id": "bc5e608fe19ccccb660402f614bc8be78fc11de053b1efb8db7ea60f2d3ab140",
    "text": "Can you build deep learning models based solely on linear regression?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that while technically possible (by using a linear activation function), it is pointless. A composition of linear functions is still a linear function, so a deep network of linear layers has no more expressive power than a single linear layer.",
    "rubric_id": ""
  },
  {
    "id": "338f1aa2bec32d9ecc1b9954dc5ce5ba09da9dde4a4829b9ef827067cfc548e2",
    "text": "When training a deep learning model, you observe that after a few epochs the accuracy of the model decreases. How will you address this problem?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify this as a symptom of overfitting. It should suggest common techniques to address it, such as early stopping (stopping training when validation performance degrades), adding regularization like dropout, or reducing the model's complexity.",
    "rubric_id": ""
  },
  {
    "id": "9212c430f2b3f5ed3818e54fd42a55e96f069c1195854d46945476bc1475d8f5",
    "text": "What is the impact on a model with an improperly set learning rate on weights?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the effects of both too high and too low learning rates. A learning rate that is too high will cause the weight updates to be too large, leading to unstable training and divergence. A rate that is too low will result in very slow learning and a higher risk of getting stuck in a local minimum.",
    "rubric_id": ""
  },
  {
    "id": "02b2d59e736e9b6754061c854d0facd34a59701a70aa46a0fc3bd546117b758e",
    "text": "What do you understand by the terms Batch, Iterations, and Epoch in training a neural network model?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly define all three terms. An epoch is one full pass through the entire training dataset. A batch is a subset of the dataset used in one training step. An iteration is one update of the model's weights, which corresponds to processing one batch.",
    "rubric_id": ""
  },
  {
    "id": "7b2e0bbf9336babee223ca257b05a21f75f6aa3a2dde684767044e7147803698",
    "text": "Is it possible to calculate the learning rate for a model a priori?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should state that it is generally not possible to calculate the optimal learning rate beforehand. It is a hyperparameter that must be found through empirical methods, such as grid search, random search, or using techniques like a learning rate range test.",
    "rubric_id": ""
  },
  {
    "id": "b46f13ed4f7d7adda46622aec0d60b820e98edb114b75517dd38fba18d293e0d",
    "text": "What is the theoretical foundation of neural networks?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must mention the Universal Approximation Theorem. It should explain that this theorem states that a neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function to an arbitrary degree of accuracy.",
    "rubric_id": ""
  },
  {
    "id": "0b81b4b0998882472b21e434caf135b0cba9df587b7e2a9d782cbccbb90e32c0",
    "text": "What are the commonly used approaches to set the learning rate?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common strategies for setting the learning rate. Check for mentions of using a fixed learning rate, using a learning rate schedule (e.g., decay), or using an adaptive learning rate method like Adam or RMSprop.",
    "rubric_id": ""
  },
  {
    "id": "91efc20fe9dc5ce8611aa81869830eca8c449c75266bb61ffe7a3b4e987e2e9c",
    "text": "Is there any difference between neural networks and deep learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clarify that 'deep learning' refers to neural networks with many layers (deep architectures). So, deep learning is a subfield of neural networks, characterized by the depth of the models used.",
    "rubric_id": ""
  },
  {
    "id": "1c68c7c4ea2aa223b17aa86de6fca4cb3be3b5f96a6d67e2477d8aee3f28a1c3",
    "text": "You want to train a deep learning model on a 10GB dataset, but your machine has 4GB RAM. How will you go about implementing a solution to this deep learning problem?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must propose a solution that does not require loading the entire dataset into memory at once. It should describe using a data generator (like those available in Keras or PyTorch) to load the data in batches from the disk during training.",
    "rubric_id": ""
  },
  {
    "id": "37c3cd475c9c832f27b1e90d3255a47e56d01296924ee574a297f02af3eafbc8",
    "text": "How will the predictability of a neural network impact if you use a ReLu activation function and then use the Sigmoid function in the final layer of the network?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should analyze the output range. Using ReLU in hidden layers allows for learning complex patterns. Using a Sigmoid in the final layer will constrain the output of the network to be between 0 and 1, making it suitable for binary classification or predicting probabilities.",
    "rubric_id": ""
  },
  {
    "id": "41825651c9d2e4b6cb33b3215792e8c54d891928953fef98e87618f852ff8137",
    "text": "What are the limitations of using a perceptron?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state the main limitation of a single perceptron: it can only learn linearly separable patterns. It cannot solve problems where the classes are not separable by a straight line, such as the XOR problem.",
    "rubric_id": ""
  },
  {
    "id": "27263db0accad1ddf7818376da42672492c1ce7a0c1fa35227a39229ac4e0c46",
    "text": "How will you differentiate between a multi-class and multi-label classification problem?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the exclusivity of classes. In multi-class classification, each sample belongs to exactly one class out of many. In multi-label classification, each sample can be assigned zero, one, or multiple labels simultaneously.",
    "rubric_id": ""
  },
  {
    "id": "1e83747470d90a57b6c2a1328b9ded1262c884c86acf5f0b22e40242406bba3f",
    "text": "What do you understand by transfer learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define transfer learning as the practice of reusing a model pre-trained on a large, general dataset for a new, specific task. This is beneficial because it leverages the features already learned by the pre-trained model, leading to better performance with less data and training time.",
    "rubric_id": ""
  },
  {
    "id": "7997f5b0e36f7ec0f5d08706bcdc9f87a55213b09199efb3b03eb837dd87e939",
    "text": "What is fine-tuning and how is it different from transfer learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify fine-tuning as a specific type of transfer learning. In standard transfer learning, only the final classification layers are retrained. In fine-tuning, the weights of some of the earlier, pre-trained layers are also unfrozen and retrained (usually with a small learning rate) on the new data.",
    "rubric_id": ""
  },
  {
    "id": "efcfa20d9b88156d7b2b81e86e6830c12f168d39d63e6b2a8798bf35cdcad061",
    "text": "Why do we use convolutions for images instead of using fully connected layers?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must highlight the key advantages of convolutions for image data. It should explain that convolutions preserve spatial relationships, are translation invariant, and use parameter sharing, which drastically reduces the number of parameters compared to a fully connected layer and makes the model more efficient.",
    "rubric_id": ""
  },
  {
    "id": "2f087ad862b83a86f65efb2dcd26ae3228f1147cacf36697e611a2783b4fe781",
    "text": "What is Gradient Clipping?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define gradient clipping as a technique to combat the exploding gradient problem. It should explain that it involves capping the gradient's norm at a predefined threshold during training to prevent the weight updates from becoming too large.",
    "rubric_id": ""
  },
  {
    "id": "dffda6a40f68040c74459f2c946ad5b900ec6d9f8b9b6c7c15fd2424ec906439",
    "text": "What do you understand by end-to-end learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define end-to-end learning as training a single, deep model to go directly from raw input to the final desired output, without intermediate, manually designed components. This allows the model to learn all the necessary processing steps, including feature extraction, automatically.",
    "rubric_id": ""
  },
  {
    "id": "b9f5bd8d001c8437e9c3361dc8c91971df4cb9733396d04da79373df38e48101",
    "text": "Are convolutional neural networks translation-invariant?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should be nuanced. It should explain that CNNs have a degree of translation equivariance due to the nature of convolutions, but it is the pooling layers that introduce a stronger degree of local translation invariance by summarizing features in a region.",
    "rubric_id": ""
  },
  {
    "id": "1ed504aaa1b3d097261ae4a47c193ba4424982756691ae015f8073888b8ad183",
    "text": "What is the advantage of using small kernels like 3x3 than using a few large ones.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list the main advantages of using small kernels. Check for: stacking multiple small kernels creates a larger receptive field with fewer parameters than a single large kernel, and it allows for more non-linearities to be introduced between the layers, increasing the network's expressive power.",
    "rubric_id": ""
  },
  {
    "id": "98de87771e7b648532fd5a66eecc22be8671949af0da4335a751b22a5d729e3e",
    "text": "How can you generate a dataset on multiple cores in real-time that can be fed to the deep learning model?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must suggest using a data generator with multiprocessing capabilities. Modern deep learning frameworks like Keras and PyTorch have data loaders that can be configured to use multiple worker processes to load and preprocess data in parallel on different CPU cores, preventing the GPU from being bottlenecked by data loading.",
    "rubric_id": ""
  },
  {
    "id": "8ff65af168787a9e106ebc6cb924f8e88ea9b6c1f1686f4c022c84c217b9e72e",
    "text": "How do you bring balance to the force when handling imbalanced datasets in deep learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list common techniques for handling class imbalance. Key methods to mention are resampling techniques (like oversampling the minority class or undersampling the majority class) and using class weights in the loss function to give more importance to the minority class.",
    "rubric_id": ""
  },
  {
    "id": "b0819493dc396e4abc7e0320d024b04b0fcb07652b3ba3031b20c53543251219",
    "text": "What are the benefits of using batch normalization when training a neural network?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list the key benefits of batch normalization. Check for: stabilizing and accelerating the training process, reducing internal covariate shift, and having a regularizing effect that can reduce the need for other regularization techniques like dropout.",
    "rubric_id": ""
  },
  {
    "id": "9d2a3a5776fcb67b0ed8f6e2fa8ac64b1e2cc19d41c7dbc2b5f25ed5ff72c921",
    "text": "Which is better LSTM or GRU?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must compare LSTM and GRU based on their architecture and performance. It should state that LSTMs are more complex and potentially more powerful for very long sequences, while GRUs are simpler, faster, and require less memory, often performing comparably on many tasks.",
    "rubric_id": ""
  },
  {
    "id": "d995d5346e2e0e7929e29956bcfd1fd9d950664e60c25f18566d3afb65f19b23",
    "text": "RMSProp and Adam optimizer adjust gradients? Does this mean that they perform gradient clipping?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must be 'no'. It must explain that while optimizers like Adam and RMSProp adapt the learning rate for each parameter based on past gradients, this is different from gradient clipping, which explicitly caps the overall magnitude of the gradients at a fixed threshold to prevent them from exploding.",
    "rubric_id": ""
  },
  {
    "id": "b938ba4685fd141afcc3a03fe95c80047b73209a7b0301574a2167b4131e83d9",
    "text": "Can you name a few hyperparameters used for training a neural network.",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list several key hyperparameters. Check for mentions of learning rate, number of hidden layers, number of neurons per layer, activation function, batch size, and number of epochs.",
    "rubric_id": ""
  },
  {
    "id": "0068fc3bf689859f6874847165c9b5d607d22315f590319db967b28086a1035c",
    "text": "When is multi-task learning usually preferred?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that multi-task learning is preferred when you have several related tasks and want to leverage shared representations to improve performance. It is particularly useful when the amount of data for any single task is small, as the model can learn from the combined data of all tasks.",
    "rubric_id": ""
  },
  {
    "id": "72b512f9189a44cb5eed31d711405a6bf19ecbd1b023dde244cfe8eeb7d683da",
    "text": "Explain the Adam Optimizer in one minute.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe Adam as an adaptive learning rate optimization algorithm. It should mention that it combines the benefits of two other methods: RMSprop (which adapts learning rates) and momentum (which helps accelerate gradients in the right direction).",
    "rubric_id": ""
  },
  {
    "id": "4bf8968db10c219cd9a3cf8b30fcb5d09de13b214409dbe2cf9db1e53044c7d5",
    "text": "Which loss function is preferred for multi-category classification?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify the correct loss function. For multi-class classification, the standard choice is Categorical Cross-Entropy (or Sparse Categorical Cross-Entropy, depending on the label format).",
    "rubric_id": ""
  },
  {
    "id": "38e2d4ee941ef0f4b156ef0dbed3e9094f19225500142009415d2580483b9efc",
    "text": "To what kind of problems can the cross-entropy loss function be applied?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should state that cross-entropy loss is used for classification problems. It must distinguish between Binary Cross-Entropy (for two-class problems) and Categorical Cross-Entropy (for multi-class problems).",
    "rubric_id": ""
  },
  {
    "id": "5f77dd79d463be9c4c8269c879e528bf161001f7af9bf7c921fb545c459dadff",
    "text": "List the steps to implement a gradient descent algorithm.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline the iterative process of gradient descent. Key steps to check for are: 1) Initialize model parameters, 2) Forward pass to compute predictions and calculate the error (loss), 3) Backward pass to compute the gradient of the loss with respect to the parameters, and 4) Update the parameters by taking a step in the opposite direction of the gradient.",
    "rubric_id": ""
  },
  {
    "id": "3c61bd5f36e7be53942495af05f90e60edfdc9a877a8d19c91297a5533b1479f",
    "text": "How important is it to shuffle the training data when using batch gradient descent?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that for true batch gradient descent (where the entire dataset is one batch), shuffling is irrelevant because the gradient is computed over all data in every step. It should clarify that shuffling is crucial for Stochastic Gradient Descent (SGD) and Mini-Batch Gradient Descent to prevent the model from learning from a biased sequence of data.",
    "rubric_id": ""
  },
  {
    "id": "546763a5ca8c4401787ab07a7616604a03b9834f88f2f0598f40f45c859ac637",
    "text": "What is the benefit of using max pooling in classification convolutional neural networks?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list the main benefits of max pooling. Look for: reducing the spatial dimensions of the feature maps (which reduces computation and number of parameters) and providing a degree of translation invariance by selecting the most prominent feature in a region.",
    "rubric_id": ""
  },
  {
    "id": "99497dca417a130879ea15b1474f453cb2218e93f770c834bef66177c53b80b6",
    "text": "Can you name a few data structures that are commonly used in deep learning?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list data structures central to deep learning frameworks. The most important one to mention is the tensor. Other valid answers include matrices, data frames (for initial data loading), and computational graphs.",
    "rubric_id": ""
  },
  {
    "id": "6bd8c63d3de7f2f9f9db83075bd928730413163cad3fee987c336ef6478d3dea",
    "text": "Can you add an L2 regularization to a recurrent neural network to overcome the vanishing gradient problem?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must be 'no' and explain why. L2 regularization penalizes large weights, shrinking them towards zero. The vanishing gradient problem is caused by repeated multiplication of small values. L2 would likely worsen the problem by further shrinking the weights.",
    "rubric_id": ""
  },
  {
    "id": "15cc8cd6ce3968927fd11f9cc4cccb5b70c2ae81a2d9ecef9a5e4b5b5ce2919c",
    "text": "How will you implement Batch Normalization in RNN?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must state that standard Batch Normalization is not directly applicable to the recurrent connections in an RNN because the statistics (mean/variance) would need to be calculated separately for each time step. It should suggest alternatives like Layer Normalization or applying Batch Normalization only to the input-to-hidden connections.",
    "rubric_id": ""
  },
  {
    "id": "0ee90170ce7fce6a0dff51c498eacc14241cadcb4f0acd833adf33705e579f5b",
    "text": "Given that there are so many deep learning algorithms, how will you determine which deep learning algorithm has to be used for a dataset.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the choice depends primarily on the structure of the data and the problem type. It should provide examples: CNNs for grid-like data (images), RNNs/LSTMs for sequential data (time series, text), and simple ANNs/MLPs for tabular data.",
    "rubric_id": ""
  },
  {
    "id": "0c46bf7d3ec7c2490dee89641d90c868f9c286d248529f0a3d17f456e7b55efa",
    "text": "How do one-hot encoding and label encoding affect the dimensionality of a dataset?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must correctly differentiate the two. Label encoding does not change the dimensionality; it just converts categories into a single integer column. One-hot encoding increases the dimensionality by adding a new binary column for each unique category in the original feature.",
    "rubric_id": ""
  },
  {
    "id": "ef401076c18574a0a429db85c3a338bbc501907b14cb88ccc316d831f878cf9f",
    "text": "Why are GPUs important for implementing deep learning models?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain that GPUs are highly effective at parallel processing, specifically for matrix and vector operations which are the core computations in deep learning. This allows for significantly faster model training compared to CPUs.",
    "rubric_id": ""
  },
  {
    "id": "b55791748bd7237dc40d429e0f9ca0e6e5f7ed91de3f07f056cbe7ec1e164b15",
    "text": "Which is the best algorithm for face detection?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that modern, high-performance face detection algorithms are based on deep learning, specifically Convolutional Neural Networks (CNNs). It could mention specific architectures like MTCNN or models based on YOLO/SSD.",
    "rubric_id": ""
  },
  {
    "id": "7fef25640f01b2028dc77ce10685c514203bb50695265bb6144e47607653ab0a",
    "text": "What evaluation approaches do you use to gauge the effectiveness of deep learning models?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should list common evaluation metrics based on the task. For classification, it should mention accuracy, precision, recall, F1-score, and AUC. For regression, it should mention MSE, RMSE, and MAE. It must also emphasize the importance of evaluating on a separate, held-out test set.",
    "rubric_id": ""
  },
  {
    "id": "6ed4500dd3cbf597ab25a949eb877bcdf8f5a5ee2a4db657501cc2ff70383b5e",
    "text": "When training a neural network, you observe that the loss does not decrease in the first few epochs. What are the possible reasons for this?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several potential causes. Key reasons to check for include a learning rate that is too low, improper weight initialization (leading to dead neurons), or issues with the data, such as it not being properly normalized.",
    "rubric_id": ""
  },
  {
    "id": "8f3e998620a610e94f8522d6d00f50cbdcfb9340280740c188f6a2d0997d87fc",
    "text": "What are the commonly used techniques to deal with the overfitting of a deep learning model?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list several common regularization techniques. Check for mentions of adding more data, data augmentation, L1/L2 regularization, dropout, and early stopping.",
    "rubric_id": ""
  },
  {
    "id": "7eb5d61dad1822ca5f35c5458831b28f03bacc5430c20edeffb5eec3b712c42b",
    "text": "What kind of gradient descent variant is the best for handling data that is too big to handle in RAM simultaneously?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify Mini-Batch Gradient Descent or Stochastic Gradient Descent (SGD) as the appropriate variants. It should explain that these methods work by updating the model's weights using smaller subsets of the data, so the entire dataset does not need to be loaded into memory at once.",
    "rubric_id": ""
  },
  {
    "id": "1ab867aa877cb899d4a38527faae9a78392ab58001eaa01cca6d9e5f031d74b4",
    "text": "How will you explain the success and recent rise in demand for deep learning in the industry?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must cite three key factors: the availability of massive datasets, the development of powerful GPU hardware for parallel computation, and algorithmic advancements that have made training deep networks more effective and stable.",
    "rubric_id": ""
  },
  {
    "id": "5e24c080aef78bb10cfab0f3e7a5cf20c79c28a2eb90bf9cb8f3410045966561",
    "text": "How do you select the depth of a neural network?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that this is a hyperparameter that is typically tuned empirically. The general approach is to start with a smaller number of layers and gradually increase the depth, monitoring the validation performance to see if the added complexity is beneficial and not just causing overfitting.",
    "rubric_id": ""
  },
  {
    "id": "e649f373f808581d5ba695b731bc7c0f346bbec9929a4e0a5235d88abe8395df",
    "text": "Have you used the ReLu activation function in your neural network? Can you explain how does the ReLu activation function works?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must correctly define the Rectified Linear Unit (ReLU) function. It should state that the function returns the input value if the input is positive, and returns zero otherwise. Formula: f(x) = max(0, x).",
    "rubric_id": ""
  },
  {
    "id": "73b8cb5dbfb0c1545281b9427ccab8c50951957b2da76cbe5e4c13975bfe9e20",
    "text": "How often do you use pre-trained models for your neural network?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should indicate that using pre-trained models (transfer learning) is a very common and effective practice, especially in domains like computer vision and NLP. It is the standard starting point unless the task or data is highly unique.",
    "rubric_id": ""
  },
  {
    "id": "92ecf1ab7ae7e2e61c7ffb6c986c9ff55b68a1ef518bf2c725f6ed6dd49522fd",
    "text": "What does the future of video analysis look like with the use of deep learning solutions? How effective/good is video analysis currently?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should acknowledge that deep learning has made video analysis highly effective for tasks like action recognition and object tracking. It should look to the future by mentioning advancements in understanding long-term temporal context and generating descriptive captions for video content.",
    "rubric_id": ""
  },
  {
    "id": "6f84600a095a18f3c5fc1e3ff07ca74343f9897306830fa641564dfaf380d204",
    "text": "What is more important to you the performance of your deep learning model or its accuracy?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must recognize that 'performance' and 'accuracy' are related but distinct, and the importance depends on the application. Accuracy refers to the correctness of predictions. Performance can refer to speed (latency) and computational cost. For real-time applications, performance is critical, while for offline analysis, accuracy might be the priority.",
    "rubric_id": ""
  },
  {
    "id": "83893291c2f135332a9e07fb8fa6211e729ed3a786a3dfde914521c78cea199c",
    "text": "Given the dataset, how will you decide which deep learning model to use and how to implement it?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must demonstrate a structured thought process. The choice of model should be based on the data type (e.g., CNN for images, RNN for sequences, MLP for tabular). Implementation should involve a standard workflow: data preprocessing, splitting data, building and training the chosen model, and evaluating its performance on a held-out test set.",
    "rubric_id": ""
  },
  {
    "id": "212bd509ff7726a202b6deab0cf61e43d52960d41c193f8dc9be09d6ac97c3e8",
    "text": "What are the most used neural network paradigms? (Hint: Talk about Encoder-Decoder Structures, LSTM, GAN, and CNN)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe several key architectures. It should define CNNs for spatial data, RNNs/LSTMs for sequential data, Encoder-Decoder structures for sequence-to-sequence tasks, and GANs for generative modeling.",
    "rubric_id": ""
  },
  {
    "id": "8083e423953a54d46e36bde24f6cc491204df7597d844be167c10bfb7adb70c9",
    "text": "Is it possible to use a neural network as a tool of dimensionality reduction?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must be 'yes' and should name the specific architecture used for this: an autoencoder. It should explain that the bottleneck layer of a trained autoencoder provides a compressed, lower-dimensional representation of the input data.",
    "rubric_id": ""
  },
  {
    "id": "ce12434d02dd10ca06575ac739002a27913b1792a9f67bff5c139a4078bbe7cd",
    "text": "How deep learning models tackle the curse of dimensionality?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should explain that deep learning models tackle the curse of dimensionality by learning a hierarchical set of features. Lower layers learn simple features, and higher layers combine them into more complex, abstract representations, effectively learning a lower-dimensional manifold where the data resides.",
    "rubric_id": ""
  },
  {
    "id": "98bf202fb2abd5926ea86aae6340124fc7bd3ae6a4f9466ecb69b43cd3a4431c",
    "text": "What are the pros and cons of using neural networks?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list both advantages and disadvantages. Pros to mention include their ability to model complex non-linear relationships and high performance on large datasets. Cons include their 'black box' nature (low interpretability), high computational cost, and the need for large amounts of data.",
    "rubric_id": ""
  },
  {
    "id": "d35aa57a1af143c2a84f778869b25004ae8da2f43fc21d0e8b5b4be793363557",
    "text": "How is a Capsule Neural Network different from a Convolutional Neural Network?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that Capsule Networks (CapsNets) aim to address a key limitation of CNNs. While CNNs detect features, CapsNets detect features and also their spatial relationships and orientation. This is achieved by using 'capsules' which output vectors instead of scalars, encoding properties like pose and orientation.",
    "rubric_id": ""
  },
  {
    "id": "319f465f2e74106a40c2d63b60771d43fc5c3a0f0cec00958d07fb9f2db9fdd2",
    "text": "What is a GAN and what are the different types of GAN you've worked with?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a Generative Adversarial Network (GAN) as a model with two competing networks, a Generator and a Discriminator, used for generative tasks. It should also be able to name specific GAN architectures, such as DCGAN (Deep Convolutional GAN) or StyleGAN.",
    "rubric_id": ""
  },
  {
    "id": "766d2c7f9a857c6ced3e45a4452d9f0d4e8cb6cbebe26ebdceda6bc0396cb726",
    "text": "For any given problem, how do you decide if you have to use transfer learning or also fine-tuning?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should base the decision on the size of the new dataset and its similarity to the original dataset used for pre-training. A good rule of thumb is to use transfer learning (freezing most layers) when the new dataset is small. Fine-tuning (unfreezing and retraining more layers) is appropriate when the new dataset is larger and somewhat different from the original.",
    "rubric_id": ""
  },
  {
    "id": "19a84fb1c8b6b6ba8e544290e99ee66deb49f656a2a942fb195e5822a2dc0e1d",
    "text": "Can you share some tricks or techniques that you use to fight to overfit a deep learning model and get better generalization?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list several common regularization techniques. Key methods to check for are data augmentation, dropout, L1/L2 weight regularization, and early stopping.",
    "rubric_id": ""
  },
  {
    "id": "6ed37e33a25a2ae04226b228678733d7b110718ea20ecdbe6813cfa82fc93513",
    "text": "Explain the difference between Gradient Descent and Stochastic Gradient Descent.",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate based on the amount of data used for each weight update. Standard (or Batch) Gradient Descent calculates the gradient using the entire training dataset. Stochastic Gradient Descent (SGD) calculates the gradient and updates the weights for each single training example, making it faster but with more variance in the updates.",
    "rubric_id": ""
  },
  {
    "id": "86b5c3306cb7cd89f97cb028ba925e3ffe2d80da0f8b947db21aacddf3b77794",
    "text": "Which one do you think is more powerful \u2013 a two-layer NN without any activation function or a two-layer decision tree?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must recognize that a neural network without a non-linear activation function is just a linear model. A two-layer decision tree, while simple, can model non-linear relationships. Therefore, the decision tree is more powerful in this specific comparison.",
    "rubric_id": ""
  },
  {
    "id": "d6004ea33af512d40457e0149c0375612ddbddfea4a5c0ffb1886e7c18300859",
    "text": "Can you name the breakthrough project that garnered the popularity and adoption of deep learning?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify AlexNet, the model that won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. It should explain that its significant performance improvement demonstrated the power of deep convolutional neural networks and sparked the modern deep learning revolution.",
    "rubric_id": ""
  },
  {
    "id": "2a8e32ba1ef1f1fe98c1551ff062d246650ea6934b2373c26cef79e0db953649",
    "text": "Differentiate between bias and variance with respect to deep learning models and how can you achieve a balance between the two?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting) in the context of deep learning. It should state that increasing model complexity (e.g., more layers/neurons) typically reduces bias but increases variance. A balance is achieved by finding a model complex enough to fit the data but using regularization techniques (like dropout) to control variance.",
    "rubric_id": ""
  },
  {
    "id": "b1f0013b10d95fcafe42659af14f9d7ccd848382f2fb9e2f6ff3c4c246d7f310",
    "text": "What are your thoughts about using GPT3 for our business?",
    "domain": "behavioral-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should demonstrate an understanding of what Large Language Models (LLMs) like GPT-3 are good for. It should propose specific, relevant business use cases, such as customer support chatbots, text summarization, content generation, or sentiment analysis, and acknowledge the costs and potential ethical considerations.",
    "rubric_id": ""
  },
  {
    "id": "f6cc9f211fe0b4e9c894bb5185a91542c97fd238aef6a001c1b3e750ebb0bca6",
    "text": "Can you train a neural network without using back-propagation? If yes, what technique will you use to accomplish this?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should be 'yes' and mention alternative optimization methods. Good examples to provide are evolutionary algorithms or genetic algorithms, which are derivative-free optimization techniques that can be used to find good weights for a neural network, although they are generally less efficient than backpropagation.",
    "rubric_id": ""
  },
  {
    "id": "697cd527bd1eb6a5378bbe486f13b52698d5555e9c3b1f1b895bc0b6829ef357",
    "text": "Explain the working of a perceptron.",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must describe the basic components of a perceptron. It should explain that it calculates a weighted sum of its inputs and then applies a step function (or activation function) to this sum to produce an output. This makes it a simple linear binary classifier.",
    "rubric_id": ""
  },
  {
    "id": "6d547f13cb39b853128b480e02025e8790a0e2c0e8490aa4dc8fbc1bbe0d6349",
    "text": "Differentiate between a feed-forward neural network and a recurrent neural network.",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate based on the flow of information. In a feed-forward network, information flows in only one direction, from input to output. In a recurrent neural network (RNN), there are loops, allowing information to persist and be passed from one step to the next, which gives it a form of memory.",
    "rubric_id": ""
  },
  {
    "id": "777d2b5784f3bd8e0c5823f726307f5e5b24abd2f3205b3a977c84278dcf6517",
    "text": "Why don't we see the exploding or vanishing gradient problem in feed-forward neural networks?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should clarify that this is a misconception. While the problems are more pronounced in RNNs due to repeated multiplication over time, deep feed-forward networks can also suffer from vanishing or exploding gradients, which is why techniques like careful initialization, batch normalization, and ReLU activation are important.",
    "rubric_id": ""
  },
  {
    "id": "f54156a064acffd27fc33381d01204fb1fe0e4e025b868d26a4be0b690dc451d",
    "text": "How do you decide the size of the filter when performing a convolution operation in a CNN?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that filter size is a hyperparameter that depends on the dataset and task. It should state that smaller filters (like 3x3) are generally preferred in modern architectures because they are computationally efficient and, when stacked, can capture a large receptive field while introducing more non-linearities.",
    "rubric_id": ""
  },
  {
    "id": "ebe382da0d1ad30c1ada0edb3d6d5c68506b5443eef2cad9fd4f6f351df7650f",
    "text": "When designing a CNN, can we find out how many convolutional layers should we use?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that the number of layers is a key hyperparameter that is determined empirically. The general approach is to start with established architectures and then experiment, adding more layers to increase model capacity while being mindful of overfitting and computational cost.",
    "rubric_id": ""
  },
  {
    "id": "6b702ad0589368deecd7bc45f87a269c3c1d78581fc2f7cf5ec47b561fe85797",
    "text": "What do you understand by a computational graph?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define a computational graph as a representation of a mathematical expression, where nodes are operations (e.g., addition, multiplication) and edges represent the flow of data (tensors). It should mention that deep learning frameworks use these graphs to automatically calculate gradients via backpropagation.",
    "rubric_id": ""
  },
  {
    "id": "0be58c4f65d0d95728dbd11e288bf12a3975e443563231600c2704c884ebb74f",
    "text": "Differentiate between PCA and Autoencoders.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on linearity. PCA is a linear dimensionality reduction technique that finds principal components that maximize variance. Autoencoders are neural networks that can learn non-linear dimensionality reductions by training an encoder and a decoder.",
    "rubric_id": ""
  },
  {
    "id": "8dcefc57141eef72f25ad77f574168b0d046122f9bcd22a20b44c67655445eb9",
    "text": "Which one is better for reconstruction linear autoencoder or PCA?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should state that a linear autoencoder and PCA are mathematically equivalent. A linear autoencoder, when trained to minimize mean squared error, will learn a latent space that is spanned by the principal components found by PCA. Therefore, for linear reconstruction, their performance is the same.",
    "rubric_id": ""
  },
  {
    "id": "16d090b3fec20345ec852fd283b51134b04a717c98bdead9bae12a6c1b613051",
    "text": "How is deep learning related to representation learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify deep learning as a form of representation learning. It should explain that the layers in a deep network learn a hierarchy of features or representations of the data, with higher layers learning more abstract and complex representations based on the features from lower layers.",
    "rubric_id": ""
  },
  {
    "id": "3b0ec1623471b2e1a6497f45e4908b6a05f7bc6c739917855ac986266357ed70",
    "text": "Explain the Borel Measurable function.",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define a Borel measurable function as a function between topological spaces where the preimage of any open set is a Borel set. This is a technical concept from measure theory relevant to the mathematical foundations of probability and random variables.",
    "rubric_id": ""
  },
  {
    "id": "1a9632b6be59211b230f78f4d2fc500956549309ca14a4447f1c865619f67a92",
    "text": "How are Gradient Boosting and Gradient Descent different from each other?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between the two concepts. Gradient Descent is an optimization algorithm used to find the minimum of a function (like a loss function) by iteratively updating parameters. Gradient Boosting is an ensemble machine learning technique that builds a strong model by sequentially adding weak learners, where each new learner is trained to correct the residual errors of the previous ones, which can be seen as a form of functional gradient descent.",
    "rubric_id": ""
  },
  {
    "id": "36087d656241e3b932d28aaf915fab4ce26c4646e11f00b60561cdea6561e453",
    "text": "In a logistic regression model, will all the gradient descent algorithms lead to the same model if run for a long time?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should be 'yes, they will converge to the same solution.' It must explain that the loss function for logistic regression is convex, which means it has a single global minimum. Therefore, any valid gradient descent algorithm, given a small enough learning rate and enough time, will eventually find this same optimal solution.",
    "rubric_id": ""
  },
  {
    "id": "ebbc0f76e32753456572b2d36dec5ac08f830e4c3963a5a9bf079c3036705b6f",
    "text": "What is the benefit of shuffling a training dataset when using batch gradient descent?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should clarify the terminology. For true batch gradient descent, which uses the entire dataset, shuffling has no effect. The benefit of shuffling applies to Mini-Batch and Stochastic Gradient Descent, where it ensures that the gradients computed for each batch are more representative of the overall dataset and prevents the model from being biased by the order of the data.",
    "rubric_id": ""
  },
  {
    "id": "9da2db2b2b44c100b97b8f4c5ad882fcd76642bd23cab506993c87125e6a7455",
    "text": "Explain the cross-entropy loss function.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define cross-entropy loss as a loss function commonly used for classification tasks. It should explain that it measures the difference between two probability distributions: the predicted distribution from the model and the true distribution (the one-hot encoded labels). A lower cross-entropy value indicates a better model.",
    "rubric_id": ""
  },
  {
    "id": "59aae1a01a99e63203e5d85957a2d2c1c6641b847a41597ec17a3067b6e7bc47",
    "text": "Why is cross-entropy preferred as the cost function for multi-class classification problems?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should state that cross-entropy is preferred because it is well-suited for probabilistic outputs (like those from a softmax function) and has favorable properties for gradient-based optimization. Unlike mean squared error, it does not suffer from learning slowdowns when the model's predictions are confident but wrong.",
    "rubric_id": ""
  },
  {
    "id": "319942d3a54503405d9985dad2e75773f708c9766c600e02194010c1746102f4",
    "text": "What happens if you do not use any activation functions in a neural network?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that without a non-linear activation function, the neural network would simply be a linear model. The composition of multiple linear transformations is just another linear transformation, so the network would have the same expressive power as a single-layer model, like linear or logistic regression.",
    "rubric_id": ""
  },
  {
    "id": "2e758491b5fa86730f4adbc999e59806f7183d0f987632a8b379b391ad602975",
    "text": "What is the importance of having residual neural networks?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that residual networks (ResNets), with their skip connections, were introduced to solve the degradation problem in very deep neural networks. These connections allow gradients to flow more easily through the network, making it possible to train much deeper models without a drop in performance.",
    "rubric_id": ""
  },
  {
    "id": "9b58cb0d2107d09e9cc5c6e4f8e8f9957c5fd10eeaaec58fa21bb5f9b9ec6b4e",
    "text": "There is a neuron in the hidden layer that always results in a large error in backpropagation. What could be the reason for this?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should identify this as a potential 'dead neuron' problem, often caused by the ReLU activation function. If a neuron's input is always negative, its output will be zero, and the gradient flowing through it will also be zero. This means its weights will never be updated during training.",
    "rubric_id": ""
  },
  {
    "id": "c761f5c1673455d094d68c0760f22e3ed82e8a6caf052454f04fa1458d4a8cd8",
    "text": "Explain the working of forwarding propagation and backpropagation in deep learning.",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the two processes. Forward propagation is the process of passing the input data through the network layer by layer to get an output prediction. Backpropagation is the process of calculating the gradient of the loss function with respect to the network's weights, moving backward from the output layer to the input layer, in order to update the weights.",
    "rubric_id": ""
  },
  {
    "id": "1c7346bd944a39fa2f3e61fb91572220219c033e9507bbd10d996dc7fc65b6ab",
    "text": "Is there any difference between feature learning and feature extraction?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should differentiate the two. Feature extraction typically refers to using predefined algorithms (like SIFT or HOG) or manual engineering to create features from raw data. Feature learning, a key aspect of deep learning, refers to the model automatically discovering and learning relevant features from the data during training.",
    "rubric_id": ""
  },
  {
    "id": "500dca2ec6e0a41f3bbe63eeeaf4dd80f3e564e8f5cf03f1e3e3a9b8afa8ae03",
    "text": "Do you know the difference between the padding parameters valid and the same padding in a CNN?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must correctly distinguish the two padding modes. 'Valid' padding means no padding is added, so the output feature map will be smaller than the input. 'Same' padding means padding is added around the input so that the output feature map has the same spatial dimensions as the input.",
    "rubric_id": ""
  },
  {
    "id": "1334d9d8db0090c94f187de6ea2ff235bb4cb269657efeaa0838ae19f3dd3cdb",
    "text": "How does deep learning outperform traditional machine learning models in time series analysis?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should focus on the ability of recurrent neural networks (RNNs), like LSTMs and GRUs, to automatically learn temporal dependencies and patterns from sequential data. Unlike traditional models that often require manual feature engineering of lags and trends, RNNs can learn these complex time-based relationships directly.",
    "rubric_id": ""
  },
  {
    "id": "e7090c944d5fb3b4fa5f5b0fcd7dd66a6d18477a2f5f15f48e2fa975325cd467",
    "text": "Can you explain the parameter sharing concept in deep learning?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must identify parameter sharing as a key concept in Convolutional Neural Networks (CNNs). It should explain that in a convolutional layer, the same filter (set of weights) is applied across different spatial locations of the input. This drastically reduces the number of parameters and allows the model to detect a feature regardless of its position.",
    "rubric_id": ""
  },
  {
    "id": "6cafe27f66cae69e650ca6e5dc14ef37d28a1c4353dc5cf5ec3347932dcdceb5",
    "text": "How many trainable parameters are there in a Gated Recurrent Unit cell and in a Long Short Term Memory cell?",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should provide the formulas for calculating the number of parameters. For a GRU, it's 3 * (n*m + m^2 + m). For an LSTM, it's 4 * (n*m + m^2 + m), where n is the input size and m is the hidden size. The key is to recognize that LSTM has one more gate than GRU, hence the 4 vs 3 multiplier.",
    "rubric_id": ""
  },
  {
    "id": "c7ea5773aef101296dea619b6ac4f2caab7d6271fb2a518472aa607e711e53b3",
    "text": "What are the key components of LSTM?",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list the core components of an LSTM cell. Check for mentions of the three gates (input, forget, and output gate) and the cell state, which acts as the long-term memory.",
    "rubric_id": ""
  },
  {
    "id": "6e30ed8fed39137e0b06dc92635537ef9e8da7187335d73509c23f8c7d9cf178",
    "text": "What are the components of a General Adversarial Network?",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must identify the two main components of a Generative Adversarial Network (GAN). These are the Generator, a neural network that creates synthetic data, and the Discriminator, a neural network that tries to distinguish between real and generated data.",
    "rubric_id": ""
  },
  {
    "id": "8768935b2f37e483cf67d53342a195a17e5a1fe5aab637acce40bb1ae2958470",
    "text": "What is your favorite machine learning algorithm and why? (Sample 1)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear justification. The justification should cover technical aspects like its performance characteristics, interpretability, or suitability for certain data types (e.g., Gradient Boosting for tabular data, CNNs for images).",
    "rubric_id": ""
  },
  {
    "id": "fe6bc681de3ada592c55945820e9cb0ba3e344bccf651f19ad2efa7a8d8ce4c9",
    "text": "What is the bias-variance tradeoff? (Sample 2)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both bias (error from overly simple assumptions causing underfitting) and variance (error from model complexity causing overfitting). It must explain their inverse relationship and the goal of finding a balance to minimize total error on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "6707ec76bf5241f0c655f54eadba0d0f1754ce5fc77a181c58ce63ccd728a284",
    "text": "What are the key differences between classification and regression? (Sample 3)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the nature of the output variable. It must state that classification predicts a discrete class label (e.g., 'cat' or 'dog'), while regression predicts a continuous numerical value (e.g., price, temperature).",
    "rubric_id": ""
  },
  {
    "id": "4b243d3473ff150acf60b98b9cefc44de62b6b94313112486141732e84f8890b",
    "text": "What is principal component analysis (PCA)? (Sample 4)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define PCA as a linear dimensionality reduction technique. It should explain that PCA transforms the data into a new set of orthogonal axes (principal components) that are ordered by the amount of variance they capture in the data.",
    "rubric_id": ""
  },
  {
    "id": "6dff6135cce9e98446f8e9df3b1fee75f759c6f9fb27c1ad66970d5b24968551",
    "text": "How would you optimize a machine learning model? (Sample 5)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe an iterative process. Key steps to look for are hyperparameter tuning (using methods like Grid Search or Random Search), feature engineering, and potentially trying different algorithms to improve a chosen evaluation metric.",
    "rubric_id": ""
  },
  {
    "id": "d90f12ce054a4f14aeb3ea9d56928a09483c89cfb3c6f317956d3e143926e945",
    "text": "Can you explain the concept of gradient descent? (Sample 6)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define gradient descent as an iterative optimization algorithm used to find the minimum of a function (typically a loss function). It should explain the core mechanism: repeatedly taking steps in the opposite direction of the gradient of the function at the current point.",
    "rubric_id": ""
  },
  {
    "id": "d5c6a876526f8fd32e4855b6690551a8e207ac0185b344de66483e9a1f86927d",
    "text": "Describe the process of feature selection. (Sample 7)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of selecting a subset of relevant features for use in model construction. It should mention the goals: improving model performance, reducing overfitting, and decreasing computational cost.",
    "rubric_id": ""
  },
  {
    "id": "3ba5ef030cb206a75f960d2deec7d566e4728dfa15bf6a5a82fc96fa534a05f5",
    "text": "What metrics would you use to evaluate a regression model? (Sample 8)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list common metrics for regression tasks. Look for mentions of Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared.",
    "rubric_id": ""
  },
  {
    "id": "9ce8b36b1e0e7141de450e55c7625b1ffa482855be8ff65405c32d7f10bc8667",
    "text": "What is the difference between bagging and boosting? (Sample 9)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the two ensemble methods. Bagging trains models in parallel on different subsets of data to reduce variance. Boosting trains models sequentially, with each new model focusing on correcting the errors of the previous ones to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "571adc8cfa9b7716e9b8b3146622ffdad81596000e796bc08a824470173ea251",
    "text": "What is the bias-variance tradeoff? (Sample 10)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of bias (underfitting) and variance (overfitting). It should explain their inverse relationship and the goal of finding an optimal model complexity that minimizes the total error, which is a sum of bias, variance, and irreducible error.",
    "rubric_id": ""
  },
  {
    "id": "6a67e1bf0105eac74fef6dce508e81b23b354f630e1e112a467917eb0219a104",
    "text": "What are the key differences between classification and regression? (Sample 11)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the output variable. It should state that classification predicts a discrete, categorical label, while regression predicts a continuous, numerical value.",
    "rubric_id": ""
  },
  {
    "id": "3103a926e09030b3aab9faba9da6eedc90face4bc6950a32e41b483ba22b7c1e",
    "text": "What are the advantages of ensemble methods? (Sample 12)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that the primary advantage of ensemble methods is improved predictive performance and robustness over a single model. It should specify that this is achieved by reducing variance (bagging) or bias (boosting).",
    "rubric_id": ""
  },
  {
    "id": "5340bbd00f09fe002c251a4433b88fc7713bce7bdd240284d39293a3176668cd",
    "text": "How would you explain the concept of overfitting? (Sample 13)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as a situation where a model learns the training data too well, including its noise and random fluctuations. It must state the key consequence: poor performance and generalization on new, unseen data.",
    "rubric_id": ""
  },
  {
    "id": "1236e6d804bab687689e036738ced2ce1d490fe0770d3e6f87e0155490bcab8d",
    "text": "How does a neural network work? (Sample 14)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the basic layered architecture of a neural network (input, hidden, output layers). It should explain that neurons in each layer perform a weighted sum of their inputs, which is then passed through a non-linear activation function to produce an output for the next layer.",
    "rubric_id": ""
  },
  {
    "id": "aa67e4b2592bfb7bbfd362a30c8420ba273b69b6d36a811e131c90e0199ba14e",
    "text": "What is principal component analysis (PCA)? (Sample 15)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a linear dimensionality reduction technique. It must explain that PCA finds a new set of orthogonal axes (principal components) that capture the maximum possible variance in the data, allowing for data compression with minimal information loss.",
    "rubric_id": ""
  },
  {
    "id": "f15188b07015a3f7f5dd554fda8887b326cf070881c84068fbcfd28cac520e80",
    "text": "Can you explain the concept of gradient descent? (Sample 16)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an optimization algorithm for minimizing a function. It should explain the core idea of iteratively adjusting a model's parameters in the opposite direction of the gradient of the loss function to find the minimum error.",
    "rubric_id": ""
  },
  {
    "id": "2027238f17189b36db03ac2d920ae6b774713105d1d5a2ddbb1e0d26fe7039cb",
    "text": "How would you optimize a machine learning model? (Sample 17)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a systematic approach to model optimization. Key steps to look for are: selecting appropriate evaluation metrics, performing hyperparameter tuning (e.g., grid search), feature engineering, and applying regularization to prevent overfitting.",
    "rubric_id": ""
  },
  {
    "id": "53c11a16c634405abdfe48d8c09c8ecc1791b2327b3ae96d664742c95b50b01a",
    "text": "What is regularization and why is it important? (Sample 18)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It should explain that it works by adding a penalty term to the loss function to discourage model complexity, leading to better generalization on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "d308ae3c3f519cb257991f02231fa0a4702030f3ed5db02d52bec6753fe26f80",
    "text": "How would you optimize a machine learning model? (Sample 19)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer should detail a comprehensive optimization strategy. It must include advanced techniques beyond simple tuning, such as cross-validation for robust evaluation, sophisticated feature engineering, error analysis to identify model weaknesses, and potentially using more complex models or ensemble methods.",
    "rubric_id": ""
  },
  {
    "id": "de927473611fca2c4c405798fb84373cf20b148108a7e9c0f0e4912a55c7a9e4",
    "text": "Explain cross-validation and its purpose. (Sample 20)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define cross-validation as a resampling technique for more reliable model evaluation. It should describe the k-fold cross-validation process: splitting data into k folds, training on k-1, testing on the holdout fold, and averaging the results to get a less biased estimate of performance on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "b42768c1f1d7df5b2f7bcbc680d02558f2164ebdd68827f4c457302ffa48aed5",
    "text": "Describe the process of feature selection. (Sample 21)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a systematic approach to selecting the most relevant features. It should differentiate between the main methods: filter methods (based on statistical properties), wrapper methods (using a model to score subsets), and embedded methods (where the model itself performs selection, like Lasso).",
    "rubric_id": ""
  },
  {
    "id": "9104866bf36801421960f2046c66bc440f56c367155dbb1502ed1b145996ed09",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 22)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must differentiate based on the penalty term. L1 regularization (Lasso) adds a penalty proportional to the absolute value of the weights, which can lead to sparse models by driving some weights to exactly zero (feature selection). L2 regularization (Ridge) adds a penalty proportional to the square of the weights, which encourages smaller weights but does not force them to zero.",
    "rubric_id": ""
  },
  {
    "id": "b220ee599485e1b1a683e241bd38610859ae29c814b1d03b36dd13fc938302b0",
    "text": "What is your favorite machine learning algorithm and why? (Sample 23)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific, sophisticated algorithm (e.g., XGBoost, LSTM) and provide a deep technical justification. The reasoning should cover the algorithm's inner workings, its advantages in specific scenarios (e.g., handling missing data, capturing temporal dependencies), and its limitations.",
    "rubric_id": ""
  },
  {
    "id": "92f551c545c1c9e39b4bd78b87209ab9215813c6c8a28dedca47ec4e1c830c83",
    "text": "Can you explain the concept of gradient descent? (Sample 24)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of gradient descent. It should cover the mathematical intuition (finding the direction of steepest descent of the loss function) and differentiate between the main variants: Batch, Stochastic (SGD), and Mini-batch gradient descent, explaining the trade-offs between them.",
    "rubric_id": ""
  },
  {
    "id": "7e502263e230e0160633c6c35c26da317a05297564ad5d220b57f4d70ad44192",
    "text": "What is regularization and why is it important? (Sample 25)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization as a method to combat overfitting by adding a penalty for model complexity to the loss function. It should explain the mathematical intuition behind L1 (Lasso) and L2 (Ridge) regularization and how they relate to the bias-variance tradeoff.",
    "rubric_id": ""
  },
  {
    "id": "ec2a94b97ea3a26b3baa380d6ac74309b1c9f61c90d63e6e7d64c45c366c517c",
    "text": "What are the advantages of ensemble methods? (Sample 26)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main advantage of ensemble methods is that they generally produce more accurate and robust models than a single model. It should mention that they achieve this by combining multiple models to reduce either bias or variance.",
    "rubric_id": ""
  },
  {
    "id": "1212dbc5f651dcaf1aa82c08abe01a8bd9a7446b6bcc5ba0364e5f6976c6e843",
    "text": "What is the difference between bagging and boosting? (Sample 27)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must state that bagging trains models in parallel on bootstrapped samples to reduce variance (e.g., Random Forest). Boosting trains models sequentially, where each model corrects the errors of its predecessor, to reduce bias (e.g., AdaBoost, Gradient Boosting).",
    "rubric_id": ""
  },
  {
    "id": "04f9d7cc422a0dc7ec8b5f09a00c3164bb9672f1abc740bbb80a8a878b374716",
    "text": "What is the bias-variance tradeoff? (Sample 28)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define bias as the error from a model being too simple (underfitting) and variance as the error from a model being too complex and sensitive to the training data (overfitting). It must explain that there is a trade-off: decreasing one often increases the other.",
    "rubric_id": ""
  },
  {
    "id": "dc6e9260f908da643acff10a26fe6b6dbd65aee02575b76f3c2c02501dcc0ea1",
    "text": "What metrics would you use to evaluate a regression model? (Sample 29)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list common regression metrics. It should go beyond the basics (MSE, MAE) and explain the pros and cons, for example, noting that RMSE penalizes large errors more and R-squared measures the proportion of variance explained.",
    "rubric_id": ""
  },
  {
    "id": "d6bac8b6584ec89151c67835a827379d2553cd5d36f59fefa395f7f3b6044268",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 30)",
    "domain": "behavioral-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must describe a project using the STAR method (Situation, Task, Action, Result). It should clearly state the project's goal, the specific machine learning techniques used, the challenges faced, and the final outcome or impact of the work.",
    "rubric_id": ""
  },
  {
    "id": "6a88ebcc8d24e828f99b720233c79c26f57b71696e02a9495a54ccd3b8a2ebe0",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 31)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should follow the STAR method (Situation, Task, Action, Result) but focus on a genuinely complex challenge. It should detail the problem, the specific machine learning approach, the technical hurdles overcome (e.g., difficult data, complex modeling), and the measurable impact of the final result.",
    "rubric_id": ""
  },
  {
    "id": "4d39780423c9cf277f19aa21161ad0647fb27e83a950ef4c61b6f2651d59134c",
    "text": "What is the role of activation functions in deep learning? (Sample 32)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity, which is crucial for allowing networks to learn complex patterns. It should also compare different activation functions (e.g., Sigmoid, Tanh, ReLU) and discuss their properties, such as the vanishing gradient problem associated with saturating functions.",
    "rubric_id": ""
  },
  {
    "id": "925007372dd5dfbec0bb487197f383e30a1b992e6c65a29cbb7cbf4f03f0cc23",
    "text": "How would you optimize a machine learning model? (Sample 33)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive and systematic optimization strategy. It should cover a range of techniques, including advanced hyperparameter tuning (e.g., Bayesian optimization), feature selection and engineering, error analysis to guide improvements, and the use of ensemble methods.",
    "rubric_id": ""
  },
  {
    "id": "8ab94000841eef466677ba0692c6ae461b7d6a28eb4e6a26bc8502fc46d2776f",
    "text": "Explain cross-validation and its purpose. (Sample 34)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough explanation of cross-validation as a method for robust model evaluation. It should detail the k-fold procedure and explain how it provides a more stable estimate of model performance on unseen data by reducing the variance associated with a single train-test split.",
    "rubric_id": ""
  },
  {
    "id": "6438b261beae7bfa94e419c29c0d8677332a9f138549f392413abf3b69007430",
    "text": "What are the key differences between classification and regression? (Sample 35)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clearly differentiate based on the output type. Classification predicts a discrete category (e.g., 'spam' vs. 'not spam'). Regression predicts a continuous quantity (e.g., price). It should also mention that different evaluation metrics are used for each task.",
    "rubric_id": ""
  },
  {
    "id": "6ebf8990d9bd1c75c2801bfb5fb0a26a5184c8bb2cdf689a965c2bf32a647895",
    "text": "What is the difference between bagging and boosting? (Sample 36)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed comparison of the two ensemble techniques. It must explain that bagging trains models in parallel on bootstrap samples to reduce variance, while boosting trains models sequentially, focusing on the mistakes of previous models to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "fac5ac8d8c2587ff9db8cc0155e8374d0a7d18fa5064106da286e0f5b4638ce9",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 37)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain that both are techniques to prevent overfitting. The key difference is the penalty term: L1 (Lasso) uses the absolute value of the weights, which can lead to feature selection (sparse weights). L2 (Ridge) uses the square of the weights, which encourages smaller weights overall.",
    "rubric_id": ""
  },
  {
    "id": "40e0d1519f5677dc39338c06a0671211f1dfd0bf4bd66fea2f1bb0741a409cb7",
    "text": "How would you explain the concept of overfitting? (Sample 38)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as a model performing very well on the training data but poorly on new, unseen data. It should explain that this happens when the model learns the noise in the training data instead of the underlying signal.",
    "rubric_id": ""
  },
  {
    "id": "5818fdbcaa53018908fc47f1d7ec9aff93ba04a11ac95b84f3605de24a45d5c4",
    "text": "How would you explain the concept of overfitting? (Sample 39)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define overfitting in the context of the bias-variance tradeoff. It should explain that an overfit model has low bias but high variance, meaning it has captured the training data's noise and will not generalize well to new data. It should also mention potential solutions like regularization or getting more data.",
    "rubric_id": ""
  },
  {
    "id": "6862e63775167055b43de0a2f2fbac75308c8ff708383c8495c8cddf298173c8",
    "text": "What is your favorite machine learning algorithm and why? (Sample 40)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a deep, technically-sound justification. For example, it could discuss the mathematical underpinnings of Gradient Boosting Machines or the architectural advantages of Transformer networks, explaining why they are powerful for certain tasks.",
    "rubric_id": ""
  },
  {
    "id": "6c815f04dd83a52ac70e73d39ce879b0cb21c2143ec5187280722e5107dbc499",
    "text": "What is your favorite machine learning algorithm and why? (Sample 41)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must demonstrate a strong understanding of a specific algorithm. It should go beyond a surface-level description, explaining the core mechanism (e.g., how attention works in Transformers, how trees are built in XGBoost) and the trade-offs involved in using it.",
    "rubric_id": ""
  },
  {
    "id": "0aa6852a23b46700b773753f778859bdd89f67f05b78b7946849b4acd3591694",
    "text": "What are the key differences between classification and regression? (Sample 42)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the fundamental difference: classification predicts a discrete class label (e.g., 'red', 'green', 'blue'), while regression predicts a continuous numerical value (e.g., 1.23, 4.56).",
    "rubric_id": ""
  },
  {
    "id": "5be2485c3c53ced9868727fa65b38807216823f84ec99c4b5f164155d272e747",
    "text": "Describe the process of feature selection. (Sample 43)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe feature selection as the process of choosing a subset of the most relevant features to use in a model. It should mention different approaches, such as filter methods (e.g., based on correlation) and wrapper methods (e.g., recursive feature elimination).",
    "rubric_id": ""
  },
  {
    "id": "a2e7c8fe19349a6ec3000e643968d3a4afae47d18895247630c47a2be13e0768",
    "text": "What are the advantages of ensemble methods? (Sample 44)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main advantage of ensemble methods is that they combine multiple models to create a more accurate and robust final model than any of the individual components.",
    "rubric_id": ""
  },
  {
    "id": "8d020ac5e3e5d91de464015b573989ee131f8e14184878f5a968e3a202220248",
    "text": "Can you explain the concept of gradient descent? (Sample 45)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm used to minimize a model's loss function. It should describe the process of calculating the gradient (slope) of the loss and taking a step in the opposite direction to find a local minimum.",
    "rubric_id": ""
  },
  {
    "id": "9d27e2578e0e6c9a0beb1d84f8276e43dde68755c4963696d9cae0cbc2496814",
    "text": "What is your favorite machine learning algorithm and why? (Sample 46)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must select a specific algorithm and provide a compelling, in-depth technical rationale. It should demonstrate a deep understanding of the algorithm's strengths, weaknesses, and the types of problems where it excels.",
    "rubric_id": ""
  },
  {
    "id": "7f7f5d2a4358201fb9f31fa7da61fe9fd4ac15683a6484e82890a448c1061066",
    "text": "How would you explain the concept of overfitting? (Sample 47)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of overfitting in the context of the bias-variance tradeoff. It should describe an overfit model as having high variance and low bias, meaning it fits the training data's noise. It must also suggest multiple ways to combat it, such as regularization, cross-validation, and adding more data.",
    "rubric_id": ""
  },
  {
    "id": "2153b2d109f98fd058ecadf9d22c844f4b73f42ddf00c8eb7bd78f375bf028ca",
    "text": "How would you approach data cleaning for a large dataset? (Sample 48)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline a systematic approach. This includes profiling the data to identify issues (missing values, outliers, inconsistencies), developing a strategy for each issue (e.g., imputation for missing data, outlier removal), and implementing the cleaning steps in a reproducible script, possibly using distributed computing frameworks for efficiency.",
    "rubric_id": ""
  },
  {
    "id": "a17e4f5c138769daaf97ee5c1732264a2a5db991dbf508bb7cc095319deaba1b",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 49)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with significant technical depth. It should clearly articulate the business problem, the data challenges, the modeling choices and why they were made, and the final, measurable impact of the project.",
    "rubric_id": ""
  },
  {
    "id": "3377751180e57ad82dbe8b5311c67455b8bd5f14058ae576ab1c92bd7880bee8",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 50)",
    "domain": "behavioral-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should follow the STAR method (Situation, Task, Action, Result). It needs to clearly describe a project, the goal, the actions taken (including the ML models used), and the outcome, even if the project was relatively simple.",
    "rubric_id": ""
  },
  {
    "id": "25f7b6a8014cda4f930be7573636184487b467274d1ae1bbf56a971b0e4cb7e1",
    "text": "What is the bias-variance tradeoff? (Sample 54)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting). It should explain their inverse relationship and the goal of finding a model complexity that minimizes total error on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "c33cb38ff3a243cd719206b6f03356267d7a763c8578e4fe358f54c75abf8852",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 55)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "Using the STAR method, the answer must detail a technically complex project. It should highlight specific challenges in data preprocessing, model selection, or deployment, and clearly state the final, quantifiable results.",
    "rubric_id": ""
  },
  {
    "id": "982127bf42f63066042a24436ddca9b4814ce3d0e008290bfe920cc45a0c5a89",
    "text": "How would you approach data cleaning for a large dataset? (Sample 56)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe a scalable and systematic approach. It should include data profiling, handling missing values through appropriate imputation, outlier detection and treatment, and ensuring data consistency, potentially using distributed frameworks like Spark for efficiency.",
    "rubric_id": ""
  },
  {
    "id": "215a2b2b8f5923b589d41cf9720ad039f44152c4851ed65a65d9a309e785341a",
    "text": "What are the advantages of ensemble methods? (Sample 57)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance and robustness by combining multiple models. It should differentiate how bagging reduces variance and boosting reduces bias.",
    "rubric_id": ""
  },
  {
    "id": "2eacb89020519804539d83b4167bba5345a114c93a972c2a01ffd96443e234d9",
    "text": "Describe the process of feature selection. (Sample 58)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must detail a structured approach to feature selection. It should differentiate between filter, wrapper, and embedded methods, providing an example for each (e.g., correlation for filter, recursive feature elimination for wrapper, Lasso for embedded).",
    "rubric_id": ""
  },
  {
    "id": "b86105157df00597b463304d3f86348ea63e6a83241b5d57281c96e1df571168",
    "text": "How would you approach data cleaning for a large dataset? (Sample 59)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should outline a basic, structured process for data cleaning. Key steps to mention are identifying and handling missing values, removing duplicate records, and correcting inconsistent data formats.",
    "rubric_id": ""
  },
  {
    "id": "aae792e60f79998c731634ca84dc078b79b6afbc3567971510e795f036b2f99e",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 60)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast the penalty terms. L1 regularization (Lasso) uses the absolute value of weights, which can result in sparse models (feature selection). L2 regularization (Ridge) uses the squared value of weights, which encourages smaller weights but doesn't force them to zero.",
    "rubric_id": ""
  },
  {
    "id": "1050ca18f1dd38b9eff2ecd6c5919a60acf4a3e5c27199b00de0368e1521084c",
    "text": "What metrics would you use to evaluate a regression model? (Sample 61)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common regression metrics and explain their interpretations. Look for mentions of MAE (interpretable, less sensitive to outliers), MSE (penalizes large errors), RMSE (in the same units as the target), and R-squared (proportion of variance explained).",
    "rubric_id": ""
  },
  {
    "id": "c1f17c909301ce0ca56eaa10a033170f9a012c1f8c20a8a6ee3e6e27eac4d373",
    "text": "What are the advantages of ensemble methods? (Sample 62)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensembles improve performance by combining diverse models. It should mention that they can reduce variance (like in Random Forests) or reduce bias (like in Gradient Boosting), leading to better generalization.",
    "rubric_id": ""
  },
  {
    "id": "e1987b2aa15170a1018d297f3dc475343200fc9e796df6649a906ca453c94a26",
    "text": "What is your favorite machine learning algorithm and why? (Sample 63)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a sophisticated algorithm and provide a deep technical justification. It should cover the algorithm's internal mechanics, its strengths in particular scenarios, and its key hyperparameters or limitations.",
    "rubric_id": ""
  },
  {
    "id": "d48dded7cdcd3d918dcec2c89b6b1b9f6183274df7981818ed2c931404b6902a",
    "text": "What is your favorite machine learning algorithm and why? (Sample 64)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should name a specific algorithm and give a clear, concise reason for the choice. The reason should relate to a practical aspect, such as its interpretability (e.g., Decision Trees) or its effectiveness on a certain type of data.",
    "rubric_id": ""
  },
  {
    "id": "302f02fbe801261aa3bd173075994ee566c3128d2b7e9a02ea9920fc42d3be48",
    "text": "What is the bias-variance tradeoff? (Sample 65)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a comprehensive explanation of the bias-variance tradeoff. It must define bias (underfitting) and variance (overfitting) mathematically or conceptually and explain how model complexity affects both, leading to the need for a balance to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "3b8600c31dd5d2811877cd1319bf1ab9790d31b349c751bfeb39c63fb4e60183",
    "text": "Can you explain the concept of gradient descent? (Sample 66)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain gradient descent as the core optimization algorithm for training many models. It should detail the process of iteratively updating parameters based on the gradient of the loss function and differentiate between batch, mini-batch, and stochastic variants.",
    "rubric_id": ""
  },
  {
    "id": "5aba8745bb36880f2b4f0669712db3dde1cfa272ba34292674d3a2345e2865a1",
    "text": "Explain cross-validation and its purpose. (Sample 67)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose: to get a more reliable estimate of model performance on unseen data. It should detail the k-fold procedure and explain how this reduces the variance of the performance estimate compared to a single train-test split.",
    "rubric_id": ""
  },
  {
    "id": "2da0f3df4ac923bbd9f5653b55293539162155d1c3fd84bc2ad6a40766827434",
    "text": "What is your favorite machine learning algorithm and why? (Sample 68)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should name a machine learning algorithm and state a valid reason for preferring it. The reason could be based on its simplicity, interpretability, or performance on a specific type of problem.",
    "rubric_id": ""
  },
  {
    "id": "ecb77a9ea01f6b2d3f8378ff109f941f350077504eba384d230f56b15f6b4920",
    "text": "What is principal component analysis (PCA)? (Sample 69)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define PCA as an unsupervised dimensionality reduction technique. It should explain that PCA identifies the directions (principal components) of maximum variance in the data and projects the data onto a lower-dimensional subspace.",
    "rubric_id": ""
  },
  {
    "id": "ec33947968e1168be7fbd0c87239a69a38bc870a4ef1572de6c4ca00580cc37e",
    "text": "What is regularization and why is it important? (Sample 70)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a method to prevent overfitting. It should explain that regularization adds a penalty for model complexity to the loss function, which helps the model generalize better to new data.",
    "rubric_id": ""
  },
  {
    "id": "a181df22746f4cb4f283a1ef23eb361ea2f4bbeaf0d237091d9b8a725504e6ee",
    "text": "Describe the process of backpropagation. (Sample 71)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe backpropagation as the algorithm for training neural networks. It should explain the two main phases: a forward pass to compute the output and the error, and a backward pass where the error is propagated back through the network to compute the gradients needed for weight updates, using the chain rule.",
    "rubric_id": ""
  },
  {
    "id": "2ffea6c180d3737e1bbffc0de0fad3d26e86267663f2297df0420f5a8c9e43e4",
    "text": "What is principal component analysis (PCA)? (Sample 72)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a linear transformation technique for dimensionality reduction. It should explain that it creates a new set of uncorrelated variables (principal components) that successively maximize variance.",
    "rubric_id": ""
  },
  {
    "id": "fbdb7d854ee3f9d8a9a17d9cb5d7d68aae500e236b39827ed478712c19e8144d",
    "text": "Describe the process of feature selection. (Sample 73)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must outline a comprehensive strategy for feature selection. It should compare and contrast filter, wrapper, and embedded methods, explaining the trade-offs between computational cost and performance for each.",
    "rubric_id": ""
  },
  {
    "id": "906a1fdb003b5ee22ded5ec289579132c135683c6742d696bbff4c176ada607f",
    "text": "How would you optimize a machine learning model? (Sample 74)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a multi-faceted optimization process. This must include hyperparameter tuning, feature engineering and selection, and potentially trying more complex models or ensemble methods to improve the chosen evaluation metric.",
    "rubric_id": ""
  },
  {
    "id": "90bcea416ada200a4015d9840de271c0244ca91d64f0206d4a021ec37c178d22",
    "text": "How would you approach data cleaning for a large dataset? (Sample 75)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must outline a basic data cleaning workflow. It should mention key tasks like handling missing values, identifying and removing duplicates, and correcting data type inconsistencies.",
    "rubric_id": ""
  },
  {
    "id": "3eea5d6dff9984e09693d54b06a4129660b9c01a652c73f9e5a94d536b53e289",
    "text": "How would you optimize a machine learning model? (Sample 76)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a structured approach to model improvement. Key elements to mention are systematic hyperparameter tuning, iterating on feature engineering, and analyzing model errors to guide the next steps.",
    "rubric_id": ""
  },
  {
    "id": "f22d1364e5bfdb48b1638c8012ccf2dd1caff834535fd2f724de569e0c9b84f3",
    "text": "What is the role of activation functions in deep learning? (Sample 77)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main role of activation functions is to introduce non-linearity into the network. This allows the model to learn complex patterns that a simple linear model cannot.",
    "rubric_id": ""
  },
  {
    "id": "695c3d1458f557ddc2ab3812536816acd429c7c8a24810fb28c7dc3a3580e05a",
    "text": "What metrics would you use to evaluate a regression model? (Sample 78)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several appropriate regression metrics. It must include common ones like MAE, MSE, and R-squared, and ideally explain the context in which one might be preferred over another (e.g., MAE's robustness to outliers).",
    "rubric_id": ""
  },
  {
    "id": "b4d6d8b3741cb96b46d93644af757d4c9f97caee687df1b8ba4073f88fdc3a1e",
    "text": "What is the difference between bagging and boosting? (Sample 79)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate the two ensemble methods. Bagging involves training models in parallel. Boosting involves training models sequentially, where each model focuses on the errors of the previous one.",
    "rubric_id": ""
  },
  {
    "id": "de82f8e7914ef5524215fbd7d4b0d112d6084e579dbb8f715b6ad9aae0dd35c2",
    "text": "What is principal component analysis (PCA)? (Sample 80)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed technical definition of PCA. It should explain that PCA performs an orthogonal transformation to convert a set of correlated variables into a set of linearly uncorrelated variables (principal components), and that these components are the eigenvectors of the covariance matrix.",
    "rubric_id": ""
  },
  {
    "id": "fc0d6b40b7519b946baa9dec2f0e3b8194a72730b131d2910caa319aa4133e12",
    "text": "Describe the process of feature selection. (Sample 81)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing the most important features for a model. It should mention the benefits, such as preventing overfitting and improving model performance.",
    "rubric_id": ""
  },
  {
    "id": "8a8e136b41831118a2ea0274831e0a62dc4ee84da2392e67c9e20996d3d7bbbb",
    "text": "Describe the process of backpropagation. (Sample 82)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe backpropagation as the algorithm for training neural networks. It should explain that it works by calculating the gradient of the loss function with respect to the network weights, propagating this error backward through the network using the chain rule to update the weights.",
    "rubric_id": ""
  },
  {
    "id": "473f05e53df556b2b6abb6d90662e54a6b1db2481c6182b75c166b315f89b5f1",
    "text": "What is the difference between bagging and boosting? (Sample 83)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference: bagging builds models independently in parallel, while boosting builds them sequentially, with each new model trying to correct the errors of the previous one.",
    "rubric_id": ""
  },
  {
    "id": "e195840e8b83ed598c033fc556b5efe05bbb9e908fcf7256e2ba6e4f95780792",
    "text": "What is your favorite machine learning algorithm and why? (Sample 84)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a reasonable justification. The reason should be tied to a specific characteristic, like the algorithm's performance, interpretability, or ease of use.",
    "rubric_id": ""
  },
  {
    "id": "4229a35da0e509046f0b69d56ab2208294711a658011902c8cbd59d4c7eeb246",
    "text": "How does a neural network work? (Sample 85)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive explanation. It should describe the architecture of layers of neurons, the process of forward propagation where weighted inputs are passed through activation functions, and the process of backpropagation where weights are updated to minimize a loss function.",
    "rubric_id": ""
  },
  {
    "id": "2e444c1ecddc342f918ee30c2405a1f01d34507c37fed55fa5370ce30f0c0bd6",
    "text": "What is regularization and why is it important? (Sample 86)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of regularization as a technique to combat overfitting. It should explain the mathematical intuition of adding a penalty term to the loss function and differentiate between L1 and L2 regularization, explaining their different effects on the model weights.",
    "rubric_id": ""
  },
  {
    "id": "f7ff5d8df396326a2dd7f5726c77b372f3dd809bd242c2fadc34cd06e45a7c58",
    "text": "How would you approach data cleaning for a large dataset? (Sample 87)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline a structured approach suitable for large data. This includes profiling the data to find anomalies, using appropriate imputation strategies for missing values, and writing clean, reproducible code. It should also mention considering distributed frameworks if the data is too large for a single machine.",
    "rubric_id": ""
  },
  {
    "id": "753d4be31d8843b91676fa9778bfdd4784a1baaf1d6202f58ddcf7d17149727a",
    "text": "What is your favorite machine learning algorithm and why? (Sample 88)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a deep technical justification for its preference. The reasoning should demonstrate a strong understanding of the algorithm's theoretical underpinnings, practical applications, and trade-offs.",
    "rubric_id": ""
  },
  {
    "id": "66803d609b25595b71dfc2379847962dd3989e857a7fd74aa55fc39b1027da72",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 89)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference in the penalty term. L1 regularization (Lasso) adds a penalty based on the absolute value of the weights, which can lead to sparse models. L2 regularization (Ridge) adds a penalty based on the square of the weights.",
    "rubric_id": ""
  },
  {
    "id": "4e5cfb5e409244b02a099789cd24faece78b612a00dee16e1a5e64a69ae508af",
    "text": "What is the role of activation functions in deep learning? (Sample 90)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the primary purpose of activation functions is to introduce non-linearity into a neural network, which allows it to learn complex, non-linear relationships in the data.",
    "rubric_id": ""
  },
  {
    "id": "53b0a3367f82f4e5a4a7ebce0c5bd6afa7d4d48dae5cb05f277b4a58bf63b29a",
    "text": "Explain cross-validation and its purpose. (Sample 91)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as getting a more reliable estimate of a model's performance on unseen data. It should describe the k-fold process of splitting the data and iteratively training and testing on different subsets.",
    "rubric_id": ""
  },
  {
    "id": "0cf6617aa06d9f426cc11fafff1dea257718210d4f6b5bb92775151339a028af",
    "text": "Explain cross-validation and its purpose. (Sample 92)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of cross-validation. It should not only describe the k-fold procedure but also explain why it's a better estimate of generalization error than a single train-test split, by reducing the variance of the performance estimate.",
    "rubric_id": ""
  },
  {
    "id": "7dcfe5f4892d5e262a449e5f2c09cbf34564e6af551e1cb4daa5b13847221858",
    "text": "What is regularization and why is it important? (Sample 93)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting in machine learning models. It is important because it helps the model generalize better to new, unseen data by penalizing model complexity.",
    "rubric_id": ""
  },
  {
    "id": "c708fcd919f3e1f15d2aeb18de5e6d55f195094f53672397b8117573db25abd8",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 94)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain the mathematical difference in their penalty terms (absolute vs. squared weights) and the practical consequence: L1 (Lasso) can produce sparse models and perform feature selection, while L2 (Ridge) shrinks weights but does not set them to zero.",
    "rubric_id": ""
  },
  {
    "id": "0245a9d7f898606e93c7e95e77ab181570a616e6873793ff2d7af2d5b6c44f04",
    "text": "What metrics would you use to evaluate a regression model? (Sample 95)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list several common regression metrics and explain their use cases. It must include metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared, and explain what each one measures.",
    "rubric_id": ""
  },
  {
    "id": "d8fea60106015841b24fc3846f9e2dd45c872007d1b2ec8c75211603c12b343b",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 96)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must highlight the core difference: L1 regularization can lead to some model weights being exactly zero, effectively performing feature selection. L2 regularization makes weights smaller but does not typically set them to zero.",
    "rubric_id": ""
  },
  {
    "id": "3a3d0eee06adff7a36ce9ec85a3595e2f57a7ddb5482921372b785d7c696a063",
    "text": "How would you approach data cleaning for a large dataset? (Sample 97)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must outline a basic workflow for data cleaning. Key steps to include are identifying and handling missing values, removing duplicate entries, and correcting formatting errors.",
    "rubric_id": ""
  },
  {
    "id": "387e267ceab932b11d7b04b97567f2b034e4eec17c160b1b4f1323c5a1c9ece9",
    "text": "What is regularization and why is it important? (Sample 98)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique used to prevent a model from overfitting to the training data. It is important because it improves the model's ability to generalize to new data.",
    "rubric_id": ""
  },
  {
    "id": "293978c0440f720383e4685ca61b4a8aa1f0d8e22667da257f7c3643524fa9c6",
    "text": "What are the key differences between classification and regression? (Sample 99)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must differentiate based on the model's output. Classification models predict a discrete category or class label. Regression models predict a continuous numerical value.",
    "rubric_id": ""
  },
  {
    "id": "ef177eae0bc26eaba0aa3ecb413685f9017dc238e1588b545f399ae9f3343bbf",
    "text": "What is your favorite machine learning algorithm and why? (Sample 100)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a deep and technically accurate justification. The reasoning should demonstrate a strong understanding of the algorithm's mechanics, its advantages, limitations, and the types of problems it is best suited for.",
    "rubric_id": ""
  },
  {
    "id": "a6bb24e60625f63a5a21e3fd81ad0541d4bf5d1dadba5c8c0163cf88885690af",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 101)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must follow the STAR method and describe a project with significant technical depth. It should detail complex challenges related to data, modeling, or deployment and explain the sophisticated actions taken to overcome them, concluding with the project's quantifiable impact.",
    "rubric_id": ""
  },
  {
    "id": "84cd2889b73acf995856b109f916496c9172d07fd50034fe2c9328ebcf8d0a59",
    "text": "Can you explain the concept of gradient descent? (Sample 102)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an iterative optimization algorithm. It should explain the core concept of moving in the opposite direction of the gradient of a loss function to find its minimum.",
    "rubric_id": ""
  },
  {
    "id": "35ac1a805d998b73183904f76ffa88a2ffb56dcef72a8848ac2fbf5f6a41e8d2",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 103)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a technically complex project. It should focus on difficult aspects, such as novel feature engineering, custom model architecture, or overcoming significant data limitations, and must present clear, measurable results.",
    "rubric_id": ""
  },
  {
    "id": "d1f99b3b5aa2a2b4752bbb5ae7057f1d1d679a3f77542b0ff8959caa8ac97f9a",
    "text": "What is your favorite machine learning algorithm and why? (Sample 104)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear technical justification. The reasoning should cover its strengths, weaknesses, and a specific scenario where it would be an appropriate choice.",
    "rubric_id": ""
  },
  {
    "id": "795fc2694f8de92ca000b961cb3039450b96f5b31a857c917b853cc12eefb929",
    "text": "What metrics would you use to evaluate a regression model? (Sample 105)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common regression metrics like MAE, MSE, and R-squared. It must also explain the trade-offs, such as RMSE's sensitivity to large errors and R-squared's interpretation as variance explained.",
    "rubric_id": ""
  },
  {
    "id": "f125573db37e6e756bdc756dd3972a411a24727b629b17b191b718651957fb18",
    "text": "How would you optimize a machine learning model? (Sample 106)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a basic optimization workflow. This must include tuning hyperparameters, performing feature selection, and potentially trying different algorithms to improve a specific metric.",
    "rubric_id": ""
  },
  {
    "id": "5cc8f6347f37fd634a7c76c8f89d4dc957bafa6637de0fd89ca7229696599fe9",
    "text": "Explain cross-validation and its purpose. (Sample 107)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as obtaining a more reliable estimate of model performance on unseen data. It should describe the k-fold procedure of splitting data into folds and iteratively training and testing on them.",
    "rubric_id": ""
  },
  {
    "id": "cc7fce8268593d468321365fe4c9d57b53702bbf85cde44214a037b81351f110",
    "text": "What is the role of activation functions in deep learning? (Sample 108)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that activation functions introduce non-linearity into a neural network. It should explain that this is essential for the network to learn complex patterns that cannot be modeled by a simple linear combination of inputs.",
    "rubric_id": ""
  },
  {
    "id": "bd821bc0c1a006db61b288b243db952294c20c2892e85b6f2e0c7b26d3aa4dab",
    "text": "What are the advantages of ensemble methods? (Sample 109)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main advantage of ensemble methods is improved predictive performance and model robustness compared to using a single model.",
    "rubric_id": ""
  },
  {
    "id": "09b7ca34e150243e7dd21434d71b1ae333bcec1dd107592276cd4e266b8840cc",
    "text": "What are the advantages of ensemble methods? (Sample 110)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain that ensemble methods combine multiple models to produce a better result, typically by reducing overfitting and improving generalization.",
    "rubric_id": ""
  },
  {
    "id": "09d38caa3645127108b5a02f29017fba1f0f5708eef3a0ca9f8ba0bf49b460b4",
    "text": "How would you approach data cleaning for a large dataset? (Sample 111)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline a systematic process. It should include data profiling to identify issues, strategies for handling missing data and outliers, and writing reproducible code. Mentioning scalable tools like Spark is a plus.",
    "rubric_id": ""
  },
  {
    "id": "58284ed920b31429f1c83127aaecbdfd3845d64f16445843dfbd3d7067ea518c",
    "text": "Can you explain the concept of gradient descent? (Sample 112)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an optimization algorithm for finding the minimum of a function. The core concept to check for is the idea of iteratively taking steps proportional to the negative of the gradient.",
    "rubric_id": ""
  },
  {
    "id": "fb42275eb948d00d300c10a2ddc8746be56081f84c6fd4277d75ca7aac001617",
    "text": "How does a neural network work? (Sample 113)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive overview. It must cover the layered architecture of neurons, the role of weights and biases, the forward propagation of signals through non-linear activation functions, and the backpropagation algorithm for updating weights to minimize a loss function.",
    "rubric_id": ""
  },
  {
    "id": "608c5848f6e737e7c8a1a5e5d6c4bd5b32b33855d882f452fd7522d1b9909be1",
    "text": "What are the key differences between classification and regression? (Sample 114)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must clearly distinguish between predicting discrete categories (classification) and continuous values (regression). It should also mention that this difference leads to the use of different model types (e.g., Logistic vs. Linear Regression) and evaluation metrics (e.g., Accuracy vs. RMSE).",
    "rubric_id": ""
  },
  {
    "id": "b83e381d4e07dc9f63291c114c3801ea327b5ab357a6d36a5d6925d3ed0899db",
    "text": "What is the bias-variance tradeoff? (Sample 115)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define both bias (error from simple models, underfitting) and variance (error from complex models, overfitting). It must explain that decreasing one typically increases the other, and the goal is to find a balance.",
    "rubric_id": ""
  },
  {
    "id": "3bd776c9ce23af53d015f6b49d2d0b2fdd3f30fa931d2b4049c48ecbecbbe63c",
    "text": "What metrics would you use to evaluate a regression model? (Sample 116)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list and differentiate common regression metrics. It should include MAE, MSE/RMSE, and R-squared, and explain their properties, such as MAE's robustness and RMSE's penalty for large errors.",
    "rubric_id": ""
  },
  {
    "id": "52f90aed27014c9410229d4c2df65eba5c1186962b20157cf989711b7fbd0560",
    "text": "What is the difference between bagging and boosting? (Sample 117)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. Check for: bagging uses parallel training on bootstrap samples to reduce variance. Boosting uses sequential training where models correct their predecessors' errors to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "6244b35f2ac8633d4b4ac0a87904f9580172717d34e3e2442eede48ed90ff2d5",
    "text": "What is the role of activation functions in deep learning? (Sample 118)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity, which is essential for neural networks to learn complex patterns. Without them, a deep network would be equivalent to a single linear model.",
    "rubric_id": ""
  },
  {
    "id": "078c1761a86cfaf27b51dc2633a86b0122084655e067722436ff23010b26a77a",
    "text": "How would you optimize a machine learning model? (Sample 119)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a multi-step process for model improvement. This must include hyperparameter tuning, feature engineering, and error analysis to identify areas for improvement.",
    "rubric_id": ""
  },
  {
    "id": "63eb7fc77949b0a02f1207cb0aee17dfadbea9300426e33f0ce0c0b7bd9d3a7b",
    "text": "What are the key differences between classification and regression? (Sample 120)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the target variable. Classification predicts a discrete class, while regression predicts a continuous value. It should also mention that they use different types of algorithms and evaluation metrics.",
    "rubric_id": ""
  },
  {
    "id": "7fcf942cbcfc2c2859d1287027a65e785f09b4fe20f6b4fc9390ffbc4acbeff1",
    "text": "What is the difference between bagging and boosting? (Sample 121)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference: Bagging trains models in parallel on random subsets of data. Boosting trains models sequentially, with each model focusing on the errors of the previous one.",
    "rubric_id": ""
  },
  {
    "id": "2e7c37545475c78a439fdc5380c9f82e83332a0847ce23b00cf3be6b8037a8e1",
    "text": "What is regularization and why is it important? (Sample 122)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting by adding a penalty for model complexity to the loss function. It is important because it helps models generalize better to new data.",
    "rubric_id": ""
  },
  {
    "id": "8e96dadb17ef0404c59fb6170846362f99b5762619fb9a6947935d33ded7f194",
    "text": "What metrics would you use to evaluate a regression model? (Sample 123)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must list and critically compare multiple regression metrics. It should discuss the pros and cons of MAE, MSE, RMSE, and R-squared, and explain which metric would be most appropriate under different business contexts (e.g., when large errors are particularly undesirable).",
    "rubric_id": ""
  },
  {
    "id": "2374959fdede5ad78df8afdbed883bbbcf3c6a505e36120cc68702742df15e82",
    "text": "What are the key differences between classification and regression? (Sample 124)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the fundamental difference based on the output: classification predicts a category, while regression predicts a number.",
    "rubric_id": ""
  },
  {
    "id": "106eb651dc21da7c6cabc20852be448126b1503f36a677065b46360d34a79a0e",
    "text": "What is the bias-variance tradeoff? (Sample 125)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation. It must define bias as error from wrong assumptions (underfitting) and variance as error from sensitivity to the training data (overfitting). It must explain their inverse relationship and the goal of finding a balance to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "da85442f23f14d4f10a6dadae64462a1e21147bca1f54791502ba421bda095ce",
    "text": "What is regularization and why is it important? (Sample 126)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It should explain that this is achieved by adding a penalty to the loss function that discourages complex models, thus improving generalization.",
    "rubric_id": ""
  },
  {
    "id": "26122b1c8596a65caa0211fefa04833d7640c74b08b56b7938c9558423da7721",
    "text": "Describe the process of feature selection. (Sample 127)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing a subset of the most important features for a model. It should mention benefits like improved performance and reduced complexity.",
    "rubric_id": ""
  },
  {
    "id": "59a6c75e7d38ae5e345d27a9144d66f03e5fe36a808d6650bf90d2ddee989199",
    "text": "How would you optimize a machine learning model? (Sample 128)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive and structured optimization process. It should include advanced hyperparameter tuning techniques (like Bayesian optimization), iterative feature engineering based on error analysis, and potentially exploring different model architectures or ensemble methods.",
    "rubric_id": ""
  },
  {
    "id": "1b26683840482f8178556d182aa0d0d5667b1df31cc06fc5349896a590003aeb",
    "text": "What is principal component analysis (PCA)? (Sample 129)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a linear dimensionality reduction method. It should explain that it transforms data to a new coordinate system where the axes (principal components) are orthogonal and capture the maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "58e3c72ae11506f8f1e2051333aab2e9945eb712403497ff25083264ca21dfae",
    "text": "What metrics would you use to evaluate a regression model? (Sample 130)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list and explain the use of several regression metrics. Check for MAE, MSE, RMSE, and R-squared, with a brief explanation of what each one represents.",
    "rubric_id": ""
  },
  {
    "id": "2837d1d357c134b0ec6603e529f11802497671e0ee68c81b0b88c2df90f72558",
    "text": "What is the role of activation functions in deep learning? (Sample 131)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity, which is critical for learning complex patterns. It should compare different functions (e.g., ReLU, sigmoid) and discuss their impact on training dynamics, like the vanishing gradient problem.",
    "rubric_id": ""
  },
  {
    "id": "0d49b879c8b4f2137e80eca0b78cfb0736a009977e5aea345e895c3b9458ecd8",
    "text": "Describe the process of feature selection. (Sample 132)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of selecting the most relevant features from a dataset to use for model training, with the goal of improving performance and simplicity.",
    "rubric_id": ""
  },
  {
    "id": "7afbf06f68716217b8953e83ba3ac499ab0c06e061f1402905a9c49e5df38147",
    "text": "What metrics would you use to evaluate a regression model? (Sample 133)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list several key regression metrics. It should include and differentiate between Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.",
    "rubric_id": ""
  },
  {
    "id": "0548fc32201b6201b526a1dabc324d24473b4592f5c2c1d131a13d8745dc05d8",
    "text": "Can you explain the concept of gradient descent? (Sample 134)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an optimization algorithm used to minimize a function. It should explain the core idea of iteratively taking steps in the direction opposite to the gradient.",
    "rubric_id": ""
  },
  {
    "id": "ae8f67ea11f5873bdcc85d9b5e7bf61cd31e1269fed57eb1c5469e03d4f7b6b5",
    "text": "What metrics would you use to evaluate a regression model? (Sample 135)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list common regression metrics and explain their properties. It must include MAE (robust to outliers), MSE/RMSE (penalizes large errors), and R-squared (measures explained variance).",
    "rubric_id": ""
  },
  {
    "id": "81b1b15d57ba05726b6b997da4fe7d75d1b717af6769511714b9283a0b4bd775",
    "text": "What are the advantages of ensemble methods? (Sample 136)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation. It must state that ensembles improve predictive accuracy and robustness. It should explain how different methods achieve this: bagging by reducing variance and boosting by reducing bias.",
    "rubric_id": ""
  },
  {
    "id": "43f69f102b01ec82c88dec819639927d15bc7f39ad6b3617ce6ee2e7f9f44bb2",
    "text": "How does a neural network work? (Sample 137)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive explanation of a neural network. It should cover the layered architecture, the role of neurons, weights, and biases, the forward pass through activation functions to generate a prediction, and the backpropagation algorithm used to update weights based on a loss function.",
    "rubric_id": ""
  },
  {
    "id": "ac5f44aebbc096e000541b237c880336445799ca391a4ac7d3d5354e11abc56e",
    "text": "What is regularization and why is it important? (Sample 138)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It's important because it adds a penalty for model complexity, helping the model generalize better to new, unseen data.",
    "rubric_id": ""
  },
  {
    "id": "0675276496115bb9062dd52baef416fde04c64354a564503dff35756560c6159",
    "text": "What is the bias-variance tradeoff? (Sample 139)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define bias as error from a model being too simple and variance as error from a model being too complex. It must explain the trade-off: reducing one often leads to an increase in the other.",
    "rubric_id": ""
  },
  {
    "id": "5607069ca21e4d62b089886bfbaac7ea58647221d79707b85fd355d2fde256ff",
    "text": "What is the difference between bagging and boosting? (Sample 140)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate the two ensemble learning techniques. Bagging involves training models in parallel on different subsets of data. Boosting involves training models sequentially, where each model focuses on the errors of the previous one.",
    "rubric_id": ""
  },
  {
    "id": "043e581d7d4fbfa026501c2d788d52c6d4e5f11f1d62e41618b112001154bad5",
    "text": "What is your favorite machine learning algorithm and why? (Sample 141)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear, simple justification. The reason should relate to a practical benefit like its ease of interpretation or its general effectiveness.",
    "rubric_id": ""
  },
  {
    "id": "f5ec5cd4576fd1cfe3aa300a1aa39dd285a3cc7cd0fd48f55bd24e5b8fad6e49",
    "text": "What is the role of activation functions in deep learning? (Sample 142)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that activation functions introduce non-linearity into the network. This is crucial for enabling the model to learn complex, non-linear relationships between inputs and outputs.",
    "rubric_id": ""
  },
  {
    "id": "379305a0fca26e41426c157c2e2fcc28ab837cf685ee22404cb222d564255cdb",
    "text": "How would you optimize a machine learning model? (Sample 143)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive optimization strategy. This should include advanced hyperparameter tuning (e.g., Bayesian Optimization), iterative feature engineering informed by error analysis, and potentially exploring more sophisticated model architectures or ensemble techniques.",
    "rubric_id": ""
  },
  {
    "id": "a7f4086303b8a02afcb76e7a50ce34297714d44230226c7117294dedb66d54ff",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 144)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must follow the STAR method (Situation, Task, Action, Result) to describe a project with significant technical complexity. It should detail the specific challenges, the advanced techniques used to solve them, and the measurable business impact.",
    "rubric_id": ""
  },
  {
    "id": "1c74987f2716339ae69736dbceac6d9f3aa6df632de1671e34e0a6c5a967d30e",
    "text": "How does a neural network work? (Sample 145)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe the basic structure of a neural network, mentioning layers of interconnected nodes (neurons). It should explain that data flows through these layers, with each neuron applying a simple computation to its inputs.",
    "rubric_id": ""
  },
  {
    "id": "416949f43be0e2714820123d858a63ed0bf3a7ce4de9961c9258b2ecfda2899d",
    "text": "What is the difference between bagging and boosting? (Sample 146)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between the two ensemble methods. Bagging trains models in parallel to reduce variance. Boosting trains models sequentially to reduce bias by focusing on errors from previous models.",
    "rubric_id": ""
  },
  {
    "id": "3b5cd0e879743a54811d3d57df8f97640e75f84b7da5e9c0fb6e3e5058cc1bc7",
    "text": "What is the role of activation functions in deep learning? (Sample 147)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that activation functions are essential for introducing non-linearity into a neural network, which allows it to learn complex patterns.",
    "rubric_id": ""
  },
  {
    "id": "9db33e047e539e2b332fafcdf168432a75151b72958cc94a24402c3af1142a98",
    "text": "How would you explain the concept of overfitting? (Sample 148)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define overfitting as a model that performs well on training data but poorly on unseen data. It should explain that this occurs when the model learns noise from the training data instead of the underlying signal, and mention potential solutions like regularization.",
    "rubric_id": ""
  },
  {
    "id": "badf6c5c9f402e9a8efbb6cbb84b1c566cc62926a176df5ded14ec36748f3d8e",
    "text": "What are the advantages of ensemble methods? (Sample 149)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main benefit of ensemble methods is that they combine multiple models to create a final model that is more accurate and robust than any single model.",
    "rubric_id": ""
  },
  {
    "id": "7ea85a396756b4ace7e85c72608f66f7cfb4246c841fba5bdcd049a616b28188",
    "text": "What is the role of activation functions in deep learning? (Sample 150)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linear transformations to the output of neurons, which is critical for the network to be able to model complex data patterns.",
    "rubric_id": ""
  },
  {
    "id": "6473dd4fe2a01345f85007f6e5aaea4ee939c5e9ac718428cfe189fb32b22e87",
    "text": "What is regularization and why is it important? (Sample 151)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It's important because it discourages model complexity, helping the model to generalize better to new data.",
    "rubric_id": ""
  },
  {
    "id": "4bdf092f11c281a948157a0cbf18e69b0afb4b70df839eadb1f34e52942118eb",
    "text": "What metrics would you use to evaluate a regression model? (Sample 152)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must list and critically evaluate several regression metrics. It should discuss the pros and cons of metrics like MAE, MSE, RMSE, and R-squared in different contexts, demonstrating an understanding of their statistical properties and business implications.",
    "rubric_id": ""
  },
  {
    "id": "ba4faf6636d3cf983c7e6a8d4dc6b98cc42e23ec9220a65d217f6cbc3d86c06d",
    "text": "Describe the process of backpropagation. (Sample 153)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe backpropagation as the core algorithm for training neural networks. It should explain that it involves a forward pass to get the prediction and error, followed by a backward pass that uses the chain rule to calculate the gradient of the error with respect to each weight, which is then used for updates.",
    "rubric_id": ""
  },
  {
    "id": "1fc1090d853ac6e6bac18141bf7c0f4c227289c2f8b97fd5a418d0c902d5b3e7",
    "text": "Describe the process of feature selection. (Sample 154)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing a subset of relevant features from a dataset. It should mention that the goal is to improve model performance and reduce training time.",
    "rubric_id": ""
  },
  {
    "id": "82cfc20e966f62de47ef7f033605533c9dacfbdf62922c154ee2e30b9cff2238",
    "text": "What is your favorite machine learning algorithm and why? (Sample 155)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear, concise justification for the choice, relating it to a practical characteristic like its performance or interpretability.",
    "rubric_id": ""
  },
  {
    "id": "9dffc9ce945585e45858456754f4e0305c2d2f3915c36754fe94b0a710af7588",
    "text": "How would you explain the concept of overfitting? (Sample 156)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as what happens when a model learns the training data too well, including noise. It must state that this leads to poor performance on new data.",
    "rubric_id": ""
  },
  {
    "id": "e763661bc81673e87d1793f4db4ec99617cd98bd9240e41c5915faea4a2bde61",
    "text": "Can you explain the concept of gradient descent? (Sample 157)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an optimization algorithm. It should explain the core idea of iteratively taking steps in the direction of the negative gradient (downhill) to find the minimum of a function.",
    "rubric_id": ""
  },
  {
    "id": "3df41414cbf1c69a46b356c81587e389b2250b6d0325ab8b51e5966f580e9455",
    "text": "How would you optimize a machine learning model? (Sample 158)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a basic model optimization process. This must include tuning model hyperparameters and possibly performing feature selection to improve performance.",
    "rubric_id": ""
  },
  {
    "id": "1a18b65ad6ad16ec690210032cb934fc68db1d93055b463fe9c5945e5fcc56bc",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 159)",
    "domain": "behavioral-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must follow the STAR method (Situation, Task, Action, Result) to describe a project. It should clearly outline the project's goal, the steps taken, the ML techniques used, and the final outcome.",
    "rubric_id": ""
  },
  {
    "id": "c8e30460092f329332885523ddcc111c16825ff8d61566bb6e5d55d4ae388467",
    "text": "How does a neural network work? (Sample 160)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe the basic structure of a neural network as layers of connected nodes. It must explain that information is passed forward through these layers, with each node applying a simple calculation.",
    "rubric_id": ""
  },
  {
    "id": "467a10482318d8787438a31b3f8d30e8b21ebe7922a314c535262b42e48ff5f7",
    "text": "What is regularization and why is it important? (Sample 161)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting by adding a penalty for model complexity. It's important for improving a model's generalization to unseen data.",
    "rubric_id": ""
  },
  {
    "id": "9d83aa2711265d00cdc8af66262c35483631e4a0f2047b959982ca86f18576cd",
    "text": "What are the key differences between classification and regression? (Sample 162)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference based on the prediction target: classification predicts a discrete class label, whereas regression predicts a continuous numerical value.",
    "rubric_id": ""
  },
  {
    "id": "ec902edd2babf6e7214accc9a6ed7f57cbd9ed7b93911d9c5cfece1c45485e4e",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 163)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with a significant technical challenge. It should detail the problem, the specific actions taken to address the challenge (e.g., advanced feature engineering, model tuning), and the resulting impact.",
    "rubric_id": ""
  },
  {
    "id": "84c0aa8aa1e57de46ed9b0c68e47081701dbc2f43b3699e4a920c19c109f4815",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 164)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain the key difference: L1 regularization can shrink some weights to zero, effectively performing feature selection, while L2 regularization encourages smaller weights but doesn't force them to zero.",
    "rubric_id": ""
  },
  {
    "id": "56b2cc9b5d7b55c00ee3ebdd8ba71878c0ab29e11b50aab348076cd135b2daba",
    "text": "Can you explain the concept of gradient descent? (Sample 165)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm. It should describe the process of calculating the gradient of a loss function and updating model parameters in the opposite direction to find a minimum. It should also differentiate between batch, mini-batch, and stochastic variants.",
    "rubric_id": ""
  },
  {
    "id": "b8d60024d98e9e3a2ddedccbca968eaa830a20dd544e7bc624113d42019bff9d",
    "text": "What metrics would you use to evaluate a regression model? (Sample 166)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison of multiple regression metrics. It should discuss the properties and trade-offs of MAE, MSE, RMSE, and R-squared, and explain how the choice of metric depends on the specific business problem and the cost of different types of errors.",
    "rubric_id": ""
  },
  {
    "id": "f436792ba81f002c891bc481b28eea1daeb2aeafdd8d0f8e2e5cd38321ca5dcd",
    "text": "How do you handle missing values in a dataset? (Sample 167)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list common methods for handling missing data. This should include removing rows/columns with missing values or imputing them with a value like the mean, median, or mode.",
    "rubric_id": ""
  },
  {
    "id": "58a41997f4c87e1e570c1ef8912db7c8b69a1dbd26d2745429388ed583e94208",
    "text": "What is principal component analysis (PCA)? (Sample 168)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a deep technical explanation of PCA. It should describe it as a linear transformation that finds the eigenvectors of the covariance matrix of the data. These eigenvectors (principal components) form an orthogonal basis that captures the directions of maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "25a42300ece50228695ad25a3a98170dc201af56c578a1f6256701c66a2144da",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 169)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast the penalty terms and their effects. L1 (Lasso) uses an absolute value penalty, leading to sparsity and feature selection. L2 (Ridge) uses a squared penalty, which shrinks coefficients but doesn't set them to zero.",
    "rubric_id": ""
  },
  {
    "id": "55285e60b48f727cb556f45951b49d66216e8e7897d3929b698e1a20c5ed4d2d",
    "text": "How does a neural network work? (Sample 170)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a neural network as a series of connected layers of nodes. It must explain that data is passed forward through these layers, with each node applying a simple computation to its inputs.",
    "rubric_id": ""
  },
  {
    "id": "60a10b88fde56a87e5ab42333e4595a7c20a57a8f32c21fc15c04a38f323474a",
    "text": "What is principal component analysis (PCA)? (Sample 171)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a dimensionality reduction technique. It should explain that it works by finding a new set of orthogonal axes (principal components) that capture the most variance in the data.",
    "rubric_id": ""
  },
  {
    "id": "a6ec924eb670dff286d1ab1c29db5eced5d30507ae85a3e378aaae592366cdf2",
    "text": "Describe the process of backpropagation. (Sample 172)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must describe backpropagation as the method for training neural networks. It should explain the core idea of calculating the error at the output and propagating it backward through the network to update the weights.",
    "rubric_id": ""
  },
  {
    "id": "2e9f6780ba4d4523c86446f0b475e8435efa254aba57806f2fd00f7a4247c1c4",
    "text": "What is regularization and why is it important? (Sample 173)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization as a method to combat overfitting. It must explain the mathematical intuition of adding a penalty term to the loss function and differentiate between L1 and L2 penalties, linking them to the bias-variance tradeoff.",
    "rubric_id": ""
  },
  {
    "id": "1bd66fbe1abae47e037349f21d4a07a168d0094088184c01508401ec72eba2f2",
    "text": "Describe the process of backpropagation. (Sample 174)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe backpropagation as the algorithm for training neural networks by calculating gradients. It should explain the two main steps: a forward pass to compute the output and a backward pass that uses the chain rule to compute the gradient of the loss with respect to each weight.",
    "rubric_id": ""
  },
  {
    "id": "30af3500887d9ee5fc63dff374bd2b0d37008ceba5be33f94f6617c1b43fc665",
    "text": "What is your favorite machine learning algorithm and why? (Sample 175)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear technical reason for the preference. The justification should be based on its performance characteristics, such as its handling of certain data types, its interpretability, or its efficiency.",
    "rubric_id": ""
  },
  {
    "id": "c79a6fdf3b153c26b9386f9df008f1e93abc6ecc6d25fe2624ea5c2f1ac6d677",
    "text": "Describe the process of backpropagation. (Sample 176)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the core training algorithm for neural networks. It should describe the process of calculating the model's error and feeding that error backward through the network to adjust the weights.",
    "rubric_id": ""
  },
  {
    "id": "582c420b5e3824d3f96f3b980030c66c300c20355e04b6a1ef749c2a46487873",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 177)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method (Situation, Task, Action, Result) to describe a project with a clear technical challenge. It should detail the problem, the solution implemented, and the final measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "bac646f4a75c8edf1efe060a2a1585a59eed8629293bb66ebf962834dfb54fb0",
    "text": "Describe the process of feature selection. (Sample 178)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive feature selection strategy. It should differentiate between filter, wrapper, and embedded methods, explaining their pros and cons and providing examples of when each would be appropriate.",
    "rubric_id": ""
  },
  {
    "id": "87cbc00ae903b94a10d2980589a1eeb8f33c08d9cdec77ace71ed2ea7671edf7",
    "text": "What is principal component analysis (PCA)? (Sample 179)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a technique for linear dimensionality reduction. It should explain that it projects data onto a lower-dimensional space by finding the directions of maximum variance, known as principal components.",
    "rubric_id": ""
  },
  {
    "id": "2c93b34e09e00ac87d0da3cf54a0a34543d3f8141adf120ac8e589a46efd78e9",
    "text": "Can you explain the concept of gradient descent? (Sample 180)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an optimization algorithm for minimizing a function. It should explain the core idea of iteratively taking steps in the direction opposite to the function's gradient.",
    "rubric_id": ""
  },
  {
    "id": "662b3e917f9934689b82b63c8571d86f49a60dafabd884c4d40f5513081a1422",
    "text": "What are the key differences between classification and regression? (Sample 181)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clearly distinguish between the two supervised learning tasks based on their output. Classification predicts a discrete category, while regression predicts a continuous numerical value.",
    "rubric_id": ""
  },
  {
    "id": "ff5daaed0042e120dbc1d7add96b53fc756bd4da6cba53cdbc890e389273872f",
    "text": "What is your favorite machine learning algorithm and why? (Sample 182)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and give a valid, concise reason for the choice, such as its good performance, interpretability, or speed.",
    "rubric_id": ""
  },
  {
    "id": "f62b010488081e814ab6158be0367d7392fb4560a8e381ae1072efb0806f4e0a",
    "text": "What is the difference between bagging and boosting? (Sample 183)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the fundamental difference: bagging trains models in parallel, while boosting trains them sequentially.",
    "rubric_id": ""
  },
  {
    "id": "086c984adfe290674142a0643ad616276ae626f6c6e7957ad298388540e8a3c7",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 184)",
    "domain": "behavioral-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must follow the STAR method (Situation, Task, Action, Result) to describe a past project. It should clearly outline the project's purpose, the actions taken, and the final outcome.",
    "rubric_id": ""
  },
  {
    "id": "26420e9815ac5fa2bfa15d61f900230f438d645f18ed649680158966706f8103",
    "text": "Can you explain the concept of gradient descent? (Sample 185)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm used to minimize a loss function. It should describe the process of updating parameters by moving in the opposite direction of the gradient and mention different variants like batch and stochastic.",
    "rubric_id": ""
  },
  {
    "id": "3d6b21abd1b0a845714b09d745b93c789698dc67d1ce1b591963c41d95a7448e",
    "text": "What is principal component analysis (PCA)? (Sample 186)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define PCA as a dimensionality reduction technique. It should explain that it finds a new set of features (principal components) that are uncorrelated and capture the most variance in the data.",
    "rubric_id": ""
  },
  {
    "id": "81978a3bfa3611bedf3747c28b0af094ff572f76cc49f67a4d06603b70221de7",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 187)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain the mathematical difference in their penalty terms (sum of absolute vs. sum of squared weights) and the practical consequence: L1's ability to perform feature selection by creating sparse models, versus L2's tendency to shrink all weights.",
    "rubric_id": ""
  },
  {
    "id": "b94b380d9b87775fe22eff6c1ee940637ee4c6d5b077f106b1e5db5b79f30663",
    "text": "How would you explain the concept of overfitting? (Sample 188)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define overfitting as a model that learns the training data, including noise, too well, resulting in poor performance on new data. It should connect this concept to high variance in the bias-variance tradeoff.",
    "rubric_id": ""
  },
  {
    "id": "8d236d9bbcddc1bc9a60751b19a8f749f439518bac872752af9b680ea3e55e99",
    "text": "What are the key differences between classification and regression? (Sample 189)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference based on the target variable's type: classification predicts discrete categories, while regression predicts continuous numbers.",
    "rubric_id": ""
  },
  {
    "id": "dbc599a0b42565e492a7c702bb7c401d715a470f5f48f665d3fe427e50cf1b3d",
    "text": "How would you optimize a machine learning model? (Sample 190)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a basic model optimization process. This must include tuning the model's hyperparameters and potentially improving the features used for training.",
    "rubric_id": ""
  },
  {
    "id": "436d19098427c44c7e17fb6114bc161bf530a452ec21a8c8ecd484a6415070cb",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 191)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must follow the STAR method to describe a highly complex project. It should detail sophisticated technical challenges and the novel solutions that were implemented, emphasizing the significant and measurable impact of the work.",
    "rubric_id": ""
  },
  {
    "id": "77240657b906bb9812b668eef5bfd8ccf63cc7a82888aba4abf7463b65ad7f71",
    "text": "What is the role of activation functions in deep learning? (Sample 192)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity into a neural network. This is critical for allowing the network to learn complex patterns that a simple linear model cannot.",
    "rubric_id": ""
  },
  {
    "id": "c22c68e7eef9a84877e5aa71773e835965856c01523fdae0ccaf8e38651644db",
    "text": "What is the role of activation functions in deep learning? (Sample 193)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main purpose of activation functions is to introduce non-linearity, which enables neural networks to model complex relationships in data.",
    "rubric_id": ""
  },
  {
    "id": "618ddab2dcb1c56909a0172ba357f6178735cef9dcf95a93638e63bb78a1b4c2",
    "text": "What is the difference between bagging and boosting? (Sample 194)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed comparison. It must explain that bagging builds models in parallel on bootstrap samples to reduce variance, while boosting builds models sequentially, with each model focusing on the errors of the previous one to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "c986a87456a24313b6de3d0184d8e4c5d99548daa8887548049ef23f288b1698",
    "text": "How would you explain the concept of overfitting? (Sample 195)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as when a model learns the training data too well, including the noise, which leads to poor performance on new data.",
    "rubric_id": ""
  },
  {
    "id": "3ec748c47a2d21abfe566aee24bf68adb8c19bb3d286b49230c88a956871f436",
    "text": "What is principal component analysis (PCA)? (Sample 196)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define PCA as a technique to reduce the number of variables in a dataset. It should explain that it does this by creating a new set of variables (principal components) that capture the most important information.",
    "rubric_id": ""
  },
  {
    "id": "4123e656c2210538ab20451c6bb2342687852c2adbeee4a07d53a63f4060e18c",
    "text": "Can you explain the concept of gradient descent? (Sample 197)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm. It should describe the process of updating a model's parameters by taking steps in the opposite direction of the gradient of the loss function to find a minimum.",
    "rubric_id": ""
  },
  {
    "id": "92c844797b2e712b80c66cbb2a74b86723120ad3ccbc2a82573df4926941bb16",
    "text": "What are the advantages of ensemble methods? (Sample 198)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance by combining multiple models. It should mention that they achieve this by reducing variance (bagging) or bias (boosting), leading to more robust results.",
    "rubric_id": ""
  },
  {
    "id": "c2f9ca66b8c59e4ad4fbbaf96cbe1b6012bd4884b9e5aae27297d019ad037f97",
    "text": "How do you handle missing values in a dataset? (Sample 199)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive strategy. It should discuss the trade-offs of different imputation methods (mean, median, model-based) and when each is appropriate. It should also mention the importance of understanding the mechanism causing the data to be missing.",
    "rubric_id": ""
  },
  {
    "id": "594060af2460cee5603d39c3b12b0291c3ca8d6b10e05905d7436e7c4166ebbb",
    "text": "What is the role of activation functions in deep learning? (Sample 200)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity, which is essential for learning complex functions. It should also compare different activation functions (like ReLU and its variants, sigmoid, tanh) and discuss their impact on issues like the vanishing gradient problem.",
    "rubric_id": ""
  },
  {
    "id": "a9fed0a9966fad7cfa0bf6b1112352298312726cfffe0039c8a4bd009e202879",
    "text": "What is principal component analysis (PCA)? (Sample 201)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a deep technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix, which represent the principal components or directions of maximum variance. It should also explain the goal of projecting the data onto a lower-dimensional subspace spanned by these components.",
    "rubric_id": ""
  },
  {
    "id": "a8e92e68970d23975d68c00151b5c21b569a2c58de5e8490ea17efcfa0bdfe78",
    "text": "What is regularization and why is it important? (Sample 202)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It is important because it adds a penalty to the model for being too complex, which helps it generalize better.",
    "rubric_id": ""
  },
  {
    "id": "bb2f652c6dec0fc1a65966d39ffa3b9c24a8dece61cd95300de3f447ef161ff9",
    "text": "What is principal component analysis (PCA)? (Sample 203)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed technical explanation of PCA. It should state that it is a linear transformation that finds the eigenvectors of the covariance matrix of the data. These eigenvectors, or principal components, define a new coordinate system that captures the maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "f129c297c841ce770a4a5cd89e78a6ef538b6c59b374e0c1fc5ca7e780c2723e",
    "text": "What is your favorite machine learning algorithm and why? (Sample 204)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a deep technical justification. It should demonstrate a strong understanding of the algorithm's mechanics, its theoretical guarantees, and the specific types of problems where it outperforms other methods.",
    "rubric_id": ""
  },
  {
    "id": "587acd526c0c37b1ffcc0b31a71fdcfbc82363e65d45cecdc5621519af0a803c",
    "text": "What is your favorite machine learning algorithm and why? (Sample 205)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and give a clear technical reason for the choice. The justification should be based on a key characteristic, such as its performance, scalability, or interpretability.",
    "rubric_id": ""
  },
  {
    "id": "9117243d055bec6dc5d0192f66f711d1abfc448cee6d9b83a1428582fd63ca38",
    "text": "How does a neural network work? (Sample 206)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a neural network as being composed of layers of interconnected nodes. It must explain that data is processed through these layers to produce a prediction.",
    "rubric_id": ""
  },
  {
    "id": "9976593c3c40ee3b0b35edf97bf604601a238d2d6a7f2ac3980d6bc633a36cbe",
    "text": "What metrics would you use to evaluate a regression model? (Sample 207)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must list and critically compare several regression metrics. It should discuss the properties and business implications of using MAE, MSE, RMSE, and R-squared, explaining when one would be more appropriate than the others.",
    "rubric_id": ""
  },
  {
    "id": "5ed0512ee19553b3a70e7f49f7db12df101c11c1755869a6840bfcf922a5b688",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 208)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain the mathematical difference in their penalty terms (absolute vs. squared value of weights) and the practical result: L1's ability to create sparse models for feature selection, versus L2's tendency to shrink all weights.",
    "rubric_id": ""
  },
  {
    "id": "7df0ecd9791c14b52e2a3d27633eaf3989c425e07c1fa22e75afff3bd804140c",
    "text": "How does a neural network work? (Sample 209)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should explain the basic concept of a neural network as a model inspired by the brain, with layers of connected nodes that process information.",
    "rubric_id": ""
  },
  {
    "id": "2d2c536d792cd417964ca8391d43ce303085bb8343cf3335a4589e23eff5cb10",
    "text": "How do you handle missing values in a dataset? (Sample 210)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe multiple strategies for handling missing data. This should include simple methods like removal or mean/median imputation, and potentially more advanced methods like model-based imputation.",
    "rubric_id": ""
  },
  {
    "id": "a81d873adb571990ac4bf0df02ef21202f418f0b88d7a87a643faa1875316b58",
    "text": "How does a neural network work? (Sample 211)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the layered architecture of a neural network. It should explain the roles of neurons, weights, and activation functions in the forward propagation process, where an input is transformed into an output.",
    "rubric_id": ""
  },
  {
    "id": "ff1dff948e39dd95311b94efaa2d14a3530c0f372de97a7d2e0104f9d2945829",
    "text": "What is the role of activation functions in deep learning? (Sample 212)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity, which is crucial for learning complex functions. It should also compare different activation functions (e.g., ReLU, sigmoid) and discuss their impact on training, such as the vanishing gradient problem.",
    "rubric_id": ""
  },
  {
    "id": "e892027cb52e03db46d6edf4ba29e9866acf087567b07f3e2e07b8120ea90dfb",
    "text": "What is the role of activation functions in deep learning? (Sample 213)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that activation functions introduce non-linearity into a neural network, which is essential for the model to learn complex patterns in data.",
    "rubric_id": ""
  },
  {
    "id": "5d0dcece0083b198ff6d6a7e83077c287ee706a6cd5775959b7da75d02e42393",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 214)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with significant technical complexity. It should detail the sophisticated methods used to overcome challenges in data, modeling, or deployment, and clearly state the measurable business impact.",
    "rubric_id": ""
  },
  {
    "id": "89d59f2e9cc5b300b3e70a5b4f09ff2fda766768825023445fe8e776e375223c",
    "text": "Describe the process of feature selection. (Sample 215)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing a subset of the most relevant features from a dataset to use for training a model.",
    "rubric_id": ""
  },
  {
    "id": "7311b319527296d0bd81d1fdcdc3a34abb38cd0bffeab48fd0a70d7b4644deda",
    "text": "Can you explain the concept of gradient descent? (Sample 216)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm for minimizing a function. It should describe the process of calculating the gradient and taking steps in the opposite direction, and mention the difference between batch and stochastic variants.",
    "rubric_id": ""
  },
  {
    "id": "38595d8449505d3393021c0a3db681c199d96c07e6ee21709a0736e28e6bb28c",
    "text": "How do you handle missing values in a dataset? (Sample 217)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive strategy for handling missing data. It should discuss the importance of understanding the missingness mechanism (MCAR, MAR, MNAR) and compare the trade-offs of various techniques, from simple imputation to more advanced model-based methods.",
    "rubric_id": ""
  },
  {
    "id": "dd6559ff7e7ade345b6c70f6e08d2ae0109f400b6af0a268930bf6d4c3d155a4",
    "text": "How do you handle missing values in a dataset? (Sample 218)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a sophisticated approach. It should cover diagnosing the type of missingness and then discuss advanced imputation techniques like MICE (Multiple Imputation by Chained Equations) or using models that can inherently handle missing values.",
    "rubric_id": ""
  },
  {
    "id": "deebed13b4f3efab24224598739b51bf2e44f8262140ce4c662053df16c23fd1",
    "text": "What is regularization and why is it important? (Sample 219)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization as a method to combat overfitting. It should explain the mathematical intuition of adding a penalty term to the loss function and differentiate the effects of L1 (sparsity) and L2 (weight shrinkage) penalties.",
    "rubric_id": ""
  },
  {
    "id": "05b0d05e0351ccd741f12121e44b44fe91373cfae6bdba1731ff16687cca290c",
    "text": "What is regularization and why is it important? (Sample 220)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It is important because it helps a model generalize better by penalizing complexity.",
    "rubric_id": ""
  },
  {
    "id": "6b3c7c812ccccf08258aed4e98ce8cf82cb09e2943e9383e6021d50cddf612a3",
    "text": "What is regularization and why is it important? (Sample 221)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain that regularization is used to prevent overfitting and that it is important because it improves the model's performance on new, unseen data.",
    "rubric_id": ""
  },
  {
    "id": "77c24e152aed28566a7a19b2497eac069c7946453be79538ac7bab01571c115b",
    "text": "How do you handle missing values in a dataset? (Sample 222)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe several methods for handling missing data. This should include removing the data, imputing with statistical measures (mean, median), and potentially more advanced techniques like K-Nearest Neighbors imputation.",
    "rubric_id": ""
  },
  {
    "id": "1e558fa047e291d1d9026df1ef7752bae31940fe734bca28d571396cb1bfc274",
    "text": "What is regularization and why is it important? (Sample 223)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting by adding a penalty term to the loss function that discourages model complexity. This is crucial for improving generalization.",
    "rubric_id": ""
  },
  {
    "id": "75c34bb20af64f75afdefaa096f63764e7793494a69ea6d74abe2c78198e54d6",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 224)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method (Situation, Task, Action, Result) to describe a project with a clear technical challenge. It should detail the specific problem, the modeling approach taken, and the final, measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "9fd47a3fb2c5f3cbbfca1b49fa3b08459502c7c4ddb406f1ce0ff5b1623862be",
    "text": "Describe the process of feature selection. (Sample 225)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe feature selection as the process of choosing a subset of the most relevant features. It should mention different categories of methods, such as filter, wrapper, and embedded techniques.",
    "rubric_id": ""
  },
  {
    "id": "81d94edda03f5c6cfe63b94407cba2d58676662afed8de92802b10edaec08b11",
    "text": "What are the advantages of ensemble methods? (Sample 226)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance and robustness. It should mention that they achieve this by combining multiple models, which can reduce bias, variance, or both.",
    "rubric_id": ""
  },
  {
    "id": "23d7bbbe02fb5f7128cdb981eaea6bdf9c7f10451c659bdd0593b836a13f3c07",
    "text": "Describe the process of feature selection. (Sample 227)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define feature selection as the process of selecting a subset of relevant features. It should describe at least one category of methods, such as wrapper methods (e.g., recursive feature elimination) or embedded methods (e.g., Lasso).",
    "rubric_id": ""
  },
  {
    "id": "482dfe970a50316caa9825ef0aca06efd44b1a0938d630058c78d099521ca21f",
    "text": "What is principal component analysis (PCA)? (Sample 228)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix, which represent the orthogonal directions of maximum variance. It should also explain how data is projected onto these components for dimensionality reduction.",
    "rubric_id": ""
  },
  {
    "id": "2ac52b1fcdc7f1219c00ac73685788f36a4bfc24ea7698fe525317a7692df0d1",
    "text": "How would you optimize a machine learning model? (Sample 229)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a structured approach to model optimization. This must include systematic hyperparameter tuning, iterative feature engineering, and analyzing model errors to guide improvements.",
    "rubric_id": ""
  },
  {
    "id": "d125e677763b70219618b5e1caedc4345cd12820e08ea1c82de04eac0fa36d9a",
    "text": "What is the difference between bagging and boosting? (Sample 230)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: bagging trains models in parallel on random data samples, while boosting trains models sequentially, with each one learning from the previous one's mistakes.",
    "rubric_id": ""
  },
  {
    "id": "868db1fd4a5d468dcaaaa46cd98c808f953543b008e844e51c6e1a9f5fd0c09a",
    "text": "How would you optimize a machine learning model? (Sample 231)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive optimization strategy. It should include advanced hyperparameter tuning (e.g., Bayesian optimization), sophisticated feature engineering, error analysis, and potentially exploring different model architectures or custom loss functions.",
    "rubric_id": ""
  },
  {
    "id": "138023fe4f902cf639b86641d8b390ce301b3fe1bc4a249d34d6f48a8a05b712",
    "text": "What is the bias-variance tradeoff? (Sample 232)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting). It must explain their inverse relationship and the goal of finding a model complexity that provides a good balance between the two to minimize overall error.",
    "rubric_id": ""
  },
  {
    "id": "16f298bd313ab243eaa7a239704614e7235bd1f60c1a9ecc670c50fd009cac98",
    "text": "What is your favorite machine learning algorithm and why? (Sample 233)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear technical justification for the choice, based on its performance characteristics, interpretability, or suitability for a particular type of data.",
    "rubric_id": ""
  },
  {
    "id": "1cc0a96d3049bc9b820d22da181e4e7ee8fcd96907c30817dfd758273c6e85fa",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 234)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with significant technical depth and complexity. It should detail the sophisticated approaches used to overcome major obstacles and present the final, impressive, and measurable results.",
    "rubric_id": ""
  },
  {
    "id": "7c75739afac033d099593b81cf56d6c632d7400b43b802859d56e4acd43b80b3",
    "text": "What is the role of activation functions in deep learning? (Sample 235)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that activation functions introduce non-linearity, which is critical for learning complex functions. It should also compare different activation functions (like ReLU and its variants versus sigmoid/tanh) and discuss their pros and cons, especially regarding the vanishing gradient problem.",
    "rubric_id": ""
  },
  {
    "id": "7b20a54df4b612243d3ce242648ceb9f8acf2285b22fd12f109ff55821687621",
    "text": "What are the advantages of ensemble methods? (Sample 236)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance by combining multiple models. It should mention that they can reduce variance (e.g., bagging) or bias (e.g., boosting), leading to more robust and accurate results.",
    "rubric_id": ""
  },
  {
    "id": "759c1e81a3ac9487b130a34b4f733fe819b35cbd8a06c06381aa224942690f8c",
    "text": "What are the advantages of ensemble methods? (Sample 237)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of why ensembles are powerful. It should cover how they reduce variance through averaging (bagging) and reduce bias by focusing on errors (boosting), linking these concepts to the bias-variance tradeoff and improved generalization.",
    "rubric_id": ""
  },
  {
    "id": "217aa003925c799d8055c2af6a3795869be6f067a9235174a8627a9f5ffffae1",
    "text": "How would you optimize a machine learning model? (Sample 238)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a structured optimization process. This must include hyperparameter tuning (e.g., using grid search), feature engineering, and potentially experimenting with different algorithms or regularization techniques.",
    "rubric_id": ""
  },
  {
    "id": "d806fec7fdec6104dae17a1945148df9e97acbabcb2c5d377057e2239e6f26ee",
    "text": "What metrics would you use to evaluate a regression model? (Sample 239)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list common metrics for evaluating regression models. Check for mentions of Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and Mean Absolute Error (MAE).",
    "rubric_id": ""
  },
  {
    "id": "c531ce7a3588fdd542af095f370e09662481ec6e77fefb5563e1d1ef793dba67",
    "text": "What are the key differences between classification and regression? (Sample 240)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clearly differentiate based on the output type. Classification predicts a discrete category. Regression predicts a continuous value. It should also note that they use different performance metrics.",
    "rubric_id": ""
  },
  {
    "id": "91dbbaa5951aec0a4c92cd8246e046056c8e68c6d09100f1136a019111640c86",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 241)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast the penalty terms and their effects. L1 (Lasso) uses an absolute value penalty, which can drive weights to zero and perform feature selection. L2 (Ridge) uses a squared penalty, which shrinks weights but does not set them to zero.",
    "rubric_id": ""
  },
  {
    "id": "595097da84ad5eb9f8095cf7e70da05bd3a1e42fa97366026cf39e46302cd25b",
    "text": "Describe the process of backpropagation. (Sample 242)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of backpropagation. It must describe the forward pass to compute the error and the backward pass that uses the chain rule to recursively compute the gradient of the error with respect to each weight in the network, which are then used for updates.",
    "rubric_id": ""
  },
  {
    "id": "8a3365483d205766f51824ae948df546eaaae0b2efd65544dedfd7cb7f7d5948",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 243)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must follow the STAR method to describe a project with substantial technical depth. It should detail the complex problem, the sophisticated modeling techniques used, the significant challenges overcome, and the impressive, measurable impact of the final solution.",
    "rubric_id": ""
  },
  {
    "id": "0a0b93b0a3bd7437c45a34f1b8767c8c97e98145a54b06abecfdd220a27f5298",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 244)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must use the STAR method to detail a complex project. It should focus on a particularly difficult technical challenge (e.g., highly imbalanced data, real-time constraints) and explain the advanced methods used to solve it, concluding with the quantifiable business outcome.",
    "rubric_id": ""
  },
  {
    "id": "6c7dce2bb6f7bb36bec92a72afa046e105dd195cc14e9dabf0289caf93ba58b0",
    "text": "How would you optimize a machine learning model? (Sample 245)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a systematic process for model improvement. This must include tuning hyperparameters, iterating on feature engineering, and analyzing model errors to guide further optimization efforts.",
    "rubric_id": ""
  },
  {
    "id": "6cd2e283e054d09994f5da445ef4ab6cada3a2c2e958713db0e89f7421565ef6",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 246)",
    "domain": "behavioral-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must follow the STAR method (Situation, Task, Action, Result). It should clearly describe a project, the objective, the specific actions and ML techniques used, and the final outcome.",
    "rubric_id": ""
  },
  {
    "id": "49816332ab6726a0e2bed51e2d9625221780d35e054db127d83cc8fe0561354a",
    "text": "What are the key differences between classification and regression? (Sample 247)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough distinction. It must cover the difference in output type (discrete vs. continuous), the types of algorithms used for each, and the different evaluation metrics appropriate for each task (e.g., accuracy/F1 vs. RMSE/R2).",
    "rubric_id": ""
  },
  {
    "id": "0f27b706411e8a85537b53a3903fe93d0b556bbe993bf068701de21828a662aa",
    "text": "Can you explain the concept of gradient descent? (Sample 248)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of gradient descent and its variants. It should cover the core mathematical concept of using the gradient to find a minimum and clearly differentiate between batch, stochastic, and mini-batch gradient descent, explaining their respective trade-offs in terms of convergence speed and stability.",
    "rubric_id": ""
  },
  {
    "id": "dbefac172cd7bbef40dfff446a189f601d27d0fa5ed721a192494050eeb241d0",
    "text": "Describe the process of feature selection. (Sample 249)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing the most important features for a model. It should mention that the goal is to improve performance and create a simpler model.",
    "rubric_id": ""
  },
  {
    "id": "88a6bef975dc2dc91e6fcb1b1135fc21e3f34172ed4bae19d993560195014dc5",
    "text": "What is principal component analysis (PCA)? (Sample 250)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a deep technical explanation of PCA. It must describe it as finding the eigenvectors of the covariance matrix of the data, which form an orthogonal basis of principal components. It should explain that this process allows for dimensionality reduction by projecting data onto the components that capture the most variance.",
    "rubric_id": ""
  },
  {
    "id": "f42a0dcc69d7faaad0663c66b18cf1bb1edca2fc12b15fdaca734d5d52458d37",
    "text": "What is the role of activation functions in deep learning? (Sample 251)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the key role of activation functions is to introduce non-linearity into a neural network, which is necessary for the model to learn complex patterns.",
    "rubric_id": ""
  },
  {
    "id": "6672526d9c0dc8e52e1c91079384013087b6fa947ecf57cccfbb9409dfeafefa",
    "text": "How does a neural network work? (Sample 252)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the layered architecture of a neural network. It should explain that neurons compute a weighted sum of inputs and then apply a non-linear activation function, and that this process is repeated through the layers to generate a prediction.",
    "rubric_id": ""
  },
  {
    "id": "76be5a03de9424b307188a37847d459be102e28b5ca4607068424abf12e942ec",
    "text": "What is the bias-variance tradeoff? (Sample 253)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting). It must explain their inverse relationship and the goal of finding a model that balances them to achieve the lowest total error on unseen data.",
    "rubric_id": ""
  },
  {
    "id": "8248b5f99f5764ea5c3339b670428cbfbf3256ce5360c95f58d51fa70d6d2f50",
    "text": "What are the advantages of ensemble methods? (Sample 254)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the primary advantage of ensemble methods is that combining multiple models typically leads to better predictive performance and a more robust solution than any single model.",
    "rubric_id": ""
  },
  {
    "id": "42cf87edadeaeda044941305c274dcea91c7240715ba3e847f66199127f0fa97",
    "text": "Explain cross-validation and its purpose. (Sample 255)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as getting a more stable and reliable estimate of a model's performance on unseen data. It should describe the k-fold process of splitting, training, and testing.",
    "rubric_id": ""
  },
  {
    "id": "95add781153e1d64888b7da19f76d89d0023cde7e3daa4e3fd3c3d4b66b3a239",
    "text": "What metrics would you use to evaluate a regression model? (Sample 256)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must list and critically compare multiple regression metrics. It should discuss the properties of MAE, MSE, RMSE, and R-squared, and explain how the choice of metric depends on the business context and sensitivity to errors.",
    "rubric_id": ""
  },
  {
    "id": "1600e6083f586c003de069c2f10c72dbf7186b89496ae262e14839efe1217306",
    "text": "What is the bias-variance tradeoff? (Sample 257)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of bias (underfitting) and variance (overfitting). It must explain their inverse relationship as model complexity changes and the goal of finding an optimal balance to minimize the total prediction error.",
    "rubric_id": ""
  },
  {
    "id": "0fef18f296fc806c5d2c5f09b22ea5b48553fd06ae1f97116c5e7dd9493c7fea",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 258)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with a clear technical challenge. It should detail the situation, the task, the specific actions and ML techniques used, and the measurable results.",
    "rubric_id": ""
  },
  {
    "id": "284d18aedf60155bc36f9c53be862c437d74abcb4e43396500b39b0efe9cc76d",
    "text": "How does a neural network work? (Sample 259)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a neural network as a model made of layers of connected nodes. It must explain that information flows through these layers to make a prediction.",
    "rubric_id": ""
  },
  {
    "id": "41af47cac4d465a0ec3a6554bfc5f1192edf7770af4392cf964f34e3eae4a15b",
    "text": "Describe the process of feature selection. (Sample 260)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe feature selection as the process of choosing a subset of the most relevant features. It should mention different categories of methods, like filter, wrapper, and embedded techniques.",
    "rubric_id": ""
  },
  {
    "id": "5dca3a9fb727677e377c3fa30e57ec3db1a7647cdb9af22217a6581c96e45a06",
    "text": "How would you approach data cleaning for a large dataset? (Sample 261)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must outline a scalable and robust data cleaning strategy. It should cover data profiling, advanced imputation techniques, outlier detection, and ensuring data consistency, while also considering the use of distributed computing frameworks like Spark for large-scale data.",
    "rubric_id": ""
  },
  {
    "id": "cc68654ad791b9e7681cb16b3fc6c8fbac9d98fa5e475edca26a77b3493f3e60",
    "text": "Describe the process of feature selection. (Sample 262)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of selecting a subset of relevant input features for a model. It should mention the goals of improving accuracy and reducing complexity.",
    "rubric_id": ""
  },
  {
    "id": "3d0a409e01554afb228e84f144f58c8ec23071797523f33d6911b51a98a720b8",
    "text": "How would you approach data cleaning for a large dataset? (Sample 263)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe a systematic approach. This includes profiling the data, handling missing values and outliers, and writing reproducible scripts. It should also mention considering scalable tools if the data exceeds single-machine memory.",
    "rubric_id": ""
  },
  {
    "id": "07b7a836e7b7b8dfbee9d987b44ee2786d383bdcecd9887340157fca7f1daa17",
    "text": "What is the difference between bagging and boosting? (Sample 264)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: Bagging involves training models independently on different data samples in parallel. Boosting involves training models sequentially, where each model learns from the previous one's errors.",
    "rubric_id": ""
  },
  {
    "id": "0b6d4dd51f3990b1f149e2925ec4efc240a28bce358ef2710f00c46d72246229",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 265)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast the penalty terms and their effects. L1 (Lasso) uses an absolute value penalty, which can perform feature selection by shrinking some weights to zero. L2 (Ridge) uses a squared penalty, which encourages smaller weights but doesn't force them to zero.",
    "rubric_id": ""
  },
  {
    "id": "bcc57ae7895e297f96007ad3b95c7f337ae6b6c10dfff8774633c193159e6388",
    "text": "How would you optimize a machine learning model? (Sample 266)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a structured approach to model optimization. This must include hyperparameter tuning, iterative feature engineering, and analyzing model errors to guide further improvements.",
    "rubric_id": ""
  },
  {
    "id": "3cb18d3a67141e20c84855e8a81356fb50a3858bb53b57b0dc8bad99cac497d4",
    "text": "What metrics would you use to evaluate a regression model? (Sample 267)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must list common metrics for regression. Check for mentions of Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE).",
    "rubric_id": ""
  },
  {
    "id": "43759c6a6b77705473bcf3f08dc2f2e2cff6a269e9b4ce647fdb6bb72c886622",
    "text": "What is the bias-variance tradeoff? (Sample 268)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting). It must explain their inverse relationship and the goal of finding a model complexity that balances them to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "cad6326f43cf91443cc0afce769f2876405b1a7836869e9dcefc31d8e0d07316",
    "text": "What is your favorite machine learning algorithm and why? (Sample 269)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific, advanced algorithm and provide a deep technical justification for the choice. It should demonstrate a strong understanding of its inner workings, its theoretical advantages, and its practical application in complex scenarios.",
    "rubric_id": ""
  },
  {
    "id": "0b494da1e47686438102a7f8e624b1fd4c81b9d83d8b555fccbb9b7a3286fadf",
    "text": "What is the difference between bagging and boosting? (Sample 270)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain that bagging builds models in parallel on bootstrap samples to reduce variance, while boosting builds models sequentially, with each model focusing on the errors of the previous one to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "850fd03fa08fd79ba1d63bce82e178ea8b1c7b94dd16ac7078780f8bb489c349",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 271)",
    "domain": "behavioral-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with significant technical complexity and challenge. It should detail sophisticated problem-solving, advanced modeling techniques, and the substantial, measurable impact of the work.",
    "rubric_id": ""
  },
  {
    "id": "2d11be9285c2d84b8517cfbba6d0833995d32a7acee279de5306f78ac9fcf135",
    "text": "What is your favorite machine learning algorithm and why? (Sample 272)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear, concise justification for the preference, relating to a practical aspect like its performance or ease of use.",
    "rubric_id": ""
  },
  {
    "id": "8c38caf40eed8b59a15c99775d1d26ac056f5a46e1739f293283d7fd9c2887d4",
    "text": "Explain cross-validation and its purpose. (Sample 273)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as being a method to get a more reliable estimate of a model's performance on new data than a single train-test split.",
    "rubric_id": ""
  },
  {
    "id": "03dfaf1fb0697b796a9f2ce468f4481cd5947b656e43200faaaf259c157bc7e8",
    "text": "What is the role of activation functions in deep learning? (Sample 274)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must explain that activation functions are crucial for introducing non-linearity, allowing networks to learn complex functions. It should also compare different activation functions (e.g., ReLU vs. sigmoid) and discuss their impact on training dynamics, such as the vanishing gradient problem.",
    "rubric_id": ""
  },
  {
    "id": "dbd2d1d43732df81b5b57ed7bb7205c378c1021362860056f13b2d47522ec702",
    "text": "What is your favorite machine learning algorithm and why? (Sample 275)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear technical justification. The reasoning should be based on its performance characteristics, interpretability, or suitability for a specific type of problem.",
    "rubric_id": ""
  },
  {
    "id": "81a09d613b14f2a8ea652c7853dc9d6f8c5099438eab4547ece6a952169dadff",
    "text": "Explain cross-validation and its purpose. (Sample 276)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as getting a more stable estimate of model performance on unseen data. It should describe the k-fold process of splitting the data into 'k' partitions and iteratively training and validating on them.",
    "rubric_id": ""
  },
  {
    "id": "09a3f89fb882ef31b2aaa601cb2e54593e4d2a3447ddac6d0bed461fe3e2a015",
    "text": "How does a neural network work? (Sample 277)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive explanation. It should cover the architecture of layered neurons, the forward pass of data through weighted connections and activation functions, the calculation of a loss, and the backpropagation algorithm for updating weights.",
    "rubric_id": ""
  },
  {
    "id": "48bb505cff865999476389330141a6fe364c3a47d5833869d965b7f9cf49d38d",
    "text": "What are the key differences between classification and regression? (Sample 278)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must clearly differentiate based on the output variable. Classification predicts a discrete category. Regression predicts a continuous value. It should also mention that they use different algorithms and evaluation metrics.",
    "rubric_id": ""
  },
  {
    "id": "ad84f52462a6e144bb932bcc85596a3a9afeb345421120b23bb8f1cec3faad6c",
    "text": "What are the key differences between classification and regression? (Sample 279)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must differentiate based on the target variable's nature. Classification predicts a discrete class label. Regression predicts a continuous numerical value. This distinction dictates the choice of models and evaluation metrics.",
    "rubric_id": ""
  },
  {
    "id": "249f5726da3a316694eb0ff5ba246fee2d33ec015ad048bbbd25dfed69ad95c6",
    "text": "What is regularization and why is it important? (Sample 280)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It should explain that it works by adding a penalty for model complexity to the loss function, which helps the model generalize better to new data.",
    "rubric_id": ""
  },
  {
    "id": "fb3136fdaf3548ad202f33adab31ccc17af729eeb2d6d34433efc5690cbe7f8f",
    "text": "Describe the process of backpropagation. (Sample 281)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe backpropagation as the core training algorithm for neural networks. It should explain the two main phases: a forward pass to compute the error, and a backward pass that uses the chain rule to compute and propagate gradients back through the network to update the weights.",
    "rubric_id": ""
  },
  {
    "id": "10998c6936d684ef0d0c03e134967cc672349a6b2302c75456344451502f7f89",
    "text": "What are the key differences between classification and regression? (Sample 282)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the fundamental difference based on the prediction target: classification outputs a category, while regression outputs a numerical value.",
    "rubric_id": ""
  },
  {
    "id": "1a0f26189035e5ef3036738a06973f74bf93801ee2d37ce103b81c08d4c419cc",
    "text": "What is the bias-variance tradeoff? (Sample 283)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (error from a model being too simple) and variance (error from a model being too complex). It must explain their inverse relationship and the goal of finding a balance to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "69cf15a4ecb502359204b9252e0e5815a2eb3c3c21055ece7b6b73f919195d45",
    "text": "What are the key differences between classification and regression? (Sample 284)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference: classification predicts a discrete label (e.g., 'yes' or 'no'), while regression predicts a continuous quantity (e.g., price).",
    "rubric_id": ""
  },
  {
    "id": "daaa489b50ec93147738896c9209a583bf9eb5bac8a1143449450bd55d88c678",
    "text": "What are the key differences between classification and regression? (Sample 285)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough distinction. It must cover the difference in output type (discrete vs. continuous), the types of algorithms suitable for each, and the different evaluation metrics used for each task (e.g., accuracy vs. RMSE).",
    "rubric_id": ""
  },
  {
    "id": "d178e4b8b234468c696b31c81d1be6ac7509f184d96f0abdcf56d6104979a697",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 286)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must follow the STAR method (Situation, Task, Action, Result) to describe a project with a clear technical challenge. It should detail the problem, the solution implemented, and the final, measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "4739c40e19fc2468083a334d2d4b5f735251fe6b389a9fa7bbc11f2cf1e75642",
    "text": "What are the key differences between classification and regression? (Sample 287)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the primary difference based on the output: classification predicts a category, and regression predicts a numerical value.",
    "rubric_id": ""
  },
  {
    "id": "a38359fd9522b88bfcf4400f5305e95e69da0fb199c20cc2f20806e8b322b11d",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 288)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain the mathematical difference in their penalty terms (sum of absolute vs. sum of squared weights) and the practical result: L1's ability to create sparse models and perform feature selection, versus L2's tendency to shrink all weights without setting them to zero.",
    "rubric_id": ""
  },
  {
    "id": "c7aaadce3c7f38dc18eb51cb2bf9e3e8a1ca1d9dc7c9decfb126c1c91b41de7b",
    "text": "How would you optimize a machine learning model? (Sample 289)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a basic model optimization process. This must include tuning the model's hyperparameters and possibly improving the features used for training.",
    "rubric_id": ""
  },
  {
    "id": "d62250369bf1348ef4766319e349f4ff3c0c80b4f08265df6c7a629d142abd4e",
    "text": "What are the advantages of ensemble methods? (Sample 290)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main advantage is improved predictive performance. It should explain that combining multiple models leads to a more robust and accurate result.",
    "rubric_id": ""
  },
  {
    "id": "3594b290c936c132ecc5be6ff92c7f31393522ec7adbc2a16b1a18feb09b02a8",
    "text": "Can you explain the concept of gradient descent? (Sample 291)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm for minimizing a loss function. It should describe the process of calculating the gradient and updating parameters in the opposite direction to find a minimum.",
    "rubric_id": ""
  },
  {
    "id": "2347b59c62b2e7d202aee08fd2444e4a83be8748dc15ba993bacc86bba773fec",
    "text": "What is regularization and why is it important? (Sample 292)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization. It must explain its purpose (preventing overfitting), the mathematical intuition of adding a penalty term, and the different behaviors of L1 (sparsity) and L2 (weight shrinkage) penalties.",
    "rubric_id": ""
  },
  {
    "id": "b69fa76efa0579875ab07fc465aefabf047f48741ee7b19d7f0f5e48deb5fa33",
    "text": "Explain cross-validation and its purpose. (Sample 293)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough explanation. It should describe the k-fold procedure and explain that its purpose is to provide a more stable and less biased estimate of a model's generalization performance compared to a single train-test split.",
    "rubric_id": ""
  },
  {
    "id": "02b864eaa926763b3227d9cbaef3a89e7067ed90ef5af9ceb93c5d07fadd27b6",
    "text": "How does a neural network work? (Sample 294)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a neural network as a model composed of layers of connected nodes (neurons). It must explain that data is processed through these layers to generate a prediction.",
    "rubric_id": ""
  },
  {
    "id": "4d903076fde8cf25a6cca0ab56095fc583578253c0112702608ceeeef8763fe3",
    "text": "How does a neural network work? (Sample 295)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the layered architecture of a neural network. It should explain the role of neurons, weights, biases, and activation functions in processing information from the input layer to the output layer.",
    "rubric_id": ""
  },
  {
    "id": "efed1716a0ccb18a79d335bc99e870ef4e2f64e768a7ecebe82e467c5043ef34",
    "text": "Describe the process of backpropagation. (Sample 296)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of backpropagation. It must describe the forward pass to compute error and the backward pass that uses the chain rule to recursively compute the gradient of the error with respect to each weight, which is then used for weight updates.",
    "rubric_id": ""
  },
  {
    "id": "d577cab09ad7bbb1b17ec76f8f931170270455af0f8628dc9c6d9ea7b14615ee",
    "text": "How would you optimize a machine learning model? (Sample 297)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a structured approach to model optimization. This must include hyperparameter tuning, iterative feature engineering, and analyzing model errors to guide further improvements.",
    "rubric_id": ""
  },
  {
    "id": "ce20e05a22d5aa2bb1867beaebfc646c0e5f5ebe89f686aba6b73025e9c32a51",
    "text": "What is the difference between bagging and boosting? (Sample 298)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain that bagging builds models in parallel on bootstrap samples to reduce variance, while boosting builds models sequentially, with each model focusing on the errors of the previous one to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "8cd86a50a3c4d572d5f1341bf3447329ba7c51176376398f20cd4006485dfc7f",
    "text": "What is your favorite machine learning algorithm and why? (Sample 299)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear technical justification for the choice. The reasoning should be based on its performance, interpretability, or suitability for a particular data type.",
    "rubric_id": ""
  },
  {
    "id": "da0df2e8ec563cddaaadb79203025ec22281442fd71f93dac15e20a8f2050cc0",
    "text": "Describe the process of feature selection. (Sample 300)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive feature selection strategy. It should differentiate between filter, wrapper, and embedded methods, explaining their pros and cons and providing examples of when each is appropriate.",
    "rubric_id": ""
  },
  {
    "id": "efbbe3178baa6a8bcf01ea9aca237877b1f3318258b52c84a96c839b3f365274",
    "text": "What metrics would you use to evaluate a regression model? (Sample 301)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list and explain several regression metrics. It must include MAE, MSE/RMSE, and R-squared, and briefly explain what each metric measures and its sensitivity to errors.",
    "rubric_id": ""
  },
  {
    "id": "b69adf23c7894725aea7b132a413320d2223600f55fe796f5d48eb87440dd12a",
    "text": "What is principal component analysis (PCA)? (Sample 302)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a deep technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix. These eigenvectors, the principal components, form an orthogonal basis that captures the directions of maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "dc43d38311ca0a012e67d1c16811dd1b96536a9d57fdfa5ae51c7d2ff35a8eec",
    "text": "How would you approach data cleaning for a large dataset? (Sample 303)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must outline a basic data cleaning workflow. Key tasks to mention are handling missing values (e.g., by removal or imputation), removing duplicates, and correcting data inconsistencies.",
    "rubric_id": ""
  },
  {
    "id": "6c1d1d9a9950cd6f6adb364d9f1155d980ba484845945b0deb9e1420611edc73",
    "text": "What is the bias-variance tradeoff? (Sample 304)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting). It must explain their inverse relationship and the goal of finding a model that balances them to achieve the best performance on new data.",
    "rubric_id": ""
  },
  {
    "id": "0f7f114fc0bb38b05bff158db15abfaf9e321c58cf926bc930bde26922c0a520",
    "text": "Describe the process of feature selection. (Sample 305)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing a subset of relevant features from a dataset. It should mention that the goal is to improve model performance and simplicity.",
    "rubric_id": ""
  },
  {
    "id": "bc4bb31a6f01e808593fe12470dcf6bfa6ce3d0d2544ace8655e78d435fa3292",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 306)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with a clear technical challenge. It should detail the situation, the specific ML task, the actions taken to overcome the challenge, and the final, measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "ac0a1c760ab4fd41e2c791b0f6c69c64d5b81150ddf2f4107fc5df6509029eb9",
    "text": "What is your favorite machine learning algorithm and why? (Sample 307)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific, advanced algorithm and provide a deep technical justification. It should demonstrate a strong understanding of the algorithm's mechanics, its theoretical underpinnings, and its practical applications.",
    "rubric_id": ""
  },
  {
    "id": "c6a7a0cfc0f6a3cbaf27501df2267b0c0951e634faaf67cae8e7fb18dec6e2fc",
    "text": "What is the bias-variance tradeoff? (Sample 308)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (error from a model being too simple) and variance (error from a model being too complex). It must explain their inverse relationship and the goal of finding a balance to minimize total error.",
    "rubric_id": ""
  },
  {
    "id": "3677ae20a4610ee290c8a91b49a67673800061d8e52a8144ee3ad1cff38555e1",
    "text": "What metrics would you use to evaluate a regression model? (Sample 309)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must list and differentiate common regression metrics. It should include MAE, MSE/RMSE, and R-squared, and explain what each one measures and how they differ in their sensitivity to errors.",
    "rubric_id": ""
  },
  {
    "id": "98e1a8e59bee2542e62c6317846a745c387c3b63ea7f2eee5f5e5e3d2a6a1263",
    "text": "What are the key differences between classification and regression? (Sample 310)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference based on the output: classification predicts a discrete class, while regression predicts a continuous numerical value.",
    "rubric_id": ""
  },
  {
    "id": "9bef4da8eaef38f5bdfcd49c8b62121d71792204332f7fb0668394ff14edc906",
    "text": "How would you optimize a machine learning model? (Sample 311)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive optimization strategy. This should include advanced hyperparameter tuning (e.g., Bayesian optimization), iterative feature engineering guided by error analysis, and potentially exploring novel model architectures or ensemble techniques.",
    "rubric_id": ""
  },
  {
    "id": "ab1fb910ec1a0a43d04351a7af3ee6fbbf752a97cdad14cdc5abdd0a56ee95bb",
    "text": "Explain cross-validation and its purpose. (Sample 312)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough explanation of cross-validation. It should describe the k-fold procedure and explain that its purpose is to provide a more stable and less biased estimate of a model's generalization performance by averaging results over multiple train-test splits.",
    "rubric_id": ""
  },
  {
    "id": "a5aab2916a3f4b99a9da48b05ef243e5e24c115548e7e8dcc9b87deb7df43bf7",
    "text": "What is the bias-variance tradeoff? (Sample 313)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define bias (underfitting) and variance (overfitting). It must explain their inverse relationship as model complexity changes and the goal of finding a balance.",
    "rubric_id": ""
  },
  {
    "id": "121131ca38ff2dec71214bb9aa76d471b8db53894ca2687db5dcd74652100444",
    "text": "How does a neural network work? (Sample 314)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive explanation. It should cover the layered architecture, the role of weights and biases, forward propagation through activation functions, and the backpropagation algorithm for updating weights to minimize a loss function.",
    "rubric_id": ""
  },
  {
    "id": "6234e004b41532c8512c511af439614ee8acc80a46b961f81d6e75a9ad331561",
    "text": "How would you explain the concept of overfitting? (Sample 315)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as when a model learns the training data too well, including the noise, which leads to poor performance on new, unseen data.",
    "rubric_id": ""
  },
  {
    "id": "c491c1c0eeadf3d0031a6f1a490aa7433b18c0c449bc122e8ca3a2f1611c9bec",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 316)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison. It must explain the mathematical difference in their penalty terms (absolute vs. squared weights) and the practical consequence: L1's ability to create sparse models and perform feature selection, versus L2's tendency to shrink all weights.",
    "rubric_id": ""
  },
  {
    "id": "f654b7eb247aaf46922064a98270838af21b57a6a1c85ac80fc02f9967b94f8a",
    "text": "Explain cross-validation and its purpose. (Sample 317)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a thorough explanation of cross-validation. It should describe the k-fold procedure and explain that its purpose is to provide a more stable and reliable estimate of model performance on unseen data by averaging over multiple splits.",
    "rubric_id": ""
  },
  {
    "id": "38cfd03d89577da4aff182575e1a96f9894ba16d4a0611c7f055cdd08690b069",
    "text": "Describe the process of backpropagation. (Sample 318)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the algorithm used to train neural networks. It should describe the core idea of calculating the error at the output and propagating it backward to update the network's weights.",
    "rubric_id": ""
  },
  {
    "id": "18334c9f692159df5d85b90565a05b61ce6df9952166deef97b0a67545f51e41",
    "text": "What are the advantages of ensemble methods? (Sample 319)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main benefit of ensemble methods is that combining multiple models usually results in better predictive performance and a more robust model.",
    "rubric_id": ""
  },
  {
    "id": "2da14df25d1b334f272a54f68be51851dedef94e45502393a3fe31200ac26ccb",
    "text": "What metrics would you use to evaluate a regression model? (Sample 320)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list and differentiate common regression metrics. It must include MAE, MSE/RMSE, and R-squared, and explain what each one measures and its sensitivity to errors.",
    "rubric_id": ""
  },
  {
    "id": "1f6c6fa1577ecd27ee2396b784e115d98d0df62a3f57fe1f43f100302137eeb4",
    "text": "Describe the process of feature selection. (Sample 321)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define feature selection as the process of choosing a subset of the most relevant features from a dataset for use in model training.",
    "rubric_id": ""
  },
  {
    "id": "744fb7ce9936430437477c5862c9df3ecff7b3fca9eb19a1df5e1973652886c7",
    "text": "Describe the process of backpropagation. (Sample 322)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the core training algorithm for neural networks. It should describe the process of calculating the model's error and feeding that error backward through the network to adjust the weights.",
    "rubric_id": ""
  },
  {
    "id": "05ce8a9cfad860eef1df7e8076fe534574dd56f7f70aaaa8cccf9b82cf1ab3fa",
    "text": "How would you explain the concept of overfitting? (Sample 323)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define overfitting as what happens when a model learns the training data too well, including its noise, leading to poor performance on new data.",
    "rubric_id": ""
  },
  {
    "id": "03afeabbbd01006cd2063afc53002c5873436299a914dce9363cca5b4d726a43",
    "text": "What is principal component analysis (PCA)? (Sample 324)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix, which form an orthogonal basis of principal components that capture the maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "45ef36f9e383655c1e73c5a6e5493e8c330ca463122a606e01940d4244eebcc4",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 325)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: L1 regularization can shrink some weights to exactly zero, performing feature selection, while L2 regularization only encourages smaller weights.",
    "rubric_id": ""
  },
  {
    "id": "7d93a9ab0508157a716dcc43d799f514349b2cb922ebccb95005400389d55e56",
    "text": "What is principal component analysis (PCA)? (Sample 326)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a deep technical explanation of PCA. It must describe it as an orthogonal linear transformation that maps the data to a new coordinate system such that the greatest variance by some projection of the data comes to lie on the first coordinate (the first principal component), the second greatest variance on the second coordinate, and so on.",
    "rubric_id": ""
  },
  {
    "id": "48adcc977f945195529ed9d8c93298a45f8d6478985cc65777e23dd9e85de56b",
    "text": "What is your favorite machine learning algorithm and why? (Sample 327)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific, sophisticated algorithm and provide a deep technical justification. It should demonstrate a strong understanding of the algorithm's mechanics, its theoretical underpinnings, and its practical application in complex scenarios.",
    "rubric_id": ""
  },
  {
    "id": "9b6d38f6ecf109a8d9e788c01a3c8527a2f2d2dc2429ed34752f9551036a33b3",
    "text": "How does a neural network work? (Sample 328)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the layered architecture of a neural network. It should explain the roles of neurons, weights, biases, and activation functions in processing information from the input layer to the output layer.",
    "rubric_id": ""
  },
  {
    "id": "2e29bd3349394b50d90469e07e9d0b7fd5d7c8e20e1bfa1bbfc6b9dbf3d7b724",
    "text": "Can you explain the concept of gradient descent? (Sample 329)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define gradient descent as an optimization algorithm. It should explain the core idea of iteratively taking steps in the direction opposite to the gradient (the 'slope') of a function to find its minimum.",
    "rubric_id": ""
  },
  {
    "id": "68b35dc4686471ffc4b57caf0579c725c8bbe3867a9c7f5317d84e0dc8e60a46",
    "text": "What is your favorite machine learning algorithm and why? (Sample 330)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and give a valid, concise reason for the choice, such as its good performance, interpretability, or ease of use.",
    "rubric_id": ""
  },
  {
    "id": "ff51423bc07d5fa9325063d854b4359f11bb97fc1b562cf18b6cf007538d2e0d",
    "text": "Explain cross-validation and its purpose. (Sample 331)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as getting a more reliable estimate of a model's performance on unseen data. It should describe the k-fold procedure of splitting the data into 'k' partitions and iteratively training and validating on them.",
    "rubric_id": ""
  },
  {
    "id": "523147c86898fe6105df87a75ff56b25373234ec1e0a2fba0e748fb2337d1f13",
    "text": "What is principal component analysis (PCA)? (Sample 332)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix. These eigenvectors, the principal components, define an orthogonal basis that captures the directions of maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "833f9022a2eb3dad5769da9617453589246bcfa86a453dbeaca304ea13c0e602",
    "text": "What are the key differences between classification and regression? (Sample 333)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough distinction. It must cover the difference in output type (discrete vs. continuous), the types of algorithms suitable for each, and the different evaluation metrics used for each task (e.g., accuracy vs. RMSE).",
    "rubric_id": ""
  },
  {
    "id": "fa00abb40e9f15e854a9fe978c8449af84f365416e1e6ad4428dd48ca33fc6ef",
    "text": "Can you explain the concept of gradient descent? (Sample 334)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of gradient descent and its variants. It should cover the core mathematical concept of using the gradient to find a minimum and clearly differentiate between batch, stochastic, and mini-batch gradient descent, explaining their respective trade-offs in terms of convergence speed and stability.",
    "rubric_id": ""
  },
  {
    "id": "8f8dbf990833d8ee3da355c22667fa4a873d7e1edda4559754c9df5523042cbb",
    "text": "How do you handle missing values in a dataset? (Sample 335)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive strategy. It should discuss the importance of understanding the missingness mechanism (MCAR, MAR, MNAR) and compare the trade-offs of various techniques, from simple imputation to more advanced model-based methods like MICE.",
    "rubric_id": ""
  },
  {
    "id": "1f42029dcc5c781cc606a4e7d762b255d57fbfb14e9a1476d217253401c939ac",
    "text": "What is the role of activation functions in deep learning? (Sample 336)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the key role of activation functions is to introduce non-linearity into a neural network, which is necessary for the model to learn complex patterns.",
    "rubric_id": ""
  },
  {
    "id": "8d9122a51204a8b11ac7b25287c272555a128bf8c879223c0a76c33b0d3c92bb",
    "text": "What are the key differences between classification and regression? (Sample 337)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough distinction. It must cover the difference in output type (discrete vs. continuous), the types of algorithms suitable for each, and the different evaluation metrics used for each task (e.g., accuracy/F1 vs. RMSE/R2).",
    "rubric_id": ""
  },
  {
    "id": "454982971eb404f60710e1ddd1dfc465e744b038d13215aaca4e3e29d48552ba",
    "text": "Describe the process of backpropagation. (Sample 338)",
    "domain": "technical-deep-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of backpropagation. It must describe the forward pass to compute error and the backward pass that uses the chain rule to recursively compute the gradient of the error with respect to each weight, which is then used for weight updates.",
    "rubric_id": ""
  },
  {
    "id": "7df21795adc27f46a2a4414de212d71ee97ae375fa469ab0c03b7d924866feab",
    "text": "What are the advantages of ensemble methods? (Sample 339)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance by combining multiple models. It should mention that they can reduce variance (e.g., bagging) or bias (e.g., boosting), leading to more robust and accurate results.",
    "rubric_id": ""
  },
  {
    "id": "096aeb8a8c580d745ee2088a2bb3dd0d812de667f87f91ec4a2b02c24842a422",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 340)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must contrast the penalty terms and their effects. L1 (Lasso) uses an absolute value penalty, which can perform feature selection by shrinking some weights to zero. L2 (Ridge) uses a squared penalty, which encourages smaller weights but doesn't set them to zero.",
    "rubric_id": ""
  },
  {
    "id": "206d3adfb0f7e7fc167359f02bcb899491b355ef7a6e7e11510c6ebb9e87b635",
    "text": "What is principal component analysis (PCA)? (Sample 341)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix. These eigenvectors, the principal components, define an orthogonal basis that captures the directions of maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "3c57f5bdc479776f6a763b559591f2d0aa59c80444507a7e419ccc2ad8834581",
    "text": "What is the difference between bagging and boosting? (Sample 342)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between the two ensemble methods. Bagging trains models in parallel on different data subsets to reduce variance. Boosting trains models sequentially, with each model focusing on the errors of the previous one to reduce bias.",
    "rubric_id": ""
  },
  {
    "id": "da9c90a2863afcbe52507397d3c1b881d74c992e20f46ce5365dbd4040d2c8ac",
    "text": "What is the role of activation functions in deep learning? (Sample 343)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that activation functions introduce non-linearity into a neural network, which is essential for the model to learn complex patterns in data.",
    "rubric_id": ""
  },
  {
    "id": "f411d735eace1a95927b8cc4b369ee2ed23529e43f7beefd4e557b3267a4f4ac",
    "text": "What is principal component analysis (PCA)? (Sample 344)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a deep technical explanation of PCA. It should describe it as finding the eigenvectors of the data's covariance matrix, which form an orthogonal basis of principal components that capture the maximum variance.",
    "rubric_id": ""
  },
  {
    "id": "3db89eb482e395a6c8f655528daa92c6b7482276d6d14e17c4e308c9b8bf8463",
    "text": "Can you explain the concept of gradient descent? (Sample 345)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of gradient descent and its variants. It should cover the core mathematical concept of using the gradient to find a minimum and clearly differentiate between batch, stochastic, and mini-batch gradient descent, explaining their respective trade-offs.",
    "rubric_id": ""
  },
  {
    "id": "0060b7fd09c5011af33efe6df851d25aa8eb853c00bc616968ca3ae959f6b9b0",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 346)",
    "domain": "behavioral-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must follow the STAR method (Situation, Task, Action, Result). It should clearly describe a project, the objective, the specific actions and ML techniques used, and the final outcome.",
    "rubric_id": ""
  },
  {
    "id": "51fbcdedd40df551b0a65ad61a3a01617fe508f10fad1791e911bf294f2cbe66",
    "text": "How does a neural network work? (Sample 347)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the layered architecture of a neural network. It should explain the role of neurons, weights, biases, and activation functions in processing information from the input layer to the output layer.",
    "rubric_id": ""
  },
  {
    "id": "36f4aa8a6823e39435a211fbd40eedbdfebb6f28fddc5535a849ba1d0ccee519",
    "text": "What is your favorite machine learning algorithm and why? (Sample 348)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must name a specific, advanced algorithm and provide a deep technical justification. It should demonstrate a strong understanding of its inner workings, its theoretical advantages, and its practical application in complex scenarios.",
    "rubric_id": ""
  },
  {
    "id": "ffbe33d498d913aad0ad41a4f5b7b24991d4431000a07219e47fa044dc011cae",
    "text": "How does a neural network work? (Sample 349)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe the layered architecture of a neural network. It should explain that neurons compute a weighted sum of inputs and then apply a non-linear activation function, and that this process is repeated through the layers to generate a prediction.",
    "rubric_id": ""
  },
  {
    "id": "294a5dc9765181247434c18da53f1c425737a8b5b1e1359494b29c791bc6aa55",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 350)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: L1 regularization can shrink some weights to exactly zero, performing feature selection, while L2 regularization only encourages smaller weights.",
    "rubric_id": ""
  },
  {
    "id": "0a6df5f60e13662a3ee9b4f3b07726e27112fe4d266115d026bb366f0bab71e9",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 351)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with a clear technical challenge. It should detail the situation, the specific ML task, the actions taken to overcome the challenge, and the final, measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "c427bdb2158cb384691bf88027144c9c015fb0945cb323f343ce0b824b95a3eb",
    "text": "What is the role of activation functions in deep learning? (Sample 352)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must state that activation functions introduce non-linearity into a neural network, which is essential for the model to learn complex patterns in data.",
    "rubric_id": ""
  },
  {
    "id": "3f09fba52f0e23050284656f8a379334ba4b87fb45885bd0a4e88a3be8de4dc7",
    "text": "How would you approach data cleaning for a large dataset? (Sample 353)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline a systematic process. It should include data profiling to identify issues, strategies for handling missing data and outliers, and writing reproducible code. Mentioning scalable tools like Spark is a plus.",
    "rubric_id": ""
  },
  {
    "id": "f5ac8facc14dba1d43c77ad81817e112ad560e4cc322604e095ea5bda45e37bf",
    "text": "What metrics would you use to evaluate a regression model? (Sample 354)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must list and critically compare multiple regression metrics. It should discuss the properties and business implications of using MAE, MSE, RMSE, and R-squared, explaining when one would be more appropriate than the others.",
    "rubric_id": ""
  },
  {
    "id": "f019e3fa90d5d4bf41947fba507d07a34e52173c96f536757838a163ba53e006",
    "text": "What metrics would you use to evaluate a regression model? (Sample 355)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should list and differentiate common regression metrics. It must include MAE, MSE/RMSE, and R-squared, and explain what each one measures and its sensitivity to errors.",
    "rubric_id": ""
  },
  {
    "id": "a46471edc52eaf12cbc2043f961ec5a3e272b0c131c690723ed46e086183aa5f",
    "text": "What metrics would you use to evaluate a regression model? (Sample 356)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed comparison of multiple regression metrics. It should discuss the properties and trade-offs of MAE, MSE, RMSE, and R-squared, and explain how the choice of metric depends on the specific business problem and the cost of different types of errors.",
    "rubric_id": ""
  },
  {
    "id": "4d43d61dae225e56a603afd2ac8cfbce787705eb081559a58ae14a8900c50d66",
    "text": "How would you explain the concept of overfitting? (Sample 357)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define overfitting as a model that performs well on training data but poorly on unseen data. It should explain that this occurs when the model learns noise from the training data instead of the underlying signal, and mention potential solutions like regularization.",
    "rubric_id": ""
  },
  {
    "id": "da1e491c7ae87e95270d0146231fa0693e09878ecac2636dc11bd46a5ee62b78",
    "text": "How would you optimize a machine learning model? (Sample 358)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer should describe a structured optimization process. This must include hyperparameter tuning, iterative feature engineering, and analyzing model errors to guide further improvements.",
    "rubric_id": ""
  },
  {
    "id": "83f44bc0853c56c9c1e9f51fad1a812cfd8756076efb4cf8bfc80fd638b31420",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 359)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with a clear technical challenge. It should detail the problem, the solution implemented, and the final, measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "610dbd4daf325c307640835499c5f8aa1d59ad37ed711d61d91ad665e4da2d5e",
    "text": "How would you optimize a machine learning model? (Sample 360)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer should describe a basic model optimization process. This must include tuning the model's hyperparameters and possibly improving the features used for training.",
    "rubric_id": ""
  },
  {
    "id": "ec850423515151527fd7ba47ca56abadfd40fb80d1b9dd88132bfcdb181aaefe",
    "text": "What is the difference between bagging and boosting? (Sample 361)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: Bagging involves training models independently on different data samples in parallel. Boosting involves training models sequentially, where each model learns from the previous one's errors.",
    "rubric_id": ""
  },
  {
    "id": "8e35e0f809e7215f6b8e5b84e8147d154b87af5687628b216a811bb4abe98b97",
    "text": "What is principal component analysis (PCA)? (Sample 362)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define PCA as a dimensionality reduction technique. It should explain that it finds a new set of features (principal components) that are uncorrelated and capture the most variance in the data.",
    "rubric_id": ""
  },
  {
    "id": "397818e09b75c74960c54ef506a90d46a59a89789188c7bab94fd5fa6c071f99",
    "text": "What is the bias-variance tradeoff? (Sample 363)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define bias as error from a model being too simple and variance as error from a model being too complex. It must explain the trade-off: reducing one often leads to an increase in the other.",
    "rubric_id": ""
  },
  {
    "id": "7065bad71117e1edd548b076d6562bd9c4bb5e86bcc5d6258fec8c149ffc8680",
    "text": "Describe the process of backpropagation. (Sample 364)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the core training algorithm for neural networks. It should describe the process of calculating the model's error and feeding that error backward through the network to adjust the weights.",
    "rubric_id": ""
  },
  {
    "id": "89b3624d5f3ef2d6c082db9da1f9eb06457378224673206317e438635ee901ad",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 365)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: L1 regularization can shrink some weights to exactly zero, performing feature selection, while L2 regularization only encourages smaller weights.",
    "rubric_id": ""
  },
  {
    "id": "e31e266d1627d7156028a39bff8b64b2ea4054c7fbcd548fcf5fd7c001f5c726",
    "text": "What are the key differences between classification and regression? (Sample 366)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference based on the output: classification predicts a discrete class, while regression predicts a continuous numerical value.",
    "rubric_id": ""
  },
  {
    "id": "27c5a63bcf8f5cdd7e4c03c6199a641c281b5f64a0980aa77919447e42842a50",
    "text": "How would you optimize a machine learning model? (Sample 367)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must describe a comprehensive optimization strategy. This should include advanced hyperparameter tuning (e.g., Bayesian optimization), iterative feature engineering guided by error analysis, and potentially exploring novel model architectures or custom loss functions.",
    "rubric_id": ""
  },
  {
    "id": "b0a0fd9ff069b37d004d79b6ec1470c2b18b849e074b3a9ed84fc133cff82a01",
    "text": "What is the difference between bagging and boosting? (Sample 368)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: bagging trains models in parallel, while boosting trains them sequentially.",
    "rubric_id": ""
  },
  {
    "id": "31d7518da5cf03183edc0428ebc76d224dd1e75b1625530f5c6ab735fcffad6e",
    "text": "What are the advantages of ensemble methods? (Sample 369)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance by combining multiple models. It should mention that they can reduce variance (e.g., bagging) or bias (e.g., boosting), leading to more robust and accurate results.",
    "rubric_id": ""
  },
  {
    "id": "74d3c572167faeb8c78fa64a3961d10d83335c83c610c8e31ee39da0f2ef65b3",
    "text": "Can you explain the concept of gradient descent? (Sample 370)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain gradient descent as an iterative optimization algorithm for minimizing a loss function. It should describe the process of calculating the gradient and updating parameters in the opposite direction to find a minimum.",
    "rubric_id": ""
  },
  {
    "id": "06d8a7b48ab88b8a87b4eb9ddb8cedde4eeb4be231aa6441fe95f3e0f0755a19",
    "text": "Explain cross-validation and its purpose. (Sample 371)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define cross-validation's purpose as being a method to get a more reliable estimate of a model's performance on new data than a single train-test split.",
    "rubric_id": ""
  },
  {
    "id": "08aca777bb880d471f467c8bbffbf8da4e1a22225527839fa855d20b55957379",
    "text": "What is principal component analysis (PCA)? (Sample 372)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must define PCA as a dimensionality reduction technique. It should explain that it works by finding a new set of orthogonal axes (principal components) that capture the most variance in the data.",
    "rubric_id": ""
  },
  {
    "id": "985f937d095d42ac9b754ad8d50be9b4defc3436c57c27c74cf9078405bf39a0",
    "text": "Describe the process of backpropagation. (Sample 373)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the core training algorithm for neural networks. It should describe the process of calculating the model's error and feeding that error backward through the network to adjust the weights.",
    "rubric_id": ""
  },
  {
    "id": "4d5f57667b5a0f44af9794c8e6e0b761ecac107c1d0318fe1be396e83e92b55a",
    "text": "What are the advantages of ensemble methods? (Sample 374)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must explain that ensemble methods improve predictive performance and robustness. It should mention that they achieve this by combining multiple models, which can reduce bias, variance, or both.",
    "rubric_id": ""
  },
  {
    "id": "a1b6392e02f99f134b5a44893f9467dd8661b8cf42c9a8d875ac84f1017abb98",
    "text": "What is the bias-variance tradeoff? (Sample 375)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define bias as error from a model being too simple and variance as error from a model being too complex. It must explain the trade-off: reducing one often leads to an increase in the other.",
    "rubric_id": ""
  },
  {
    "id": "57f90cfdf5e3844439c8f6b8d0eec92815a3fa14d95737a2a92c1d99f9910688",
    "text": "Describe the process of backpropagation. (Sample 376)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the algorithm used to train neural networks. It should describe the core idea of calculating the error at the output and propagating it backward to update the network's weights.",
    "rubric_id": ""
  },
  {
    "id": "7873dd2f6cfba3a4cb03486450249869d1cdee458e4bc308f63c6a60eef721d6",
    "text": "What is the role of activation functions in deep learning? (Sample 377)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the key role of activation functions is to introduce non-linearity into a neural network, which is necessary for the model to learn complex patterns.",
    "rubric_id": ""
  },
  {
    "id": "1192675ec58760dd2dcbeaa2406791d21bf4fbeaf8c00dd2ea634d78b6a0cdb9",
    "text": "What are the key differences between classification and regression? (Sample 378)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough distinction. It must cover the difference in output type (discrete vs. continuous), the types of algorithms suitable for each, and the different evaluation metrics used for each task (e.g., accuracy/F1 vs. RMSE/R2).",
    "rubric_id": ""
  },
  {
    "id": "47092056c99607dbcfdcb4ebe788728dad0cd91537f21bacd359d137f812cf23",
    "text": "Can you explain the concept of gradient descent? (Sample 379)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of gradient descent and its variants. It should cover the core mathematical concept of using the gradient to find a minimum and clearly differentiate between batch, stochastic, and mini-batch gradient descent, explaining their respective trade-offs.",
    "rubric_id": ""
  },
  {
    "id": "95877ce681c81ed95c82842f4db675854afa027d4a5366850c3e84e6c674f97e",
    "text": "What is your favorite machine learning algorithm and why? (Sample 380)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and give a valid, concise reason for the choice, such as its good performance, interpretability, or speed.",
    "rubric_id": ""
  },
  {
    "id": "3b88b46b8e19d176e66bcf238c52ae4908846c993e4ca579c7db8886ec62ca58",
    "text": "What is regularization and why is it important? (Sample 381)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization. It must explain its purpose (preventing overfitting), the mathematical intuition of adding a penalty term, and the different behaviors of L1 (sparsity) and L2 (weight shrinkage) penalties.",
    "rubric_id": ""
  },
  {
    "id": "4e91b3ad681d4a90ff98ad2198edab7288c7470062332955849a53b2d6a507c4",
    "text": "What is regularization and why is it important? (Sample 382)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define regularization as a technique to prevent overfitting. It is important because it helps a model generalize better by penalizing complexity.",
    "rubric_id": ""
  },
  {
    "id": "6581f799c3f4d9a97abbf7d4ef7dbe507ad072b64501428d704755709fc88e88",
    "text": "Explain cross-validation and its purpose. (Sample 383)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a thorough explanation of cross-validation. It should describe the k-fold procedure and explain that its purpose is to provide a more stable and less biased estimate of a model's generalization performance by averaging results over multiple train-test splits.",
    "rubric_id": ""
  },
  {
    "id": "4a56f4a92de056d99042ca06064d61c99ca2cccd1bc09d9992bcc1536918f5c2",
    "text": "What is your favorite machine learning algorithm and why? (Sample 384)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear, simple justification. The reason should relate to a practical benefit like its ease of interpretation or its general effectiveness.",
    "rubric_id": ""
  },
  {
    "id": "4a7f732a52c59e0e76f1022b091c778ee163a811bf761589e0042076f19de901",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 385)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: L1 regularization can shrink some weights to exactly zero, performing feature selection, while L2 regularization only encourages smaller weights.",
    "rubric_id": ""
  },
  {
    "id": "7ff412936bbc86a1cae695bff4f8f09deefa2019d37250324593a4ccf2419ecb",
    "text": "Describe the process of backpropagation. (Sample 386)",
    "domain": "technical-deep-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must describe backpropagation as the core training algorithm for neural networks. It should explain the two main phases: a forward pass to compute the error, and a backward pass that uses the chain rule to compute and propagate gradients back through the network to update the weights.",
    "rubric_id": ""
  },
  {
    "id": "3786509ff3a3c1b16f9309e42d01b179d53c256ed7280084cb4569758e43d266",
    "text": "What is the difference between bagging and boosting? (Sample 387)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must distinguish between the two ensemble methods. Bagging trains models in parallel to reduce variance. Boosting trains models sequentially to reduce bias by focusing on errors from previous models.",
    "rubric_id": ""
  },
  {
    "id": "767034099eafa284bb8ca1b3c821b7589e54711a73d9893425867b3ae7c57372",
    "text": "What is regularization and why is it important? (Sample 388)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization. It must explain its purpose (preventing overfitting), the mathematical intuition of adding a penalty term, and the different behaviors of L1 (sparsity) and L2 (weight shrinkage) penalties.",
    "rubric_id": ""
  },
  {
    "id": "68413efa8e00f297727a5a07a94852721d465c749129c64b9922c43b240fe3a4",
    "text": "How would you approach data cleaning for a large dataset? (Sample 389)",
    "domain": "technical-data-science",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must outline a systematic process. It should include data profiling to identify issues, strategies for handling missing data and outliers, and writing reproducible code. Mentioning scalable tools like Spark is a plus.",
    "rubric_id": ""
  },
  {
    "id": "8125c5296c4d92cde774c768052c5f06407127cb692fc121c21312d18af4c6cd",
    "text": "Explain the difference between L1 and L2 regularization. (Sample 390)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the key difference: L1 regularization can shrink some weights to exactly zero, performing feature selection, while L2 regularization only encourages smaller weights.",
    "rubric_id": ""
  },
  {
    "id": "d5e03e2cbfbcf32964a03db06aa3e85a485256207687b3ecac70ecc14720852b",
    "text": "What is principal component analysis (PCA)? (Sample 391)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must define PCA as a dimensionality reduction technique. It should explain that it finds a new set of features (principal components) that are uncorrelated and capture the most variance in the data.",
    "rubric_id": ""
  },
  {
    "id": "5e10d2a0291fac70affae1ebe1c58d0ed04041c6ce3a103e2dc83860f55b1c7a",
    "text": "What are the advantages of ensemble methods? (Sample 392)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state that the main benefit of ensemble methods is that combining multiple models usually results in better predictive performance and a more robust model.",
    "rubric_id": ""
  },
  {
    "id": "8f6dc281bbe44c93208d97f2b477c7e44356a9998b21822f91039954136d2147",
    "text": "Describe a challenging machine learning project you have worked on. (Sample 393)",
    "domain": "behavioral-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must use the STAR method to describe a project with a clear technical challenge. It should detail the problem, the solution implemented, and the final, measurable outcome.",
    "rubric_id": ""
  },
  {
    "id": "33fbd61ccec8e0204a62ffc1e98c4553e6e27fd863819ac2e9c034460f44021f",
    "text": "What are the key differences between classification and regression? (Sample 394)",
    "domain": "technical-machine-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must state the core difference based on the output: classification predicts a discrete class, while regression predicts a continuous numerical value.",
    "rubric_id": ""
  },
  {
    "id": "e1615cc2df320db2870fdc39eacefb04ae066f06eac88d5c8107118b478c3d73",
    "text": "How do you handle missing values in a dataset? (Sample 395)",
    "domain": "technical-data-science",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a comprehensive strategy. It should discuss the importance of understanding the missingness mechanism (MCAR, MAR, MNAR) and compare the trade-offs of various techniques, from simple imputation to more advanced model-based methods like MICE.",
    "rubric_id": ""
  },
  {
    "id": "33b82d956df4f1236d3df1cc5fc8c9eb00262ccc1d4fa4c8676334dd73081a9f",
    "text": "Describe the process of backpropagation. (Sample 396)",
    "domain": "technical-deep-learning",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must explain backpropagation as the core training algorithm for neural networks. It should describe the process of calculating the model's error and feeding that error backward through the network to adjust the weights.",
    "rubric_id": ""
  },
  {
    "id": "456397dfea9dd23789f683f4a891041502e04358a6e83f9660df1042d28d5051",
    "text": "What are the advantages of ensemble methods? (Sample 397)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must provide a detailed explanation of why ensembles are powerful. It should cover how they reduce variance through averaging (bagging) and reduce bias by focusing on errors (boosting), linking these concepts to the bias-variance tradeoff and improved generalization.",
    "rubric_id": ""
  },
  {
    "id": "41ac40483d803619cd4bbd9ab0055a89d5ddefb9a37cf9942857501c277e6fdd",
    "text": "How would you approach data cleaning for a large dataset? (Sample 398)",
    "domain": "technical-data-science",
    "difficulty": 3,
    "ideal_answer_snippet": "The answer must outline a basic data cleaning workflow. Key tasks to mention are handling missing values (e.g., by removal or imputation), removing duplicates, and correcting data inconsistencies.",
    "rubric_id": ""
  },
  {
    "id": "8e675e7036891b9c8489b03f27aba9fd4106258ca3f4f01e022f31bf21961b8c",
    "text": "What is your favorite machine learning algorithm and why? (Sample 399)",
    "domain": "technical-machine-learning",
    "difficulty": 5,
    "ideal_answer_snippet": "The answer must name a specific algorithm and provide a clear technical justification for the choice, based on its performance characteristics, interpretability, or suitability for a particular type of data.",
    "rubric_id": ""
  },
  {
    "id": "e7cc16dbef10ae2899c5bf6a3912196078c31c21852ddd6af8e01f9ae6e2dbb7",
    "text": "What is regularization and why is it important? (Sample 400)",
    "domain": "technical-machine-learning",
    "difficulty": 8,
    "ideal_answer_snippet": "The answer must give a detailed explanation of regularization. It must explain its purpose (preventing overfitting), the mathematical intuition of adding a penalty term, and the different behaviors of L1 (sparsity) and L2 (weight shrinkage) penalties.",
    "rubric_id": ""
  },
  {
    "id": "7998d5c56e5d312f6492cdaec668953d3aa5f42d83f9c42593448e950d5e0fb6",
    "text": "Design a URL shortener service. Discuss storage, hashing, and scalability trade-offs.",
    "domain": "technical-tech-sysdesign",
    "difficulty": 6,
    "ideal_answer_snippet": "Cover API design, unique ID generation, DB schema, caching, rate limiting, and horizontal scaling.",
    "rubric_id": "rubric-sysdesign-01"
  },
  {
    "id": "21814b27d2f0cbe58f06e53aa1f000ec10b1e62864607e8a7ea29d52cc0a2cc3",
    "text": "Explain how you would optimize a Spark job that is running slowly on large datasets.",
    "domain": "technical-tech-ds",
    "difficulty": 5,
    "ideal_answer_snippet": "Discuss partitioning, caching, avoiding wide shuffles, predicate pushdown, and monitoring lineage/stages.",
    "rubric_id": "rubric-ds-01"
  },
  {
    "id": "8b0beadb85b99197db56d6efec6a671342dac64a049a079158e6606a0419fea7",
    "text": "Tell me about a time you handled a significant production incident.",
    "domain": "behavioural-behavioral",
    "difficulty": 4,
    "ideal_answer_snippet": "Describe incident detection, triage, root cause analysis, communication, and postmortem actions.",
    "rubric_id": "rubric-behavioral-01"
  }
]